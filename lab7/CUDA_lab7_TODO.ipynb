{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1tcrOAl5shww8EXE3X46hQu91Ms9d0oLB","timestamp":1745444472849}],"collapsed_sections":["NO_C5o9-xRF_"],"mount_file_id":"1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo","authorship_tag":"ABX9TyPZ4bv5zF/bXqv13AyEJq1F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","# **LAB 7 - CUDA Libraries**\n","---"],"metadata":{"id":"fZYqN0UwVLC_"}},{"cell_type":"markdown","metadata":{"id":"NO_C5o9-xRF_"},"source":["# ‚ñ∂Ô∏è CUDA setup"]},{"cell_type":"code","metadata":{"id":"8fekR2O4xRGE"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Psl9iouxRGE"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GPU computing notebooks download (from github)"],"metadata":{"id":"gcg1GyK5srek"}},{"cell_type":"code","source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"],"metadata":{"id":"tyHOxci3s3H8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"227eLdP5csN1"},"source":["NVCC Plugin for Jupyter notebook"]},{"cell_type":"code","source":["%cd GPUcomputing/utils/nvcc4jupyter-master/\n","!!python3 -m build\n","%load_ext nvcc4jupyter\n","%cd /content/"],"metadata":{"id":"4TzxMBFds8aT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lAVvcKOX_DU0"},"source":["# ‚úÖ cuBLAS"]},{"cell_type":"code","metadata":{"id":"OH6TuWnB-_0M"},"source":["%%cuda_group_save --name \"mat_prod_cublas.cu\" --group \"lez7\"\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include \"cublas_v2.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","#define IDX2R(r,c,D) ( r * D + c)\n","#define IDX2C(r,c,D) ( c * D + r )\n","\n","#define BLOCK_SIZE 4\n","#define M          (1<<12)\n","#define N          (1<<12)\n","#define P          (1<<12)\n","\n","void generate_random_vector(int, float**);\n","void generate_random_dense_matrix_Row_Maj(int, int, float**);\n","void generate_random_dense_matrix_Col_Maj(int, int, float**);\n","void plot_mat_Row_Maj(int, int, float*, char);\n","void plot_mat_Col_Maj(int, int, float*, char);\n","__global__ void matProdSMEMstatic(float*, float*, float*, int, int, int);\n","\n","/*\n"," * comparison between standard prod kernel and cuBLAS\n"," */\n","int main(int argc, char **argv) {\n","\n","\tint n = N, m = M, p = P;\n","\tfloat *A, *d_A;  // matrix M x N  (row M, col N)\n","\tfloat *B, *d_B;  // matrix N x P  (row N, col P)\n","\tfloat *C, *d_C;  // matrix M x P, C = A*B\n","\tfloat *x, *d_x;  // vector N x 1\n","\tfloat *y, *d_y;  // vector N x 1, y = A*x\n","\tfloat beta = 0.0f;\n","\tfloat alpha = 1.0f;\n","\tcublasHandle_t handle;\n","\tdevice_name();\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// Generate inputs\n","\tsrand(10);\n","\tgenerate_random_dense_matrix_Col_Maj(m, n, &A);\n","\tgenerate_random_dense_matrix_Col_Maj(n, p, &B);\n","\tgenerate_random_vector(n, &x);\n","\tgenerate_random_vector(n, &y);\n","\n","\tC = (float *) malloc(m * p * sizeof(float));\n","\n","\t// Allocate device memory\n","\tCHECK(cudaMalloc((void **)&d_A, m * n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_B, n * p * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_C, m * p * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_x, n * sizeof(float)));\n","\tCHECK(cudaMalloc((void **)&d_y, m * sizeof(float)));\n","\n","\t// Create the cuBLAS handle\n","\tCHECK_CUBLAS(cublasCreate(&handle));\n","\tint version;\n","\tCHECK_CUBLAS(cublasGetVersion(handle, &version));\n","\tprintf(\"Using CUBLAS Version: %d\\n\", version);\n","\n","\t// Transfer inputs to the device, column-major order\n","\tCHECK_CUBLAS(cublasSetMatrix(m, n, sizeof(float), A, m, d_A, m));\n","\tCHECK_CUBLAS(cublasSetMatrix(n, p, sizeof(float), B, n, d_B, n));\n","\tCHECK_CUBLAS(cublasSetMatrix(m, p, sizeof(float), C, m, d_C, m));\n","\tCHECK_CUBLAS(cublasSetVector(n, sizeof(float), x, 1, d_x, 1));\n","\tCHECK_CUBLAS(cublasSetVector(m, sizeof(float), y, 1, d_y, 1));\n","\n","\t/***************************************************\n","\t *      Multipl. matrix-vector CUBLAS              *\n","\t ***************************************************/\n","\n","  printf(\"\\n**  Matrix-vector product...\\n\");\n","  printf(\"    y(%d x 1) = A(%d x %d) * x(%d x 1)\\n\",n,m,n,n);\n","\n","\tcudaEventRecord(start);\n","\tCHECK_CUBLAS(cublasSgemv(handle, CUBLAS_OP_N, m, n, &alpha, d_A, m, d_x, 1, &beta, d_y, 1));\n","\tcudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tfloat milliseconds;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tprintf(\"    elapsed time: %.5f (sec)\\n\", milliseconds / 1000.0);\n","\n","\t// Retrieve the output vector from the device\n","\tCHECK_CUBLAS(cublasGetVector(m, sizeof(float), d_y, 1, y, 1));\n","\n","\n","\t/**********************************************\n","\t *  Multiplic. matrix-matrix CUBLAS           *\n","\t **********************************************/\n","\n","\tprintf(\"\\n**  Matrix-Matrix product...\\n\");\n","  printf(\"    C(%d x %d) = A(%d x %d) * B(%d x %d)\\n\",m,p,m,n,n,p);\n","\n","  //plot_mat_Col_Maj(m, n, A, 'A');\n","  //plot_mat_Col_Maj(n, p, B, 'B');\n","\n","\tCHECK(cudaMemset(d_C, 0,  m * p *sizeof(float)));\n","\tCHECK(cudaEventRecord(start));\n","\tCHECK_CUBLAS(cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, p, n, &alpha, d_A, m, d_B, n, &beta, d_C, m));\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tCHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n","\tprintf(\"    elapsed time: %.5f (sec)\\n\", milliseconds / 1000.0);\n","\n","\t// Retrieve the output vector from the device\n","\tCHECK_CUBLAS(cublasGetMatrix(m, p, sizeof(float), d_C, m, C, m));\n","\n","  //plot_mat_Col_Maj(m, p, C, 'C');\n","\n","\n","\t/*****************************************************\n","\t *  Multiplicat. matrix-matrix kernel ad-hoc         *\n","\t *****************************************************/\n","\n","\tprintf(\"\\n**  Matrix-Matrix product using ad-hoc kernel (with SMEM)...\\n\");\n","  printf(\"    C(%d x %d) = A(%d x %d) * B(%d x %d)\\n\",m,p,m,n,n,p);\n","\n","  float *A1, *B1;\n","  srand(10);\n","\tgenerate_random_dense_matrix_Row_Maj(m, n, &A1);\n","\tgenerate_random_dense_matrix_Row_Maj(n, p, &B1);\n","\n","  //plot_mat_Row_Maj(m, n, A1, 'A');\n","  //plot_mat_Row_Maj(n, p, B1, 'B');\n","\n","\t// copy matrices A and B to the GPU\n","\tCHECK(cudaMemcpy(d_A, A1, m * n * sizeof(float), cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemcpy(d_B, B1, n * p * sizeof(float), cudaMemcpyHostToDevice));\n","  CHECK(cudaMemset(d_C, 0.0f, m * p * sizeof(float)));\n","\n","\t// grid block dims = shared mem dims = BLOCK_SIZE\n","\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n","\tdim3 grid((p + block.x - 1) / block.x, (m + block.y - 1) / block.y);\n","\tCHECK(cudaEventRecord(start));\n","\tmatProdSMEMstatic<<<grid, block>>>(d_A, d_B, d_C, n, m, p);\n","  CHECK(cudaDeviceSynchronize());\n","\tCHECK(cudaEventRecord(stop));\n","\tCHECK(cudaEventSynchronize(stop));\n","\tCHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n","\tprintf(\"    elapsed time: %.5f (sec)\\n\", milliseconds / 1000.0);\n","\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C, d_C, m * p * sizeof(float), cudaMemcpyDeviceToHost));\n","\n","  //plot_mat_Row_Maj(m, p, C, 'C');\n","\n","\t// free memory\n","\tcudaFree(d_A);\n","\tcudaFree(d_B);\n","\tcudaFree(d_C);\n","\tcudaFree(d_x);\n","\tcudaFree(d_y);\n","\tCHECK_CUBLAS(cublasDestroy(handle));\n","\n","\treturn EXIT_SUCCESS;\n","}\n","\n","/*\n"," * Generate a vector of length N with random single-precision floating-point\n"," * values between 0 and 100.\n"," */\n","\n","void generate_random_vector(int n, float **x) {\n","\tfloat *z = (float *) malloc(sizeof(float) * n);\n","\n","\tfor (int i = 0; i < n; i++)\n","\t\tz[i] = (float)rand() / RAND_MAX;\n","\t*x = z;\n","}\n","\n","/*\n"," * Generate a matrix with M rows and N columns in column-major order. The matrix\n"," * will be filled with random single-precision floating-point values between 0 and 10\n"," */\n","void generate_random_dense_matrix_Col_Maj(int rows, int cols, float **A) {\n","\tfloat *a = (float *) malloc(sizeof(float) * rows * cols);\n","\n","  float val = 1.0;\n","  for (int c = 0; c < cols; ++c)\n","    for (int r = 0; r < rows; ++r){\n","      a[IDX2C(r,c,rows)] = val;\n","      val += 1;\n","    }\n","\t*A = a;\n","}\n","\n","void generate_random_dense_matrix_Row_Maj(int rows, int cols, float **A) {\n","\tfloat *a = (float *) malloc(sizeof(float) * rows * cols);\n","\n","  float val = 1.0;\n","\tfor (int r = 0; r < rows; r++)\n","\t\tfor (int c = 0; c < cols; c++) {\n","\t\t\ta[IDX2R(r,c,cols)] = val;\n","      val += 1;\n","\t\t}\n","\t*A = a;\n","}\n","\n","void plot_mat_Row_Maj(int rows, int cols, float *A, char name) {\n","  printf(\"\\nShow mat %c...\\n\", name);\n","\tfor(int r = 0; r < rows; ++r){\n","    for(int c = 0; c < cols; ++c)\n","\t\t\tprintf(\"%4.1f \", A[IDX2R(r,c,cols)]);\n","    printf(\"\\n\");\n","\t}\n","  printf(\"\\n\");\n","}\n","\n","void plot_mat_Col_Maj(int rows, int cols, float *A, char name) {\n","  printf(\"\\nShow mat %c...\\n\", name);\n","  for(int r = 0; r < rows; ++r){\n","    for(int c = 0; c < cols; ++c)\n","      printf(\"%4.1f \", A[IDX2C(r,c,rows)]);\n","    printf(\"\\n\");\n","  }\n","  printf(\"\\n\");\n","}\n","\n","\n","/*\n"," * Kernel for matrix product with static SMEM\n"," *      C   =   A   *   B\n"," *   (m x p) (m x n) (n x p)\n"," */\n","__global__ void matProdSMEMstatic(float* A, float* B, float* C, int n, int m, int p) {\n","\t// indexes\n","\tuint row = blockIdx.y * blockDim.y + threadIdx.y; // in [0..m]\n","\tuint col = blockIdx.x * blockDim.x + threadIdx.x; // in [0..p]\n","\n","\t// target: compute the right sum for the given row and col\n","\tfloat sum = 0.0;\n","\n","\t// static shared memory\n","\t__shared__ float As[BLOCK_SIZE][BLOCK_SIZE];\n","\t__shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];\n","\n","\t// loop over blocks from block row of matrix A and block column of matrix B\n","\tuint numBlocks = (n + BLOCK_SIZE - 1) / BLOCK_SIZE;\n","\n","\tfor (uint i = 0; i < numBlocks; i++) {\n","\n","\t\t// copy block from matrix to shared memory\n","\t\tuint r = i * BLOCK_SIZE + threadIdx.y;\n","\t\tuint c = i * BLOCK_SIZE + threadIdx.x;\n","\t\tAs[threadIdx.y][threadIdx.x] = A[IDX2R(row, c, n)];\n","\t\tBs[threadIdx.y][threadIdx.x] = B[IDX2R(r, col, p)];\n","\n","\t\t__syncthreads();  //  BARRIER SYNC on SMEM loading\n","\n","\t\tuint K = BLOCK_SIZE;\n","\t\tif (i == (numBlocks - 1))\n","      K = n - i * BLOCK_SIZE;   // tune last block\n","\n","\t\t// compute this part of row-column product\n","\t\tfor (uint k = 0; k < K; k++)\n","\t\t\tsum += As[threadIdx.y][k] * Bs[k][threadIdx.x];\n","\n","\t\t__syncthreads();  //  BARRIER SYNC on prod over blocks\n","\t}\n","\n","\t// store computed element in matrix C\n","\tif (row < m && col < p)\n","\t\tC[row * p + col] = sum;\n","}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["‚Ü© **Run...**"],"metadata":{"id":"T9S0V6giQ1QK"}},{"cell_type":"code","metadata":{"id":"7G91KROXBScK"},"source":["!nvcc -arch=sm_75 src/lez7/mat_prod_cublas.cu  -o prod -lcublas\n","!./prod"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Gradiente coniugato"],"metadata":{"id":"UwHlqd-bmEaw"}},{"cell_type":"markdown","source":["‚ÜòÔ∏è **TODO...**"],"metadata":{"id":"1wm23k6-G38i"}},{"cell_type":"markdown","source":["Calcolare discesa lungo il gradiente..."],"metadata":{"id":"WK1z7xCcSz5v"}},{"cell_type":"code","source":["%%cuda_group_save --name \"conj_grad.cu\" --group \"lez7\"\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <string.h>\n","#include <time.h>\n","#include <cublas_v2.h>\n","#include <cblas.h>\n","#include <cuda_runtime.h>\n","#include <cusparse.h>\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","#define IDX2R(r,c,D) ( r * D + c)\n","#define IDX2C(r,c,D) ( c * D + r )\n","\n","#define N          (1<<10)\n","\n","void generate_random_vector(int, double**);\n","void generate_rand_posdefinite_mat(int, double**);\n","void plot_mat(int, double*, char);\n","void plot_vec(int, double*, char);\n","double norm2(int, double *);\n","\n","/*\n"," * This sample implements a conjugate gradient solver on GPU using CUBLAS\n"," */\n","int main(int argc, char **argv) {\n","  int n = N;\t\t\t\t\t\t\t\t\t// problem size\n","\tdouble *A, *dA;      \t\t\t\t// matrix N x N  (square)\n","\tdouble *x, *dx;      \t\t\t\t// vector N x 1\n","\tdouble *b, *db;     \t\t\t\t// vector N x 1\n","\tdouble *dr, *dr1;    \t\t\t\t// vector N x 1\n","\tdouble *dp;       \t\t\t   \t// vector N x 1\n","\tdouble *dAxp,*dAxx, *dAxr; \t// vector N x 1\n","\n","\tcublasHandle_t handle;\n","\tdevice_name();\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// Generate instance: matrix A and vector b\n","\tsrand(time(NULL));\n","\tgenerate_rand_posdefinite_mat(n, &A);      // random symmetric matrix A\n","\tgenerate_random_vector(n, &b);            // random verctor b\n","\tgenerate_random_vector(n, &x);            // random initial solution\n","\t//plot_mat(n, A,'A');\n","\n","\t// Allocate device memory\n","\tCHECK(cudaMalloc((void **)&dA, n * n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dx, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&db, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dr, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dr1, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dp, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dAxp, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dAxr, n * sizeof(double)));\n","\tCHECK(cudaMalloc((void **)&dAxx, n * sizeof(double)));\n","\n","\t// Create the cuBLAS handle\n","\tCHECK_CUBLAS(cublasCreate(&handle));\n","\tint version;\n","\tCHECK_CUBLAS(cublasGetVersion(handle, &version));\n","\tprintf(\"Using CUBLAS Version: %d\\n\", version);\n","\n","\t// Transfer inputs to the device, column-major order\n","\tCHECK_CUBLAS(cublasSetMatrix(n, n, sizeof(double), A, n, dA, n));\n","\tCHECK_CUBLAS(cublasSetVector(n, sizeof(double), b, 1, db, 1));\n","\tCHECK_CUBLAS(cublasSetVector(n, sizeof(double), x, 1, dx, 1));\n","\n","\t// CG\n","\tdouble beta = 0.0f;\n","\tdouble alpha = 0.0f;\n","\tdouble one = 1.0f, minusOne = -1.0f, zero = 0.0f;\n","\tdouble num, den = 0;\n","\n","\t // init\n","\t\t\t\t\t//# r0 = b\n","\t\t\t\t\t//# r0 = b ‚àí ùê¥‚àóx0\n","\t\t\t\t\t//# p0 = r0\n","\n","\t // loop\n","\tfor (int k = 0; k <= n; k++) {\n","\t\t\t\t\t//# num = pùëò^ùëá ‚àó rùëò\n","\t\t\t\t\t//# Axp = ùê¥ ‚àó pùëò\n","\t\t\t\t\t//# den = pùëò^ùëá ‚àó ùê¥ ‚àó pùëò\n","\t\t\t\t\t//# ùõºùëò = num/den\n","\t\t\t\t\t//# x(ùëò+1) = xùëò + ùõºùëò * pùëò\n","\t\t\t\t\t//# Axx = ùê¥ ‚àó x(ùëò+1)\n","\t\t\t\t\t//# r(k) = b\n","\t\t\t\t\t//# r(ùëò+1) = b ‚àí ùê¥ ‚àó x(ùëò+1)\n","\t\t\t\t\t//# Axr = ùê¥ ‚àó r(ùëò+1)\n","\t\t\t\t\t//# num = pùëò^ùëá ‚àó ùê¥ ‚àó r(ùëò+1)\n","\t\t\t\t\t//# ùõΩùëò = num/den\n","\t\t\t\t\t//# p(k+1) = rk - ùõΩùëò * pùëò\n","\t}\n","\n","\t// final solution\n","\tCHECK_CUBLAS(cublasGetVector(n, sizeof(double), dx, 1, x, 1));\n","\tcublasDgemv(handle, CUBLAS_OP_N, n, n, &one, dA, n, dx, 1, &zero, db, 1);    // b1 = ùê¥‚àóùë•\n","\tdouble *b1 = (double *) malloc(sizeof(double) * n);\n","\tCHECK_CUBLAS(cublasGetVector(n, sizeof(double), db, 1, b1, 1));              // b1 (approx solution)\n","\n","\t//plot norms of the vectors\n","\tprintf(\"norm b orig  = %f\\n\", norm2(n, b));\n","\tprintf(\"norm b = A*x = %f\\n\", norm2(n, b1));\n","\t//plot_vec(n, b, 'b');\n","\t//plot_vec(n, b1, 'b');\n","\n","  free(A);\n","  free(x);\n","  free(b);\n","  cudaFree(dA);\n","  cudaFree(dx);\n","\tcudaFree(db);\n","  cudaFree(dr);\n","\tcudaFree(dr1);\n","\tcudaFree(dp);\n","\tcudaFree(dAxp);\n","\tcudaFree(dAxr);\n","}\n","\n","void generate_rand_posdefinite_mat(int n, double **A) {\n","\tdouble *a = (double *) malloc(sizeof(double) * n * n);\n","\tdouble *r = (double *) malloc(sizeof(double) * n * n);\n","\n","\t// generate a random matrix\n","\tfor (int i = 0; i < n; i++)\n","\t\tfor (int j = 0; j < n; j++)\n","\t\t\tr[i*n+j] = (double)rand() / RAND_MAX;\n","\n","\t// compute the product with its transpose (positive definite matrix)\n","\tfor (int i = 0; i < n; i++) {\n","  \tfor (int j = i; j < n; j++) {\n","   \t\ta[i*n+j] = 0;\n","   \t\tfor (int k = 0; k < n; k++)\n","    \t\ta[i*n+j] += r[i*n+k]*r[j*n+k];\n","\t\t\ta[j*n+i] = a[i*n+j];\n","  \t}\n","\t}\n","\t*A = a;\n","}\n","\n","\n","void plot_mat(int n, double *A, char name) {\n","  printf(\"\\nShow mat %c...\\n\", name);\n","\tfor(int r = 0; r < n; ++r){\n","    for(int c = 0; c < n; ++c)\n","\t\t\tprintf(\"%4.1f \", A[IDX2R(r,c,n)]);\n","    printf(\"\\n\");\n","\t}\n","  printf(\"\\n\");\n","}\n","\n","double norm2(int n, double *x) {\n","\tdouble norm = 0;\n","\tfor(int i = 0; i < n; ++i)\n","\t\tnorm += x[i]*x[i];\n","\tnorm = sqrt(norm);\n","  return norm;\n","}\n","\n","void plot_vec(int n, double *x, char name) {\n","  printf(\"\\nShow vec %c...\\n\", name);\n","\tfor(int i = 0; i < n; ++i)\n","\t\t\tprintf(\"%4.1f \", x[i]);\n","  printf(\"\\n\");\n","}\n","\n","void generate_random_vector(int n, double **x) {\n","\tdouble *z = (double *) malloc(sizeof(double) * n);\n","\n","\tfor (int i = 0; i < n; i++)\n","\t\tz[i] = (double)rand() / RAND_MAX;\n","\t*x = z;\n","}\n"],"metadata":{"id":"ThfBjl_OiObI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["‚Ü© **Run...**"],"metadata":{"id":"hqggkk-ui5N_"}},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/lez7/conj_grad.cu  -o cojgrad -lcublas\n","!./cojgrad"],"metadata":{"id":"adoih_dPi5OA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vXUIQkZLCTcG"},"source":["# ‚úÖ cuRAND\n"]},{"cell_type":"markdown","source":["### Calcolo di PI greco col metodo Monte Carlo..."],"metadata":{"id":"EBj1BWfwjW2d"}},{"cell_type":"code","metadata":{"id":"-Y52R0d3CA50"},"source":["%%cuda_group_save --name \"PI_kernel_MC.cu\" --group \"lez7\"\n","\n","#include <stdio.h>\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <curand_kernel.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","\n","#define TRIALS_PER_THREAD 10000\n","#define BLOCKS  264\n","#define THREADS 264\n","#define PI 3.1415926535 // known value of pi\n","\n","float pi_mc_CPU(long trials) {\n","\tlong points_in_circle = 0;\n","\tfor (long i = 0; i < trials; i++) {\n","\t\tfloat x = rand() / (float) RAND_MAX;\n","\t\tfloat y = rand() / (float) RAND_MAX;\n","\t\tpoints_in_circle += (x * x + y * y <= 1.0f);\n","\t}\n","\treturn 4.0f * points_in_circle / trials;\n","}\n","\n","__global__ void pi_mc_GPU(float *estimate, curandState *states) {\n","\tunsigned int tid = threadIdx.x + blockDim.x * blockIdx.x;\n","\tint points_in_circle = 0;\n","\tcurand_init(tid, 0, 0, &states[tid]);\n","\tfor (int i = 0; i < TRIALS_PER_THREAD; i++) {\n","\t\tfloat x = curand_uniform(&states[tid]);\n","\t\tfloat y = curand_uniform(&states[tid]);\n","\t\tpoints_in_circle += (x * x + y * y <= 1.0f);\n","\t}\n","\testimate[tid] = 4.0f * points_in_circle / (float) TRIALS_PER_THREAD;\n","}\n","\n","/*\n"," * MAIN: MC method\n"," */\n","int main(void) {\n","\n","\tfloat host[BLOCKS * THREADS];\n","\tfloat *dev;\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// CPU procedure\n","\tfloat iStart = seconds();\n","\tfloat pi_cpu = pi_mc_CPU(THREADS * BLOCKS * TRIALS_PER_THREAD);\n","\tfloat iElaps = seconds() - iStart;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\", iElaps);\n","\tprintf(\"CPU estimate of PI = %f [error of %f]\\n\", pi_cpu, abs(pi_cpu - PI));\n","\n","\t// GPU procedure\n","\tcurandState *devStates;\n","\tcudaMalloc((void **) &dev, BLOCKS * THREADS * sizeof(float));\n","\tcudaMalloc((void **) &devStates, BLOCKS * THREADS * sizeof(curandState));\n","\tcudaEventRecord(start);\n","\tpi_mc_GPU<<<BLOCKS, THREADS>>>(dev, devStates);\n","  cudaEventRecord(stop);\n","\tcudaEventSynchronize(stop);\n","\tcudaMemcpy(host, dev, BLOCKS * THREADS * sizeof(float), cudaMemcpyDeviceToHost);\n","\tfloat pi_gpu = 0.0;\n","\tfor (int i = 0; i < BLOCKS * THREADS; i++)\n","\t\tpi_gpu += host[i];\n","\tpi_gpu /= (BLOCKS * THREADS);\n","\tfloat milliseconds = 0;\n","\tcudaEventElapsedTime(&milliseconds, start, stop);\n","\tprintf(\"\\nGPU elapsed time (curand Monte Carlo): %.5f (sec)\\n\", milliseconds / 1000);\n","\tprintf(\"GPU estimate of PI = %f [error of %f ]\\n\", pi_gpu, abs(pi_gpu - PI));\n","  printf(\"Speed-up           = %.0f\\n\", iElaps/milliseconds*1000);\n","\tcudaFree(dev);\n","\tcudaFree(devStates);\n","\treturn 0;\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["‚Ü© **Run...**"],"metadata":{"id":"aR6Ygx7SjII2"}},{"cell_type":"code","metadata":{"id":"0PSc9B9PDTWt"},"source":["!nvcc -arch=sm_75 src/lez7/PI_kernel_MC.cu  -o mc_PI\n","!./mc_PI"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["clacolo con host API..."],"metadata":{"id":"R7xacSVXj4yU"}},{"cell_type":"code","metadata":{"id":"eLcGSW8rqa9j"},"source":["%%cuda_group_save --name \"PI_host_MC.cu\" --group \"lez7\"\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <curand.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define TRIALS_PER_THREAD 10000\n","#define BLOCKS  264\n","#define THREADS 264\n","#define PI 3.1415926535 // known value of pi\n","\n","int main(void) {\n","\n","\tlong trials = THREADS * BLOCKS * TRIALS_PER_THREAD; // num points\n","\n","  printf(\"Number of random points in the square = %lu\\n\", trials);\n","\n","\tcurandGenerator_t gen;\n","\tfloat *X_d, *X, *Y_d, *Y ;\n","\n","\t// Allocate points on host\n","\tX = (float *) malloc(trials * sizeof(float));\n","  Y = (float *) malloc(trials * sizeof(float));\n","\n","\t/* Allocate n floats on device */\n","\tCHECK(cudaMalloc((void **)&X_d, trials * sizeof(float)));\n","  CHECK(cudaMalloc((void **)&Y_d, trials * sizeof(float)));\n","\n","\t// Create pseudo-random number generator\n","\tCHECK_CURAND(curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT));\n","\n","\t// Set seed\n","\tCHECK_CURAND(curandSetPseudoRandomGeneratorSeed(gen, 1234ULL));\n","\n","\t// Generate 2*n floats on device\n","\tCHECK_CURAND(curandGenerateUniform(gen, X_d, trials));\n","  CHECK_CURAND(curandGenerateUniform(gen, Y_d, trials));\n","\n","\t// Copy device memory to host\n","\tCHECK(cudaMemcpy(X, X_d, trials * sizeof(float), cudaMemcpyDeviceToHost));\n","  CHECK(cudaMemcpy(Y, Y_d, trials * sizeof(float), cudaMemcpyDeviceToHost));\n","\n","  // num of points within the circle\n","  ulong points_in_circle = 0;\n","  for (long i = 0; i < trials; i++)\n","\t\tpoints_in_circle += (X[i] * X[i] + Y[i] * Y[i] <= 1.0f);\n","\n","  // estimate PI\n","\tfloat pi = 4.0f * points_in_circle / (float)trials;\n","  printf(\"Estimate of PI = %f [error of %f]\\n\", pi, abs(pi - PI));\n","\n","\t// Cleanup\n","\tCHECK_CURAND(curandDestroyGenerator(gen));\n","\tCHECK(cudaFree(X_d));\n","  CHECK(cudaFree(Y_d));\n","  free(X);\n","\tfree(Y);\n","\treturn EXIT_SUCCESS;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["‚Ü© **Run...**"],"metadata":{"id":"lYkkVllwjsEV"}},{"cell_type":"code","metadata":{"id":"mfR471rze2p-"},"source":["!nvcc -arch=sm_75 src/lez7/PI_host_MC.cu -o mc_PI -lcurand\n","!./mc_PI"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Calcolo dell'area della campana di Gauss col metodo Monte Carlo..."],"metadata":{"id":"kLOic3BejhXx"}},{"cell_type":"markdown","source":["‚ÜòÔ∏è **TODO...**"],"metadata":{"id":"xLhhyZwhkM5X"}},{"cell_type":"code","metadata":{"id":"wPALm1BbkoSY"},"source":["%%cuda_group_save --name \"Gauss_MC.cu\" --group \"lez7\"\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <curand_kernel.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define TRIALS_PER_THREAD 10000\n","#define BLOCKS  264\n","#define THREADS 264\n","#define PI 3.1415926535 // known value of pi\n","\n","float Gauss_CPU(long trials, float a, float b, float max) {\n","\tlong s = 0;\n","\tfor (long i = 0; i < trials; i++) {\n","\t\tfloat x = (b-a)*(rand() / (float) RAND_MAX)+a;\n","\t\tfloat y = (rand() / (float) RAND_MAX);\n","\t\ts += (y <= expf(-x*x/2));\n","\t}\n","\treturn s / (float)trials;\n","}\n","\n","__global__ void Gauss_GPU(...) {\n","\n","\t// TODO\n","\n"," }\n","\n","int main(int argc, char *argv[]) {\n","\n","\tfloat host[BLOCKS * THREADS];\n","\tfloat *dev;\n","\tfloat a = -1;\n","\tfloat b = 2;\n","\tfloat max = 1.0f/sqrt(2*PI);\n","\tfloat A = (b-a)*max;\n","\tfloat P_true = 0.818594;\n","\n","\t// events to measure time\n","\tcudaEvent_t start, stop;\n","\tcudaEventCreate(&start);\n","\tcudaEventCreate(&stop);\n","\n","\t// CPU procedure\n","\tfloat iStart = seconds();\n","\tlong N = THREADS * BLOCKS * TRIALS_PER_THREAD;\n","\tfloat P_cpu = Gauss_CPU(N,a,b,max);\n","\tfloat iElaps = seconds() - iStart;\n","\tP_cpu = P_cpu*A;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\", iElaps);\n","\tprintf(\"CPU estimate of P = %f [error of %f]\\n\", P_cpu, abs(P_cpu - P_true));\n","\n","\t// GPU procedure\n","\n","\t// TODO\n","\n","\tprintf(\"GPU elapsed time: %.5f (sec)\\n\", seconds);\n","\tprintf(\"GPU estimate of P = %f [error of %f ]\\n\", P, abs(P - P_true));\n","\tprintf(\"Speedup = %f\\n\", iElaps/seconds);\n","\tcudaFree(dev);\n","\tcudaFree(devStates);\n","\treturn 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["‚Ü© **Run...**"],"metadata":{"id":"7LBEopdZk1db"}},{"cell_type":"code","metadata":{"id":"4Jm_7O2nk1dc"},"source":["!nvcc -arch=sm_75 src/lez7/Gauss_MC.cu -o Gauss_MC\n","!./Gauss_MC"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOFMQZAkjlLW"},"source":["# ‚úÖ cuFFT"]},{"cell_type":"code","metadata":{"id":"v9nRkLgeB10A"},"source":["%%cuda_group_save --name \"cufft.cu\" --group \"lez7\"\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cufft.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define BATCH 16\n","\n","/*\n"," * An example usage of the cuFFT library. This example performs a 1D forward\n"," * FFT.\n"," */\n","\n","int nprints = 30;\n","\n","/*\n"," * Create N fake samplings along the function cos(x). These samplings will be\n"," * stored as single-precision floating-point values.\n"," */\n","void generate_fake_samples(int N, float **out) {\n","\tint i;\n","\tfloat *result = (float *) malloc(sizeof(float) * N);\n","\tfloat delta = M_PI / 20.0;\n","\tfor (i = 0; i < N; i++)\n","\t\tresult[i] = cos(i * delta);\n","\t*out = result;\n","}\n","\n","void rect(uint N, float **out) {\n","\tfloat *r = (float *) calloc(N, sizeof(float));\n","\tfor (uint i = 0; i < N/100; ++i)\n","    r[i] = 1.0f;\n","\t*out = r;\n","}\n","\n","/*\n"," * Convert a real-valued vector r of length Nto a complex-valued vector.\n"," */\n","void real_to_complex(float *r, cufftComplex **complx, int N) {\n","\tint i;\n","\t(*complx) = (cufftComplex *) malloc(sizeof(cufftComplex) * N);\n","\n","\tfor (i = 0; i < N; i++) {\n","\t\t(*complx)[i].x = r[i];\n","\t\t(*complx)[i].y = 0;\n","\t}\n","}\n","\n","int main(int argc, char **argv) {\n","\n","\tint i;\n","\tint N = 1024*1024;\n","\tfloat *samples;\n","\tcufftHandle plan = 0;\n","\tcufftComplex *dComplexSamples, *complexSamples, *complexFreq;\n","\n","\t// Input Generation\n","\trect(N, &samples);\n","\n","  printf(\"Start computation...\\n\");\n","  float start = seconds();\n","\treal_to_complex(samples, &complexSamples, N);\n","\n","  complexFreq = (cufftComplex *) malloc(sizeof(cufftComplex) * N);\n","\n","\t// Setup the cuFFT plan\n","\tCHECK_CUFFT(cufftPlan1d(&plan, N, CUFFT_C2C, 1));\n","\n","\t// Allocate device memory\n","\tCHECK(cudaMalloc((void **)&dComplexSamples, sizeof(cufftComplex) * N));\n","\n","\t// Transfer inputs into device memory\n","\tCHECK(cudaMemcpy(dComplexSamples, complexSamples, sizeof(cufftComplex) * N, cudaMemcpyHostToDevice));\n","\n","\t// Execute a complex-to-complex 1D FFT\n","\tCHECK_CUFFT(cufftExecC2C(plan, dComplexSamples, dComplexSamples, CUFFT_FORWARD));\n","\n","\t// Retrieve the results into host memory\n","\tCHECK(cudaMemcpy(complexFreq, dComplexSamples, sizeof(cufftComplex) * N, cudaMemcpyDeviceToHost));\n","\n","  float elaps = seconds() - start;\n","\n","  printf(\"Elapsed time: %f (sec)\\n\", elaps);\n","\n","  // save FFT on a file\n","  printf(\"Save on file...\\n\");\n","  FILE *filePtr;\n","  filePtr = fopen(\"FFTdata.txt\",\"w\");\n","  for (i = 0; i < N; i++) {\n","    fprintf(filePtr, \"%.3g, %.5g\\n\", complexFreq[i].x, complexFreq[i].y);\n","  }\n","\n","\tfree(samples);\n","\tfree(complexSamples);\n","\tfree(complexFreq);\n","\n","\tCHECK(cudaFree(dComplexSamples));\n","\tCHECK_CUFFT(cufftDestroy(plan));\n","\treturn 0;\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["‚Ü© **Run...**"],"metadata":{"id":"YRtcUgZvmGKA"}},{"cell_type":"code","metadata":{"id":"wLxZjCx8bT3s"},"source":["!nvcc -arch=sm_75 src/lez7/cufft.cu -o fft -lcufft\n","!./fft"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPU4iiE7LT59"},"source":["# python code: read FFT data file and plot the FFT magnitude\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# read file\n","Xlist = []\n","Ylist = []\n","with open(\"FFTdata.txt\", \"r\") as f:\n","  for line in f.readlines():\n","    x,y = line.split(\",\")\n","    Xlist.append(float(x))\n","    Ylist.append(float(y))\n","\n","# compute magnitude\n","X = np.power(Xlist,2)\n","Y = np.power(Ylist,2)\n","F = np.sqrt(X+Y)\n","\n","# plot\n","plt.subplots(figsize=(10, 6))\n","plt.plot(F[:500])\n","plt.show()"],"execution_count":null,"outputs":[]}]}