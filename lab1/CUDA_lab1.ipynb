{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDA_lab1.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["9YGa6hXkx77o","XX4ILmhgLNUZ","zs_a5Vuimily"],"mount_file_id":"1IFQanBdBBUzqheWXiloaVlYrS_p2zjrL","authorship_tag":"ABX9TyOBq91IrCUhR72G/363RGdw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9YGa6hXkx77o"},"source":["# ‚ñ∂Ô∏è Google Colaboratory (colab)"]},{"cell_type":"markdown","metadata":{"id":"F-lZoo4TstJn"},"source":["[Colaboratory](https://research.google.com/colaboratory/faq.html) (or Colab) is a **free research tool** from *Google* for machine learning education and research built on top of [Jupyter Notebook](https://jupyter.org/). It requires no setup and runs entirely in the **cloud**. In Google Colab you can write, execute, save and share your Jupiter Notebooks. You access powerful computing resources like **TPUs** and **GPUs** all for free through your browser. All major Python libraries like **Tensorflow**, **Scikit-learn**, **PyTorch**, **Pandas**, etc. are pre-installed. Google Colab requires no configuration, you only need a **Google Account** and then you are good to go. Your notebooks are stored in your **Google Drive**, or can be loaded from **GitHub**. Colab notebooks can be shared just as you would with Google Docs or Sheets. Simply click the Share button at the top right of any Colab notebook, or follow these Google Drive file sharing instructions.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zfPMRBrqzjjb"},"source":["##Upload/download files\n","\n","\n","Once you open a **Google Colab notebook**, it creates a **virtual machine** instance on a Google Cloud Platform. To **upload** files from your local machine to Colab virtual storage, use `upload` option from the left sidebar. To **download** files from Colab's virtual storage to your local machine, right-click on a file and then select `Download`. You can also mount your google drive: once you click on **MOUNT DRIVE** in the left sidebar, it will insert a code cell into your notebook that you'll need to run to mount your google drive (it will ask for your authorization). Another way to download files (without mounting a google drive) is to use a `!gdown` or `!wget` commands (more details in the [Shell commands](#scrollTo=JrF12-bqPKPm) section)<br><br>\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1CRjolVrVbEboNPLVVw-c_AtsBBcSou1Z\" width=800 px><br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ZvWtrdMfxQD8"},"source":["## Notebook rules\n","\n","Some basic notebook rules:\n","\n","\n","1.   Click inside a cell with code and press SHIFT+ENTER (or click \"PLAY\" button) to execute it.\n","2.   Re-executing a cell will reset it (any input will be lost).\n","3.   Execute cells TOP TO BOTTOM.\n","5. Notebooks are saved to your Google Drive \n","6. Mount your Google Drive to have a direct access from a notebook to the files stored in the drive (this includes Team Drives).\n","7. If using Colab's virtual storage only, all the uploaded/stored files will get deleted when a runtime is recycled."]},{"cell_type":"markdown","metadata":{"id":"ulev4sV3wc-T"},"source":["## Shell commands"]},{"cell_type":"markdown","metadata":{"id":"fS67zRIavQtS"},"source":["The command `uname` displays the information about the system.\n","\n","* **-a option:** It prints all the system information in the following order: Kernel name, network node hostname, \n","kernel release date, kernel version, machine hardware name, hardware platform, operating system\n","."]},{"cell_type":"code","metadata":{"id":"PT7Umr53u2Qz"},"source":["!uname -a && cat /etc/*release"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i1h8YWW1RzEN"},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7qM1A-h_mnC_"},"source":["If you play with IPython's shell commands for a while, you might notice that you cannot use `!cd` to navigate the filesystem:"]},{"cell_type":"code","metadata":{"id":"u1R7Ci1nml4P"},"source":["! cd /content/drive/MyDrive/GPU_computing/github/GPUcomputing/\n","! pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7wt_VrzenkgM"},"source":["The reason is that shell commands in the notebook are executed in a temporary subshell. If you'd like to change the working directory in a more enduring way, you can use the `%cd` **magic command**:"]},{"cell_type":"code","metadata":{"id":"ZS7RrfYvfceJ"},"source":["% cd /content/drive/MyDrive/GPU_computing/github/GPUcomputing/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iseDMLyXT7wG"},"source":["!ls -la lab1/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWIzTy57JLBW"},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9PmBZql0ow4"},"source":["# ‚ñ∂Ô∏è CUDA zone"]},{"cell_type":"markdown","metadata":{"id":"Ur7-3SF3h4vy"},"source":["## How to use accelerated hardware\n","\n","To change hardware runtime you just have to navigate from `Runtime -> change runtime` type and select your preferred accelerated hardware type **GPU** or **TPU**.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nTRXba1Msgq2"},"source":["## NVIDIA System Management Interface (nvidia-smi) \n","\n","The NVIDIA System Management Interface (**`nvidia-smi`**) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the **management** and **monitoring** of NVIDIA GPU devices. \n","\n","This utility allows administrators to query GPU device state and with the appropriate privileges, permits administrators to modify GPU device state.  It is targeted at the TeslaTM, GRIDTM, QuadroTM and Titan X product, though limited support is also available on other NVIDIA GPUs.\n","\n","For more details, please refer to the **`nvidia-smi`** documentation ([doc](http://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf))"]},{"cell_type":"code","metadata":{"id":"NlXMCnBVBkeE"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9nxmU0pZJE7R"},"source":["How to remove cuda completely from ubuntu... and install another version"]},{"cell_type":"code","metadata":{"id":"MLlLB3gXDKBr"},"source":["!apt-get --purge remove cuda nvidia* libnvidia-*\n","!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n","!apt-get remove cuda-*\n","!apt autoremove\n","!apt-get update"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XX4ILmhgLNUZ"},"source":["## CUDA Toolkit\n","Develop, Optimize and Deploy GPU-Accelerated Apps\n","The NVIDIA¬Æ CUDA¬Æ Toolkit provides a development environment for creating high performance GPU-accelerated applications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers. The toolkit includes GPU-accelerated libraries, debugging and optimization tools, a C/C++ compiler, and a runtime library to build and deploy your application on major architectures including x86, Arm and POWER.\n","\n","Using built-in capabilities for distributing computations across multi-GPU configurations, scientists and researchers can develop applications that scale from single GPU workstations to cloud installations with thousands of GPUs.\n","[cuda-toolkit](https://developer.nvidia.com/cuda-toolkit)\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"38jSDwugDYKB"},"source":["!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\n","!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\n","!wget https://developer.download.nvidia.com/compute/cuda/11.2.1/local_installers/cuda-repo-ubuntu1804-11-2-local_11.2.1-460.32.03-1_amd64.deb\n","!dpkg -i cuda-repo-ubuntu1804-11-2-local_11.2.1-460.32.03-1_amd64.deb\n","!apt-key add /var/cuda-repo-ubuntu1804-11-2-local/7fa2af80.pub\n","!apt-get update\n","!apt-get -y install cuda"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vifkJTru0yOg"},"source":["!ls -la /usr/local"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OR8MTAveVNmu"},"source":["Now you can check your CUDA installation by running the command given below :\n"]},{"cell_type":"code","metadata":{"id":"p9RIwaPbVQHV"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iVV0CidyVeqU"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","*Usage*:\n","\n","\n","*   Load Extension `%load_ext nvcc_plugin`\n","*   Mark a cell to be treated as cuda cell\n","`%%cuda --name example.cu --compile false`\n","\n","**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n","\n","*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"X1EeyR1jBnWR"},"source":["!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7HcKDuAB-CO"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile /root/.bashrc\n","\n","# If not running interactively, don't do anything\n","[ -z \"$PS1\" ] && return\n","\n","# don't put duplicate lines in the history. See bash(1) for more options\n","# ... or force ignoredups and ignorespace\n","HISTCONTROL=ignoredups:ignorespace\n","\n","# append to the history file, don't overwrite it\n","shopt -s histappend\n","\n","# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)\n","HISTSIZE=10000\n","HISTFILESIZE=20000\n","\n","# check the window size after each command and, if necessary,\n","# update the values of LINES and COLUMNS.\n","shopt -s checkwinsize\n","\n","# make less more friendly for non-text input files, see lesspipe(1)\n","[ -x /usr/bin/lesspipe ] && eval \"$(SHELL=/bin/sh lesspipe)\"\n","\n","PS1='\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ '\n","\n","# enable color support of ls and also add handy aliases\n","if [ -x /usr/bin/dircolors ]; then\n","    test -r ~/.dircolors && eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\"\n","    alias ls='ls --color=auto'\n","    #alias dir='dir --color=auto'\n","    #alias vdir='vdir --color=auto'\n","\n","    alias grep='grep --color=auto'\n","    alias fgrep='fgrep --color=auto'\n","    alias egrep='egrep --color=auto'\n","fi\n","\n","# some more ls aliases\n","alias ll='ls -lF'\n","alias la='ls -A'\n","alias l='ls -CF'\n","\n","# path setup\n","export PATH=\"/usr/local/cuda/bin:$PATH\""],"metadata":{"id":"GJXznz-0qs7f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"twcqMEhVVMr8"},"source":["## Save and compile\n","\n","To save the `.cu` file and compile it using the command-line syntax *define* the the magic cell:\n","```\n","%%cuda --name filename.cu \n","```\n","The source file will be saved under the directory `src/`\n","\n","Otherwise, you can use standard the macig command:\n","```\n","%%writefile <path-to-file->/filename.cu \n","```"]},{"cell_type":"markdown","source":["# ‚ñ∂Ô∏è VS Code on Colab"],"metadata":{"id":"zs_a5Vuimily"}},{"cell_type":"code","source":["#@title Colab-ssh tunnel\n","#@markdown Execute this cell to open the ssh tunnel. Check [colab-ssh documentation](https://github.com/WassimBenzarti/colab-ssh) for more details.\n","\n","# Install colab_ssh on google colab\n","!pip install colab_ssh --upgrade\n","\n","from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n","ssh_tunnel_password = \"gpu\" #@param {type: \"string\"}\n","launch_ssh_cloudflared(password=ssh_tunnel_password)\n","\n","# Optional: if you want to clone a Github or Gitlab repository\n","repository_url=\"https://github.com/giulianogrossi/GPUcomputing\" #@param {type: \"string\"}\n","init_git_cloudflared(repository_url)"],"metadata":{"cellView":"form","id":"BCf9JxqphHAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ‚úÖ Hello World!"],"metadata":{"id":"mB94Ce6kViOj"}},{"cell_type":"code","metadata":{"id":"RlbVvBaXCHBs"},"source":["%%cuda --name hello.cu\n","#include <stdio.h>\n","#include <iostream>\n","\n","using namespace std;\n","\n","__global__ void helloFromGPU (void) {\n","    printf(\"Hello World from GPU!\\n\");\n","}\n","\n","int main(void) {\n","    // # hello from GPU \n","    cout << \"Hello World from CPU!\" << endl;\n","    cudaSetDevice(1);\n","    helloFromGPU <<<1, 10>>>();\n","    cudaDeviceSynchronize();\n","    return 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OURqX6K2isWG"},"source":["compile..."]},{"cell_type":"code","metadata":{"id":"JjFZp49LcO-F"},"source":["%%shell\n","\n","nvcc -arch=sm_37 src/hello.cu -o hello"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Hvii50CGGfP"},"source":["and execute..."]},{"cell_type":"code","metadata":{"id":"kMEGfjJMcX_e"},"source":["%%shell\n","\n","./hello"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c9DOGMoaV-rq"},"source":["##Edit, compile & exec\n","\n","With the magic cell \n","```\n","%cu\n","```\n","you can edit, compile (only one file at a time) and execute direcly the code by executing the cell..."]},{"cell_type":"code","metadata":{"id":"6DxzZ-xZWMoX"},"source":["%%cu \n","#include <stdio.h>\n","\n","__global__ void helloFromGPU (void) {\n","    printf(\"Hello World from GPU!\\n\");\n","}\n","\n","int main(void) {\n","    // # hello from GPU\n","    printf(\"Hello World from CPU!\\n\");\n","    cudaSetDevice(1);\n","    helloFromGPU <<<1,10>>>();\n","    cudaDeviceSynchronize();\n","    return 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4bll8pe7Fj3y"},"source":["#  ‚úÖ MQDB: Matrici quadrate diagonali a blocchi"]},{"cell_type":"code","metadata":{"id":"KMp_CpISiVvH"},"source":["#@title working directory: **MQDB-CUDA**\n","%mkdir -p MQDB\n","%ls -la"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Libreria MQDB: collezione di funzioni per oerare sui tipi MQDB "],"metadata":{"id":"humax_OpcNhe"}},{"cell_type":"code","metadata":{"id":"mbG20QCi7G6T"},"source":["%%writefile MQDB/mqdb.h\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <string.h>\n","#include <math.h>\n","#include <sys/time.h>\n","\n","#ifndef MQDB_H\n","#define MQDB_H\n","\n","#define randu() ((float)rand() / (float) RAND_MAX)\n","#define abs(x) ((x)<0 ? (-x) : (x))\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","typedef struct MQDB {\n","\tchar desc[100];   // description\n","\tint nBlocks;      // num. of blocks\n","\tint *blkSize;     // block dimensions\n","\tfloat *elem;       // elements in row-major order\n","\tulong nElems;     // actual number of elements\n","} mqdb;\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","// # function prototypes #\n","int genRandDims(mqdb*, uint, uint);\n","void fillBlocks(mqdb*, uint, uint, char, float);\n","mqdb mqdbConst(uint, uint, uint, float);\n","void mqdbProd(mqdb, mqdb, mqdb);\n","void matProd(mqdb, mqdb, mqdb);\n","void checkResult(mqdb, mqdb);\n","void mqdbDisplay(mqdb);\n","\n","inline double seconds() {\n","    struct timeval tp;\n","    struct timezone tzp;\n","    int i = gettimeofday(&tp, &tzp);\n","    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n","}\n","\n","#endif"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eiDq208h8qmn"},"source":["%%writefile MQDB/mqdb.cpp\n","\n","#include \"mqdb.h\"\n","\n","/**\n"," * random generate block dimensions\n"," */\n","int genRandDims(mqdb *M, uint n, uint k) {\n","\n","\tif (n == 0 || k == 0 || k > n) {\n","\t\tprintf(\"error: n,k must be positive and n > k!\\n\");\n","\t\treturn(-1);\n","\t}\n","\t// random generation of block sizes\n","\tM->blkSize = (int *) malloc(k * sizeof(int));\n","\tint sum = 0;\n","\tint r;\n","\tfloat mu = 2.0f * (float) n / (float) k;\n","\tfor (int i = 0; i < k - 1; i++) {\n","\t\t// expected value E[block_size] = n/k\n","\t\twhile ((r = round(mu * randu())) > n - sum - k + i + 1);\n","\t\tif (!r)\n","\t\t\tr += 1;\n","\t\tM->blkSize[i] = r;\n","\t\tsum += r;\n","\t}\n","\tM->blkSize[k - 1] = n - sum;\n","\treturn(0);\n","}\n","\n","/**\n"," * # fill blocks either random or constant #\n"," */\n","void fillBlocks(mqdb *M, uint n, uint k, char T, float c) {\n","\t//mat size n*n\n","\tM->elem = (float *) calloc(n * n, sizeof(float));\n","\tM->nElems = 0;\n","\tint offset = 0;\n","\t// # loop on blocks #\n","\tfor (int i = 0; i < k; i++) {\n","\t\tfor (int j = 0; j < M->blkSize[i]; j++)\n","\t\t\tfor (int k = 0; k < M->blkSize[i]; k++)\n","\t\t\t\tif (T == 'C')  \t    // const fill mat entries\n","\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = c;\n","\t\t\t\telse if (T == 'R') \t// random fill mat entries\n","\t\t\t\t\tM->elem[offset * n + j * n + k + offset] = randu();\n","\t\toffset += M->blkSize[i];\n","\t\tM->nElems += M->blkSize[i]*M->blkSize[i];\n","\t}\n","\t// # set description #\n","\tsprintf(M->desc, \"Random mqdb:  mat. size = %d, num. blocks = %d, blk sizes: \",n,k);\n","}\n","\n","/**\n"," * rand_gen_mqdb: mqdb  type returned\n"," *                n     square matrix size\n"," *                k     number of blocks\n"," *                seed  seed for random generator\n"," */\n","mqdb genRandMat(unsigned n, unsigned k, unsigned seed) {\n","\tmqdb M;\n","\tsrand(seed);\n","\tgenRandDims(&M, n, k);\n","\tM.nBlocks = k;\n","\n","\t// # random fill mat entries #\n","\tfillBlocks(&M, n, k, 'R', 0.0);\n","\n","\treturn M;\n","}\n","\n","/**\n"," * const_mqdb: mqdb     is the type returned\n"," *                n     is the square matrix size\n"," *                k     is the number of blocks\n"," *                seed  is the seed for random generator\n"," *                c   \tis the constant value assigned\n"," */\n","mqdb mqdbConst(uint n, uint k, uint seed, float c) {\n","\tmqdb M;\n","\tsrand(seed);\n","\tgenRandDims(&M, n, k);\n","\tM.nBlocks = k;\n","\n","\t// fill mat entries with a constant\n","\tfillBlocks(&M, n, k, 'C', c);\n","\n","\treturn M;\n","}\n","\n","/*\n"," * standard (naive) matrix product on host\n"," */\n","void matProd(mqdb A, mqdb B, mqdb C) {\n","\tint n = 0;\n","\tfor (uint i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];\n","\n","\tfor (uint r = 0; r < n; r++)\n","\t\tfor (uint c = 0; c < n; c++) {\n","\t\t\tdouble sum = 0;\n","\t\t\tfor (uint l = 0; l < n; l++){\n","\t\t\t\tdouble a = A.elem[r * n + l];\n","\t\t\t\tdouble b = B.elem[l * n + c];\n","\t\t\t\tsum += a*b;\n","\t\t\t}\n","\t\t\tC.elem[r * n + c] = (float)sum;\n","\t\t}\n","}\n","\n","/*\n"," * elementwise comparison between two mqdb\n"," */\n","void checkResult(mqdb A, mqdb B) {\n","\tdouble epsilon = 1.0E-8;\n","\tbool match = 1;\n","\tint n = 0;\n","\tfor (int i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];\n","\tfor (int i = 0; i < n * n; i++) {\n","\t\tif (fabs(A.elem[i] - B.elem[i]) > epsilon) {\n","\t\t\tmatch = 0;\n","\t\t\tprintf(\"   * Arrays do not match!\\n\");\n","\t\t\tprintf(\"     gpu: %2.2f,  host: %2.2f at current %d\\n\", A.elem[i],\n","\t\t\t\t\tB.elem[i], i);\n","\t\t\tbreak;\n","\t\t}\n","\t}\n","\tif (match)\n","\t\tprintf(\"   Arrays match\\n\\n\");\n","}\n","/*\n"," * print mqdb\n"," */\n","void mqdbDisplay(mqdb M) {\n","\tint n = 0;\n","\tprintf(\"%s\", M.desc);\n","\tfor (int j = 0; j < M.nBlocks; j++) {\n","\t\tprintf(\"%d  \", M.blkSize[j]);\n","\t\tn += M.blkSize[j];\n","\t}\n","\tprintf(\"\\n\");\n","\tfor (int j = 0; j < n * n; j++) {\n","\t\tif (M.elem[j] == 0)\n","\t\t\tprintf(\"------\");\n","\t\telse\n","\t\t\tprintf(\"%5.2f \", M.elem[j]);\n","\t\tif ((j + 1) % n == 0)\n","\t\t\tprintf(\"\\n\");\n","\t}\n","\tprintf(\"\\n\");\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üî¥ TODO"],"metadata":{"id":"BWkjCoM0ckzF"}},{"cell_type":"markdown","source":["Sviluppare una funzione per effettuare il prodotto ottimizzato (ristretto ai soli blocchi sulla diagonale) tra due matrici $C=A*B$ ti tipo MQDB, aventi uguale dimensione (stesso lato $n$ e ugual dimensione $n_i$ dei $k$ blocchi $k_i$ sulla diagonale)"],"metadata":{"id":"_QMShprZETnd"}},{"cell_type":"code","source":["%%writefile MQDB/prod_mqdb.cpp\n","\n","#include \"mqdb.h\"\n","\n","/*\n"," * product between mqdb matrices restricted to blocks\n"," */\n","void mqdbProd(mqdb A, mqdb B, mqdb C) {\n","\tuint n = 0;\n","\tfor (uint i = 0; i < A.nBlocks; i++)\n","\t\tn += A.blkSize[i];                    // mat dim\n","\tint k = A.nBlocks;                      // num blks\n","\tint dl = 0;                             // blk left bound\n","\tint dr = 0;                             // blk left bound\n","\tfor (uint i = 0; i < k; i++) {          // loop on blks\n","\t\tdr += A.blkSize[i];                   // blk right bound\n","\t\tfor (uint r = dl; r < dr; r++) {      // scan block rows\n","\t\t\tfor (uint c = dl; c < dr; c++) {    // scan block cols\n","\t\t\t\tfloat s = 0;\n","\t\t\t\tfor (uint l = dl; l < dr; l++)\n","\t\t\t\t\ts += A.elem[r*n + l] * B.elem[c + l * n];\n","\t\t\t\tC.elem[r*n + c] = s;\n","\t\t\t}\n","\t\t}\n","\t\tdl = dr;\n","\t}\n","}"],"metadata":{"id":"BtdrHhgOcoJI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Main"],"metadata":{"id":"1CSpZ6wplPmy"}},{"cell_type":"code","metadata":{"id":"r19AgzDRBJh3"},"source":["%%writefile MQDB/main.cpp\n","#include <sys/time.h>\n","#include \"mqdb.h\"\n","\n","/*\n"," * main function\n"," */\n","int main(void) {\n","\tuint n = 2*1024;      // matrix size\n","  uint k = 10;          // num of blocks\n","\tmqdb A, B, C, C1;     // mqdb host matrices\n","\n","\t// # fill in #\n","\tA = mqdbConst(n, k, 10, 1);\n","\tB = mqdbConst(n, k, 10, 1);\n","\tC = mqdbConst(n, k, 10, 1);\n","\tC1 = mqdbConst(n, k, 10, 1);\n","\n","\tulong nBytes = n * n * sizeof(float);\n","\tulong kBytes = k * sizeof(uint);\n","\tprintf(\"Memory size required = %.1f (MB)\\n\",(float)nBytes/(1024.0*1024.0));\n","\n","\tprintf(\"CPU mat product...\\n\");\n","\tdouble start = seconds();\n","  matProd(A, B, C);\n","\tdouble CPUTime = seconds() - start;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n","\n","  printf(\"CPU MQDB product...\\n\");\n","\tstart = seconds();\n","  mqdbProd(A, B, C1);\n","\tCPUTime = seconds() - start;\n","\tprintf(\"CPU elapsed time: %.5f (sec)\\n\\n\", CPUTime);\n","\n","\t// check result\n","\tcheckResult(C, C1);\n"," \n","\treturn 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kWihzIB84j1"},"source":["# Compilazione ed esecuzione\n","!g++ MQDB/prod_mqdb.cpp MQDB/main.cpp MQDB/mqdb.cpp -o main\n","!./main"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Report\n","\n","Riportare i tempi di esecuzione per \n","\n","$k = 10$\n","* n = 1024, time = \n","* n = 2048, time = \n","* n = 4096, time = \n","\n","$k = 20$\n","* n = 1024, time = \n","* n = 2048, time = \n","* n = 4096, time = "],"metadata":{"id":"JrC7365ckKJ6"}},{"cell_type":"code","source":[""],"metadata":{"id":"NQT8OVjhlDJA"},"execution_count":null,"outputs":[]}]}