{"cells":[{"cell_type":"markdown","id":"cd16b39b","metadata":{"id":"cd16b39b"},"source":["---\n","# **LAB 9 - NN in CUDA Pytorch**\n","---"]},{"cell_type":"markdown","id":"-_i3qX0HhLrV","metadata":{"id":"-_i3qX0HhLrV"},"source":["# ‚ñ∂Ô∏è CUDA setup"]},{"cell_type":"code","execution_count":null,"id":"JZS1v474hLrW","metadata":{"id":"JZS1v474hLrW"},"outputs":[],"source":["!nvcc --version"]},{"cell_type":"code","execution_count":null,"id":"TWZ7N-4OhLrW","metadata":{"id":"TWZ7N-4OhLrW"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"id":"xSoLaRWchLrX","metadata":{"id":"xSoLaRWchLrX"},"outputs":[],"source":["!pip install numba-cuda==0.4.0"]},{"cell_type":"code","execution_count":null,"id":"iTq5M1SfhLrX","metadata":{"id":"iTq5M1SfhLrX"},"outputs":[],"source":["from numba import config\n","config.CUDA_ENABLE_PYNVJITLINK = 1"]},{"cell_type":"markdown","id":"32aab92c","metadata":{"id":"32aab92c"},"source":["# üêç Pytorch basic"]},{"cell_type":"code","execution_count":null,"id":"043af3e4","metadata":{"id":"043af3e4"},"outputs":[],"source":["import torch\n","torch.__version__"]},{"cell_type":"code","execution_count":null,"id":"da1e673b","metadata":{"id":"da1e673b"},"outputs":[],"source":["x = torch.rand(2, 3)\n","print(x)\n","print(x.dtype)"]},{"cell_type":"code","execution_count":null,"id":"7e2b5802","metadata":{"id":"7e2b5802"},"outputs":[],"source":["x = torch.ones((5, 3), dtype=torch.double)\n","print(x)\n"]},{"cell_type":"code","execution_count":null,"id":"1de59c01","metadata":{"id":"1de59c01"},"outputs":[],"source":["# Vector\n","vector = torch.tensor([7, 7])\n","vector"]},{"cell_type":"code","execution_count":null,"id":"27dd4814","metadata":{"id":"27dd4814"},"outputs":[],"source":["# Matrix\n","matrix = torch.tensor([[7, 8],\n","                      [9, 10]])\n","matrix"]},{"cell_type":"code","execution_count":null,"id":"62efbf9b","metadata":{"id":"62efbf9b"},"outputs":[],"source":["x = torch.arange(10).reshape(2, 5)\n","x.shape\n","\n","torch.Size([2, 5])"]},{"cell_type":"code","execution_count":null,"id":"1042cd76","metadata":{"id":"1042cd76"},"outputs":[],"source":["points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n","points.storage()"]},{"cell_type":"code","execution_count":null,"id":"ebfd61cd","metadata":{"id":"ebfd61cd"},"outputs":[],"source":["r = (torch.rand(2, 2) - 0.5) * 2 # values between -1 and 1\n","print('A random matrix, r:')\n","print(r)\n","\n","# Common mathematical operations are supported:\n","print('\\nAbsolute value of r:')\n","print(torch.abs(r))\n","\n","# ...as are trigonometric functions:\n","print('\\nInverse sine of r:')\n","print(torch.asin(r))\n","\n","# ...and linear algebra operations like determinant and singular value decomposition\n","print('\\nDeterminant of r:')\n","print(torch.det(r))\n","print('\\nSingular value decomposition of r:')\n","print(torch.svd(r))\n","\n","# ...and statistical and aggregate operations:\n","print('\\nAverage and standard deviation of r:')\n","print(torch.std_mean(r))\n","print('\\nMaximum value of r:')\n","print(torch.max(r))\n"]},{"cell_type":"code","execution_count":null,"id":"d4082c31","metadata":{"id":"d4082c31"},"outputs":[],"source":["a = torch.ones(3,1)\n","b = torch.ones(1,3)\n","c = torch.ones(2, 1, 1)\n","print(f\"shapes: a: {a.shape}, b: {b.shape}, c: {c.shape}\")\n","d = a + b\n","print(\"d = a + b:\", d.shape)\n","e = c * d\n","print(\"e = c * d:\", e.shape)"]},{"cell_type":"markdown","id":"b8589b63","metadata":{"id":"b8589b63"},"source":["# üêç Pytorch on GPU"]},{"cell_type":"code","execution_count":null,"id":"6559e0fb","metadata":{"id":"6559e0fb"},"outputs":[],"source":["import torch\n","# Check CUDA availability\n","print(torch.cuda.is_available())\n","# Get the current CUDA device\n","print(torch.cuda.current_device())\n","# Get the name of the current CUDA device\n","print(torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":null,"id":"d96893fa","metadata":{"id":"d96893fa"},"outputs":[],"source":["# Move a tensor to GPU\n","x = torch.tensor([1, 2, 3])\n","x_gpu = x.to('cuda')\n","print(x_gpu)"]},{"cell_type":"code","execution_count":null,"id":"8ab68c4f","metadata":{"id":"8ab68c4f"},"outputs":[],"source":["import torch\n","x = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')\n","print(x)"]},{"cell_type":"code","execution_count":null,"id":"729b9c80","metadata":{"id":"729b9c80"},"outputs":[],"source":["cuda = torch.device('cuda')     # Default CUDA device\n","cuda0 = torch.device('cuda:0')\n","print(cuda0)  # device(type='cuda', index=0)\n","cuda2 = torch.device('cuda:1')  # GPU 2 (these are 0-indexed)\n","print(cuda2)  # device(type='cuda', index=2)\n","\n","x = torch.tensor([1., 2.], device=cuda0)\n","print(x.device)  # device(type='cuda', index=0)\n","# x.device is device(type='cuda', index=0)\n","y = torch.tensor([1., 2.]).cuda()\n","print(y.device)  # device(type='cuda', index=0)\n","# y.device is device(type='cuda', index=0)\n","\n","with torch.cuda.device(0):\n","\t# allocates a tensor on GPU 1\n","\ta = torch.tensor([1., 2.], device=cuda)\n","\n","\t# transfers a tensor from CPU to GPU 1\n","\tb = torch.tensor([1., 2.]).cuda()\n","\t# a.device and b.device are device(type='cuda', index=1)\n","\n","\t# You can also use ``Tensor.to`` to transfer a tensor:\n","\tb2 = torch.tensor([1., 2.]).to(device=cuda)\n","\t# b.device and b2.device are device(type='cuda', index=1)\n","\n","\tc = a + b\n","\t# c.device is device(type='cuda', index=1)\n","\n","\tz = x + y\n","\t# z.device is device(type='cuda', index=0)\n"]},{"cell_type":"code","execution_count":null,"id":"766e36cc","metadata":{"id":"766e36cc"},"outputs":[],"source":["# Let's do some matrix multiplication on the CPU first\n","a_full = torch.randn(10240, 10240, dtype=torch.double)\n","b_full = torch.randn(10240, 10240, dtype=torch.double)\n","\n","ab_full = a_full @ b_full # takes 280.110 ms on GA100"]},{"cell_type":"markdown","id":"3ae441ca","metadata":{"id":"3ae441ca"},"source":["* TF32 (TensorFloat-32) is a precision mode that allows for faster matrix multiplications on NVIDIA Ampere and later GPUs.\n","* It uses 19 bits for the mantissa instead of the usual 23 bits in FP32, which can lead to faster computations with a small loss in precision.\n","* This is particularly useful for deep learning workloads where the precision loss is often acceptable.\n","* The following code demonstrates the use of TF32 in PyTorch for matrix multiplication.\n","* Ensure that TF32 is enabled for matrix multiplication"]},{"cell_type":"code","execution_count":null,"id":"aeaf45b4","metadata":{"id":"aeaf45b4"},"outputs":[],"source":["# Let's do some matrix multiplication on the GPU\n","a_full = torch.randn(10240, 10240, dtype=torch.double, device='cuda')\n","b_full = torch.randn(10240, 10240, dtype=torch.double, device='cuda')\n","ab_full = a_full @ b_full\n","mean = ab_full.abs().mean()  # 80.7277\n","\n","a = a_full.float()\n","b = b_full.float()\n","\n","start_event = torch.cuda.Event(enable_timing=True)\n","end_event = torch.cuda.Event(enable_timing=True)\n","# Do matmul at TF32 mode.\n","torch.backends.cuda.matmul.allow_tf32 = True\n","start_event.record()\n","ab_tf32 = a @ b  # takes 40.432 ms on GA100\n","end_event.record()\n","torch.cuda.synchronize()  # Wait for the events to be recorded!\n","elapsed_time_ms = start_event.elapsed_time(end_event)\n","print(f'TF32 matmul took {elapsed_time_ms:.3f} ms')\n","error = (ab_tf32 - ab_full).abs().max()  # 0.1747\n","relative_error = error / mean  # 0.0022\n","print(f'Max error: {error:.4f}, Relative error: {relative_error:.6f}')\n","\n","# Do matmul with TF32 disabled.\n","torch.backends.cuda.matmul.allow_tf32 = False\n","start_event.record()\n","ab_fp32 = a @ b  # takes 280.110 ms on GA100\n","end_event.record()\n","torch.cuda.synchronize()  # Wait for the events to be recorded!\n","elapsed_time_ms = start_event.elapsed_time(end_event)\n","print(f'TF32 matmul took {elapsed_time_ms:.3f} ms')\n","error = (ab_fp32 - ab_full).abs().max()  # 0.0031\n","relative_error = error / mean  # 0.000039\n","print(f'Max error: {error:.4f}, Relative error: {relative_error:.6f}')\n","\n"]},{"cell_type":"markdown","id":"c997af7d","metadata":{"id":"c997af7d"},"source":["# üêç Linear model"]},{"cell_type":"code","execution_count":null,"id":"8d4cf1db","metadata":{"id":"8d4cf1db"},"outputs":[],"source":["import torch\n","\n","t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n","t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n","t_c = torch.tensor(t_c)\n","t_u = torch.tensor(t_u)\n","\n","# parameters of the model\n","w = torch.ones(())\n","b = torch.zeros(())\n","\n","# Let's define a model that predicts Celsius from unknown\n","def model(x, w, b):\n","   return w * x + b\n","\n","# Let's define the loss function that measures the difference between\n","def loss_fn(y1, y2):\n","\tsquared_diffs = 0.5 * (y1 - y2)**2\n","\treturn squared_diffs.mean()\n","\n","# Let's compute the predictions and the loss\n","t_p = model(t_u, w, b)\n","loss = loss_fn(t_p, t_c)\n","\n","# initial values\n","w = torch.ones(1)\n","b = torch.zeros(1)\n","print(f\"w: {w}, b: {b}\")\n","print(f\"shapes: w: {w.shape}, b: {b.shape}\")\n","t_p = model(t_u, w, b)\n","print(t_p)"]},{"cell_type":"code","execution_count":null,"id":"1175b7bf","metadata":{"id":"1175b7bf"},"outputs":[],"source":["import math\n","\n","delta = 0.1\n","\n","loss_rate_of_change_w = \\\n","    (loss_fn(model(t_u, w + delta, b), t_c) -\n","     loss_fn(model(t_u, w - delta, b), t_c)) / (2.0 * delta)\n","learning_rate = 1e-2\n","w = w - learning_rate * loss_rate_of_change_w\n","\n","loss_rate_of_change_b = \\\n","    (loss_fn(model(t_u, w, b + delta), t_c) -\n","     loss_fn(model(t_u, w, b - delta), t_c)) / (2.0 * delta)\n","b = b - learning_rate * loss_rate_of_change_b\n","\n","def dloss_fn(t_p, t_c):\n","    dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)  # <1>\n","    return dsq_diffs\n","\n","def dmodel_dw(t_u, w, b):\n","    return t_u\n","def dmodel_db(t_u, w, b):\n","    return 1.0\n","\n","def grad_fn(t_u, t_c, t_p, w, b):\n","    dloss_dtp = dloss_fn(t_p, t_c)\n","    dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n","    dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n","    return torch.stack([dloss_dw.sum(), dloss_db.sum()])  # <1>\n","\n","# Let's define a training loop that will train the model\n","def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n","\tfor epoch in range(1, n_epochs + 1):\n","\t\tw, b = params\n","\n","\t\tt_p = model(t_u, w, b)  # <1>\n","\t\tloss = loss_fn(t_p, t_c)\n","\t\tgrad = grad_fn(t_u, t_c, t_p, w, b)  # <2>\n","\n","\t\tparams = params - learning_rate * grad\n","\t\tN = round(math.sqrt(n_epochs))\n","\t\tif not (epoch % N):\n","\t\t\tprint('Epoch %d, Loss %f' % (epoch, float(loss))) # <3>\n","\n","\treturn params\n","\n","\n","# Let's train the model using the training loop\n","lr = 1e-2\n","params = training_loop(\tn_epochs = 100,\n","\tlearning_rate = lr,\n","\tparams = torch.tensor([1.0, 0.0]),\n","\tt_u = t_u, t_c = t_c)\n","\n","print('\\nFinal parameters:', params, '\\n')\n","\n","lr = 1e-4\n","params = training_loop(\tn_epochs = 100,\n","\tlearning_rate = lr,\n","\tparams = torch.tensor([1.0, 0.0]),\n","\tt_u = t_u, t_c = t_c)\n","print('\\nFinal parameters:', params, '\\n')\n","\n","\n","t_un = 0.1 * t_u\n","params = training_loop(\n","\tn_epochs = 100,\n","\tlearning_rate = 1e-2,\n","\tparams = torch.tensor([1.0, 0.0]),\n","\tt_u = t_un, # <1>\n","\tt_c = t_c)\n","print('\\nFinal parameters:', params, '\\n')\n","\n","params = training_loop(\n","\tn_epochs = 5000,\n","\tlearning_rate = 1e-2,\n","\tparams = torch.tensor([1.0, 0.0]),\n","\tt_u = t_un, t_c = t_c)\n","print('\\nFinal parameters:', params, '\\n')\n"]},{"cell_type":"code","execution_count":null,"id":"36bd28af","metadata":{"id":"36bd28af"},"outputs":[],"source":["params\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","t_p = model(t_un, *params)  # <1>\n","\n","fig = plt.figure(dpi=200)\n","plt.xlabel(\"Temperature (¬∞Fahrenheit)\")\n","plt.ylabel(\"Temperature (¬∞Celsius)\")\n","plt.plot(t_u.numpy(), t_p.detach().numpy()) # <2>\n","plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n","plt.savefig(\"temp_unknown_plot.png\", format=\"png\")  # bookskip\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","fig = plt.figure(dpi=200)\n","plt.xlabel(\"Measurement\")\n","plt.ylabel(\"Temperature (¬∞Celsius)\")\n","plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n","\n","plt.savefig(\"temp_data_plot.png\", format=\"png\")"]},{"cell_type":"markdown","id":"33f53c3e","metadata":{"id":"33f53c3e"},"source":["Using autograd..."]},{"cell_type":"code","execution_count":null,"id":"bd94fc0b","metadata":{"id":"bd94fc0b"},"outputs":[],"source":["loss = loss_fn(model(t_u, *params), t_c)\n","loss.backward()"]},{"cell_type":"code","execution_count":null,"id":"45c861f9","metadata":{"id":"45c861f9"},"outputs":[],"source":["params = torch.tensor([1.0, 0.0], requires_grad=True)\n","params.grad is None"]},{"cell_type":"code","execution_count":null,"id":"084f6734","metadata":{"id":"084f6734"},"outputs":[],"source":["if params.grad is not None:\n","   params.grad.zero_()"]},{"cell_type":"code","execution_count":null,"id":"66d53366","metadata":{"id":"66d53366"},"outputs":[],"source":["def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n","    for epoch in range(1, n_epochs + 1):\n","        if params.grad is not None:  # <1>\n","            params.grad.zero_()\n","\n","        t_p = model(t_u, *params)\n","        loss = loss_fn(t_p, t_c)\n","        loss.backward()\n","\n","        with torch.no_grad():  # <2>\n","            params -= learning_rate * params.grad\n","\n","        if epoch % 500 == 0:\n","            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n","\n","    return params"]},{"cell_type":"code","execution_count":null,"id":"1174170c","metadata":{"id":"1174170c"},"outputs":[],"source":["training_loop(\n","    n_epochs = 5000,\n","    learning_rate = 1e-2,\n","    params = torch.tensor([1.0, 0.0], requires_grad=True), # <1>\n","    t_u = t_un, # <2>\n","    t_c = t_c)"]},{"cell_type":"markdown","id":"bc4399b0","metadata":{"id":"bc4399b0"},"source":["‚Ü© SOLUTION: optimizer..."]},{"cell_type":"code","execution_count":null,"id":"43f687a2","metadata":{"id":"43f687a2"},"outputs":[],"source":["import torch.optim as optim\n","dir(optim)"]},{"cell_type":"code","execution_count":null,"id":"712ddb67","metadata":{"id":"712ddb67"},"outputs":[],"source":["# Let's use the optimizer to train the model\n","params = torch.tensor([1.0, 0.0], requires_grad=True)\n","learning_rate = 1e-5\n","optimizer = optim.SGD([params], lr=learning_rate)\n","t_p = model(t_un, *params)\n","loss = loss_fn(t_p, t_c)\n","loss.backward()"]},{"cell_type":"code","execution_count":null,"id":"d17a7dda","metadata":{"id":"d17a7dda"},"outputs":[],"source":["# Let's use an optimizer to update the parameters\n","optimizer.step()\n","params = torch.tensor([1.0, 0.0], requires_grad=True)\n","learning_rate = 1e-2\n","optimizer = optim.SGD([params], lr=learning_rate)\n","\n","#\n","t_p = model(t_un, *params)\n","loss = loss_fn(t_p, t_c)\n","\n","optimizer.zero_grad() # <1>\n","loss.backward()\n","optimizer.step()\n","\n","# define a training loop that uses the optimizer\n","def training_loop(n_epochs, optimizer, params, t_u, t_c):\n","    for epoch in range(1, n_epochs + 1):\n","        t_p = model(t_u, *params)\n","        loss = loss_fn(t_p, t_c)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if epoch % 500 == 0:\n","            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n","\n","    return params\n","\n","# Let's train the model using the training loop with an optimizer\n","training_loop(\n","    n_epochs = 5000,\n","    optimizer = optimizer,\n","    params = params, # <1>\n","    t_u = t_un,\n","    t_c = t_c)"]},{"cell_type":"markdown","id":"80aedefb","metadata":{"id":"80aedefb"},"source":["‚Ü© TODO: optimizer..."]},{"cell_type":"code","execution_count":null,"id":"15421523","metadata":{"id":"15421523"},"outputs":[],"source":["# Let's use an optimizer to update the parameters\n","\n","\n","# define a training loop that uses the optimizer\n","\n","\n","# Let's train the model using the training loop with an optimizer\n"]},{"cell_type":"markdown","id":"aceb988d","metadata":{"id":"aceb988d"},"source":["# üêç MLP"]},{"cell_type":"markdown","id":"9b00eee9","metadata":{"id":"9b00eee9"},"source":["Example1: celsius vs fahrenheit..."]},{"cell_type":"code","execution_count":null,"id":"9af88cfa","metadata":{"id":"9af88cfa"},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","\n","torch.set_printoptions(edgeitems=2, linewidth=75)"]},{"cell_type":"code","execution_count":null,"id":"fc531082","metadata":{"id":"fc531082"},"outputs":[],"source":["t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n","t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n","t_c = torch.tensor(t_c).unsqueeze(1) # <1>\n","t_u = torch.tensor(t_u).unsqueeze(1) # <1>\n","\n","t_u.shape"]},{"cell_type":"code","execution_count":null,"id":"857d7c02","metadata":{"id":"857d7c02"},"outputs":[],"source":["n_samples = t_u.shape[0]\n","n_val = int(0.2 * n_samples)\n","\n","# Shuffle the indices\n","shuffled_indices = torch.randperm(n_samples)\n","\n","# Split the indices into training and validation sets\n","train_indices = shuffled_indices[:-n_val]\n","val_indices = shuffled_indices[-n_val:]\n","\n","# show the indices\n","train_indices, val_indices"]},{"cell_type":"code","execution_count":null,"id":"d86c295b","metadata":{"id":"d86c295b"},"outputs":[],"source":["#  Split the data into training and validation sets using the shuffled indices\n","t_u_train = t_u[train_indices]\n","t_c_train = t_c[train_indices]\n","\n","t_u_val = t_u[val_indices]\n","t_c_val = t_c[val_indices]\n","\n","t_un_train = 0.1 * t_u_train\n","t_un_val = 0.1 * t_u_val"]},{"cell_type":"code","execution_count":null,"id":"a015921e","metadata":{"id":"a015921e"},"outputs":[],"source":["import torch.nn as nn\n","\n","# Define a simple linear model\n","linear_model = nn.Linear(1, 1)\n","linear_model(t_un_val)"]},{"cell_type":"code","execution_count":null,"id":"72a21b8f","metadata":{"id":"72a21b8f"},"outputs":[],"source":["print(linear_model.weight)\n","print(linear_model.bias)"]},{"cell_type":"code","execution_count":null,"id":"cd8afb5b","metadata":{"id":"cd8afb5b"},"outputs":[],"source":["x = torch.ones(10, 1)\n","linear_model(x)"]},{"cell_type":"code","execution_count":null,"id":"0aaac440","metadata":{"id":"0aaac440"},"outputs":[],"source":["linear_model = nn.Linear(1, 1)\n","optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)"]},{"cell_type":"code","execution_count":null,"id":"9acb4513","metadata":{"id":"9acb4513"},"outputs":[],"source":["def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n","\tfor epoch in range(1, n_epochs + 1):\n","\t\tt_p_train = model(t_u_train)\n","\t\tloss_train = loss_fn(t_p_train, t_c_train)\n","\n","\t\tt_p_val = model(t_u_val)\n","\t\tloss_val = loss_fn(t_p_val, t_c_val)\n","\n","\t\toptimizer.zero_grad()\n","\t\tloss_train.backward()\n","\t\toptimizer.step()\n","\n","\t\tif epoch == 1 or epoch % 1000 == 0:\n","\t\t\tprint(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"f\" Validation loss {loss_val.item():.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"da94535c","metadata":{"id":"da94535c"},"outputs":[],"source":["def loss_fn(t_p, t_c):\n","\tsquared_diffs = (t_p - t_c)**2\n","\treturn squared_diffs.mean()\n","\n","linear_model = nn.Linear(1, 1) # <1>\n","optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n","\n","training_loop(\n","    n_epochs = 3000,\n","    optimizer = optimizer,\n","    model = linear_model,\n","    loss_fn = loss_fn,\n","    t_u_train = t_un_train,\n","    t_u_val = t_un_val,\n","    t_c_train = t_c_train,\n","    t_c_val = t_c_val)\n","\n","print()\n","print(linear_model.weight)\n","print(linear_model.bias)"]},{"cell_type":"code","execution_count":null,"id":"84fd07b5","metadata":{"id":"84fd07b5"},"outputs":[],"source":["linear_model = nn.Linear(1, 1)\n","optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n","\n","training_loop(\n","\tn_epochs = 3000,\n","\toptimizer = optimizer,\n","\tmodel = linear_model,\n","\tloss_fn = nn.MSELoss(), #\n","\tt_u_train = t_un_train,\n","\tt_u_val = t_un_val,\n","\tt_c_train = t_c_train,\n","\tt_c_val = t_c_val)\n","\n","print()\n","print(linear_model.weight)\n","print(linear_model.bias)"]},{"cell_type":"markdown","id":"13a9c1da","metadata":{"id":"13a9c1da"},"source":["‚Ü© Solution: optimizer..."]},{"cell_type":"code","execution_count":null,"id":"ef64f6eb","metadata":{"id":"ef64f6eb"},"outputs":[],"source":["# sequential model\n","seq_model = nn.Sequential(\n","            nn.Linear(1, 13), # <1>\n","            nn.Tanh(),\n","            nn.Linear(13, 1)) # <2>\n","seq_model"]},{"cell_type":"code","execution_count":null,"id":"c403f0b3","metadata":{"id":"c403f0b3"},"outputs":[],"source":["[param.shape for param in seq_model.parameters()]"]},{"cell_type":"code","execution_count":null,"id":"f9a708ee","metadata":{"id":"f9a708ee"},"outputs":[],"source":["# Let's use the optimizer to train the model\n","optimizer = optim.SGD(seq_model.parameters(), lr=1e-3) # <1>\n","\n","# Let's define a training loop that uses the optimizer\n","training_loop(\n","\tn_epochs = 5000,\n","\toptimizer = optimizer,\n","\tmodel = seq_model,\n","\tloss_fn = nn.MSELoss(),\n","\tt_u_train = t_un_train,\n","\tt_u_val = t_un_val,\n","\tt_c_train = t_c_train,\n","\tt_c_val = t_c_val)\n","\n","print('output', seq_model(t_un_val))\n","print('answer', t_c_val)\n","print('hidden', seq_model[0].weight) # <1>\n","print('hidden', seq_model[0].bias) # <1>\n","\n"]},{"cell_type":"markdown","id":"9dc23082","metadata":{"id":"9dc23082"},"source":["‚Ü© TODO: optimizer..."]},{"cell_type":"code","execution_count":null,"id":"b9d5087c","metadata":{"id":"b9d5087c"},"outputs":[],"source":["# sequential model"]},{"cell_type":"code","execution_count":null,"id":"73522817","metadata":{"id":"73522817"},"outputs":[],"source":["# Let's use the optimizer to train the model\n","\n","# Let's define a training loop that uses the optimizer\n","\n","\n","# Let's train the model using the training loop with an optimizer\n","print('output', seq_model(t_un_val))\n","print('answer', t_c_val)\n","print('hidden', seq_model[0].weight) # <1>\n","print('hidden', seq_model[0].bias) # <1>"]},{"cell_type":"code","execution_count":null,"id":"dcd6788e","metadata":{"id":"dcd6788e"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","t_range = torch.arange(20., 90.).unsqueeze(1)\n","\n","fig = plt.figure(dpi=200)\n","plt.xlabel(\"Fahrenheit\")\n","plt.ylabel(\"Celsius\")\n","plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n","plt.plot(t_range.numpy(), seq_model(0.1 * t_range).detach().numpy(), 'c-')\n","plt.plot(t_u.numpy(), seq_model(0.1 * t_u).detach().numpy(), 'kx')\n","plt.show()"]},{"cell_type":"markdown","id":"b39ea01d","metadata":{"id":"b39ea01d"},"source":["**Example 2:** A nonlinear dataset.\n","\n","Use the dataset for regression:\n","- define a MLP model\n","- instantiate model, define loss and optimizer\n","- train the model\n","- plot results\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","\n","# Generate synthetic non-linear dataset\n","torch.manual_seed(0)\n","x = torch.linspace(-3, 3, 100).view(-1, 1)  # Input\n","y = x**2 + torch.sin(x) + 0.2 * torch.randn_like(x)  # Non-linear function with noise\n"],"metadata":{"id":"tv_CSqNnyobD"},"id":"tv_CSqNnyobD","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"9bad15c4","metadata":{"id":"9bad15c4"},"outputs":[],"source":["# Define MLP model\n","class MLPRegression(nn.Module):\n","\tdef __init__(self):\n","\t\tsuper(MLPRegression, self).__init__()\n","\t\tself.fc1 = nn.Linear(1, 64)\n","\t\tself.fc2 = nn.Linear(64, 64)\n","\t\tself.fc3 = nn.Linear(64, 1)\n","\t\tself.activation = nn.ReLU()     # Non-linear activation\n","\n","\tdef forward(self, x):\n","\t\tx = self.activation(self.fc1(x))\n","\t\tx = self.activation(self.fc2(x))\n","\t\treturn self.fc3(x)\n","\n","# Instantiate model, define loss and optimizer\n","model = MLPRegression()\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","# Training loop\n","epochs = 500\n","for epoch in range(epochs):\n","    optimizer.zero_grad()\n","    y_pred = model(x)\n","    loss = criterion(y_pred, y)\n","    loss.backward()\n","    optimizer.step()\n","\n","# Plot results\n","plt.scatter(x.numpy(), y.numpy(), label=\"True Data\", alpha=0.5)\n","plt.plot(x.numpy(), model(x).detach().numpy(), color='red', label=\"MLP Prediction\")\n","plt.xlabel(\"X\")\n","plt.ylabel(\"Y\")\n","plt.title(\"Non-Linear Regression with MLP\")\n","plt.legend()\n","plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["-_i3qX0HhLrV","32aab92c"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}