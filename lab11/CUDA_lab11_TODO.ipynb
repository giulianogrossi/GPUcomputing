{"cells":[{"cell_type":"markdown","id":"cd16b39b","metadata":{"id":"cd16b39b"},"source":["---\n","# **LAB 9 - NN in CUDA Pytorch**\n","---"]},{"cell_type":"markdown","id":"-_i3qX0HhLrV","metadata":{"id":"-_i3qX0HhLrV"},"source":["# ‚ñ∂Ô∏è CUDA setup"]},{"cell_type":"code","execution_count":1,"id":"JZS1v474hLrW","metadata":{"id":"JZS1v474hLrW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748506839117,"user_tz":-120,"elapsed":186,"user":{"displayName":"Giuliano Grossi","userId":"05046904419500019805"}},"outputId":"408e1369-f014-41af-fc1d-8e445d630cd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","execution_count":2,"id":"TWZ7N-4OhLrW","metadata":{"id":"TWZ7N-4OhLrW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748506839172,"user_tz":-120,"elapsed":57,"user":{"displayName":"Giuliano Grossi","userId":"05046904419500019805"}},"outputId":"47311f1d-31df-4346-92fa-72b91b1ff672"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu May 29 08:20:39 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"id":"xSoLaRWchLrX","metadata":{"id":"xSoLaRWchLrX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748506849035,"user_tz":-120,"elapsed":9861,"user":{"displayName":"Giuliano Grossi","userId":"05046904419500019805"}},"outputId":"d7efea85-021d-47fb-aab6-8bb0316c60a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numba-cuda==0.4.0\n","  Downloading numba_cuda-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: numba>=0.59.1 in /usr/local/lib/python3.11/dist-packages (from numba-cuda==0.4.0) (0.60.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.59.1->numba-cuda==0.4.0) (0.43.0)\n","Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.11/dist-packages (from numba>=0.59.1->numba-cuda==0.4.0) (2.0.2)\n","Downloading numba_cuda-0.4.0-py3-none-any.whl (453 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m453.8/453.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numba-cuda\n","  Attempting uninstall: numba-cuda\n","    Found existing installation: numba-cuda 0.2.0\n","    Uninstalling numba-cuda-0.2.0:\n","      Successfully uninstalled numba-cuda-0.2.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 25.2.1 requires numba-cuda<0.3.0a0,>=0.2.0, but you have numba-cuda 0.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numba-cuda-0.4.0\n"]}],"source":["!pip install numba-cuda==0.4.0"]},{"cell_type":"code","execution_count":4,"id":"iTq5M1SfhLrX","metadata":{"id":"iTq5M1SfhLrX","executionInfo":{"status":"ok","timestamp":1748506850422,"user_tz":-120,"elapsed":1388,"user":{"displayName":"Giuliano Grossi","userId":"05046904419500019805"}}},"outputs":[],"source":["from numba import config\n","config.CUDA_ENABLE_PYNVJITLINK = 1"]},{"cell_type":"markdown","id":"32aab92c","metadata":{"id":"32aab92c"},"source":["# üêç Pytorch basic"]},{"cell_type":"code","execution_count":null,"id":"043af3e4","metadata":{"id":"043af3e4"},"outputs":[],"source":["import torch\n","torch.__version__"]},{"cell_type":"code","execution_count":null,"id":"da1e673b","metadata":{"id":"da1e673b"},"outputs":[],"source":["x = torch.rand(2, 3)\n","print(x)\n","print(x.dtype)"]},{"cell_type":"code","execution_count":null,"id":"7e2b5802","metadata":{"id":"7e2b5802"},"outputs":[],"source":["x = torch.ones((5, 3), dtype=torch.double)\n","print(x)\n"]},{"cell_type":"code","execution_count":null,"id":"1de59c01","metadata":{"id":"1de59c01"},"outputs":[],"source":["# Vector\n","vector = torch.tensor([7, 7])\n","vector"]},{"cell_type":"code","execution_count":null,"id":"27dd4814","metadata":{"id":"27dd4814"},"outputs":[],"source":["# Matrix\n","matrix = torch.tensor([[7, 8],\n","                      [9, 10]])\n","matrix"]},{"cell_type":"code","execution_count":null,"id":"62efbf9b","metadata":{"id":"62efbf9b"},"outputs":[],"source":["x = torch.arange(10).reshape(2, 5)\n","x.shape\n","\n","torch.Size([2, 5])"]},{"cell_type":"code","execution_count":null,"id":"1042cd76","metadata":{"id":"1042cd76"},"outputs":[],"source":["points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n","points.storage()"]},{"cell_type":"code","execution_count":null,"id":"ebfd61cd","metadata":{"id":"ebfd61cd"},"outputs":[],"source":["r = (torch.rand(2, 2) - 0.5) * 2 # values between -1 and 1\n","print('A random matrix, r:')\n","print(r)\n","\n","# Common mathematical operations are supported:\n","print('\\nAbsolute value of r:')\n","print(torch.abs(r))\n","\n","# ...as are trigonometric functions:\n","print('\\nInverse sine of r:')\n","print(torch.asin(r))\n","\n","# ...and linear algebra operations like determinant and singular value decomposition\n","print('\\nDeterminant of r:')\n","print(torch.det(r))\n","print('\\nSingular value decomposition of r:')\n","print(torch.svd(r))\n","\n","# ...and statistical and aggregate operations:\n","print('\\nAverage and standard deviation of r:')\n","print(torch.std_mean(r))\n","print('\\nMaximum value of r:')\n","print(torch.max(r))\n"]},{"cell_type":"code","execution_count":null,"id":"d4082c31","metadata":{"id":"d4082c31"},"outputs":[],"source":["a = torch.ones(3,1)\n","b = torch.ones(1,3)\n","c = torch.ones(2, 1, 1)\n","print(f\"shapes: a: {a.shape}, b: {b.shape}, c: {c.shape}\")\n","d = a + b\n","print(\"d = a + b:\", d.shape)\n","e = c * d\n","print(\"e = c * d:\", e.shape)"]},{"cell_type":"markdown","id":"b8589b63","metadata":{"id":"b8589b63"},"source":["# üêç Pytorch on GPU"]},{"cell_type":"code","execution_count":null,"id":"6559e0fb","metadata":{"id":"6559e0fb"},"outputs":[],"source":["import torch\n","# Check CUDA availability\n","print(torch.cuda.is_available())\n","# Get the current CUDA device\n","print(torch.cuda.current_device())\n","# Get the name of the current CUDA device\n","print(torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":null,"id":"d96893fa","metadata":{"id":"d96893fa"},"outputs":[],"source":["# Move a tensor to GPU\n","x = torch.tensor([1, 2, 3])\n","x_gpu = x.to('cuda')\n","print(x_gpu)"]},{"cell_type":"code","execution_count":null,"id":"8ab68c4f","metadata":{"id":"8ab68c4f"},"outputs":[],"source":["import torch\n","x = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')\n","print(x)"]},{"cell_type":"code","execution_count":null,"id":"729b9c80","metadata":{"id":"729b9c80"},"outputs":[],"source":["cuda = torch.device('cuda')     # Default CUDA device\n","cuda0 = torch.device('cuda:0')\n","print(cuda0)  # device(type='cuda', index=0)\n","cuda2 = torch.device('cuda:1')  # GPU 2 (these are 0-indexed)\n","print(cuda2)  # device(type='cuda', index=2)\n","\n","x = torch.tensor([1., 2.], device=cuda0)\n","print(x.device)  # device(type='cuda', index=0)\n","# x.device is device(type='cuda', index=0)\n","y = torch.tensor([1., 2.]).cuda()\n","print(y.device)  # device(type='cuda', index=0)\n","# y.device is device(type='cuda', index=0)\n","\n","with torch.cuda.device(0):\n","\t# allocates a tensor on GPU 1\n","\ta = torch.tensor([1., 2.], device=cuda)\n","\n","\t# transfers a tensor from CPU to GPU 1\n","\tb = torch.tensor([1., 2.]).cuda()\n","\t# a.device and b.device are device(type='cuda', index=1)\n","\n","\t# You can also use ``Tensor.to`` to transfer a tensor:\n","\tb2 = torch.tensor([1., 2.]).to(device=cuda)\n","\t# b.device and b2.device are device(type='cuda', index=1)\n","\n","\tc = a + b\n","\t# c.device is device(type='cuda', index=1)\n","\n","\tz = x + y\n","\t# z.device is device(type='cuda', index=0)\n"]},{"cell_type":"code","execution_count":null,"id":"766e36cc","metadata":{"id":"766e36cc"},"outputs":[],"source":["# Let's do some matrix multiplication on the CPU first\n","a_full = torch.randn(10240, 10240, dtype=torch.double)\n","b_full = torch.randn(10240, 10240, dtype=torch.double)\n","\n","ab_full = a_full @ b_full # takes 280.110 ms on GA100"]},{"cell_type":"markdown","id":"3ae441ca","metadata":{"id":"3ae441ca"},"source":["* TF32 (TensorFloat-32) is a precision mode that allows for faster matrix multiplications on NVIDIA Ampere and later GPUs.\n","* It uses 19 bits for the mantissa instead of the usual 23 bits in FP32, which can lead to faster computations with a small loss in precision.\n","* This is particularly useful for deep learning workloads where the precision loss is often acceptable.\n","* The following code demonstrates the use of TF32 in PyTorch for matrix multiplication.\n","* Ensure that TF32 is enabled for matrix multiplication"]},{"cell_type":"code","execution_count":null,"id":"aeaf45b4","metadata":{"id":"aeaf45b4"},"outputs":[],"source":["# Let's do some matrix multiplication on the GPU\n","a_full = torch.randn(10240, 10240, dtype=torch.double, device='cuda')\n","b_full = torch.randn(10240, 10240, dtype=torch.double, device='cuda')\n","ab_full = a_full @ b_full\n","mean = ab_full.abs().mean()  # 80.7277\n","\n","a = a_full.float()\n","b = b_full.float()\n","\n","start_event = torch.cuda.Event(enable_timing=True)\n","end_event = torch.cuda.Event(enable_timing=True)\n","# Do matmul at TF32 mode.\n","torch.backends.cuda.matmul.allow_tf32 = True\n","start_event.record()\n","ab_tf32 = a @ b  # takes 40.432 ms on GA100\n","end_event.record()\n","torch.cuda.synchronize()  # Wait for the events to be recorded!\n","elapsed_time_ms = start_event.elapsed_time(end_event)\n","print(f'TF32 matmul took {elapsed_time_ms:.3f} ms')\n","error = (ab_tf32 - ab_full).abs().max()  # 0.1747\n","relative_error = error / mean  # 0.0022\n","print(f'Max error: {error:.4f}, Relative error: {relative_error:.6f}')\n","\n","# Do matmul with TF32 disabled.\n","torch.backends.cuda.matmul.allow_tf32 = False\n","start_event.record()\n","ab_fp32 = a @ b  # takes 280.110 ms on GA100\n","end_event.record()\n","torch.cuda.synchronize()  # Wait for the events to be recorded!\n","elapsed_time_ms = start_event.elapsed_time(end_event)\n","print(f'TF32 matmul took {elapsed_time_ms:.3f} ms')\n","error = (ab_fp32 - ab_full).abs().max()  # 0.0031\n","relative_error = error / mean  # 0.000039\n","print(f'Max error: {error:.4f}, Relative error: {relative_error:.6f}')\n","\n"]},{"cell_type":"markdown","source":["‚Ü© TODO: translate in pytorch using CUDA..."],"metadata":{"id":"Va7NWvSexrJt"},"id":"Va7NWvSexrJt"},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","import numpy as np\n","import math\n","\n","# Create random input and output data\n","x = np.linspace(-math.pi, math.pi, 2000)\n","y = np.sin(x)\n","\n","# Randomly initialize weights\n","a = np.random.randn()\n","b = np.random.randn()\n","c = np.random.randn()\n","d = np.random.randn()\n","\n","learning_rate = 1e-6\n","for t in range(2000):\n","    # Forward pass: compute predicted y\n","    # y = a + b x + c x^2 + d x^3\n","    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n","\n","    # Compute and print loss\n","    loss = np.square(y_pred - y).sum()\n","    if t % 100 == 99:\n","        print(t, loss)\n","\n","    # Backprop to compute gradients of a, b, c, d with respect to loss\n","    grad_y_pred = 2.0 * (y_pred - y)\n","    grad_a = grad_y_pred.sum()\n","    grad_b = (grad_y_pred * x).sum()\n","    grad_c = (grad_y_pred * x ** 2).sum()\n","    grad_d = (grad_y_pred * x ** 3).sum()\n","\n","    # Update weights\n","    a -= learning_rate * grad_a\n","    b -= learning_rate * grad_b\n","    c -= learning_rate * grad_c\n","    d -= learning_rate * grad_d\n","\n","print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"],"metadata":{"id":"pzDFQnOixjsz"},"id":"pzDFQnOixjsz","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"c997af7d","metadata":{"id":"c997af7d"},"source":["# üêç Linear model"]},{"cell_type":"code","execution_count":null,"id":"8d4cf1db","metadata":{"id":"8d4cf1db"},"outputs":[],"source":["import torch\n","\n","t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n","t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n","t_c = torch.tensor(t_c)\n","t_u = torch.tensor(t_u)\n","\n","# parameters of the model\n","w = torch.ones(())\n","b = torch.zeros(())\n","\n","# Let's define a model that predicts Celsius from unknown\n","def model(x, w, b):\n","   return w * x + b\n","\n","# Let's define the loss function that measures the difference between\n","def loss_fn(y1, y2):\n","\tsquared_diffs = 0.5 * (y1 - y2)**2\n","\treturn squared_diffs.mean()\n","\n","# Let's compute the predictions and the loss\n","t_p = model(t_u, w, b)\n","loss = loss_fn(t_p, t_c)\n","\n","# initial values\n","w = torch.ones(1)\n","b = torch.zeros(1)\n","print(f\"w: {w}, b: {b}\")\n","print(f\"shapes: w: {w.shape}, b: {b.shape}\")\n","t_p = model(t_u, w, b)\n","print(t_p)"]},{"cell_type":"code","execution_count":null,"id":"1175b7bf","metadata":{"id":"1175b7bf"},"outputs":[],"source":["import math\n","\n","delta = 0.1\n","\n","loss_rate_of_change_w = \\\n","    (loss_fn(model(t_u, w + delta, b), t_c) -\n","     loss_fn(model(t_u, w - delta, b), t_c)) / (2.0 * delta)\n","learning_rate = 1e-2\n","w = w - learning_rate * loss_rate_of_change_w\n","\n","loss_rate_of_change_b = \\\n","    (loss_fn(model(t_u, w, b + delta), t_c) -\n","     loss_fn(model(t_u, w, b - delta), t_c)) / (2.0 * delta)\n","b = b - learning_rate * loss_rate_of_change_b\n","\n","def dloss_fn(t_p, t_c):\n","    dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)  # <1>\n","    return dsq_diffs\n","\n","def dmodel_dw(t_u, w, b):\n","    return t_u\n","def dmodel_db(t_u, w, b):\n","    return 1.0\n","\n","def grad_fn(t_u, t_c, t_p, w, b):\n","    dloss_dtp = dloss_fn(t_p, t_c)\n","    dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n","    dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n","    return torch.stack([dloss_dw.sum(), dloss_db.sum()])  # <1>\n","\n","# Let's define a training loop that will train the model\n","def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n","\tfor epoch in range(1, n_epochs + 1):\n","\t\tw, b = params\n","\n","\t\tt_p = model(t_u, w, b)  # <1>\n","\t\tloss = loss_fn(t_p, t_c)\n","\t\tgrad = grad_fn(t_u, t_c, t_p, w, b)  # <2>\n","\n","\t\tparams = params - learning_rate * grad\n","\t\tN = round(math.sqrt(n_epochs))\n","\t\tif not (epoch % N):\n","\t\t\tprint('Epoch %d, Loss %f' % (epoch, float(loss))) # <3>\n","\n","\treturn params\n","\n","\n","# Let's train the model using the training loop\n","lr = 1e-2\n","params = training_loop(\tn_epochs = 100,\n","\tlearning_rate = lr,\n","\tparams = torch.tensor([1.0, 0.0]),\n","\tt_u = t_u, t_c = t_c)\n","\n","print('\\nFinal parameters:', params, '\\n')\n","\n","lr = 1e-4\n","params = training_loop(\tn_epochs = 100,\n","\tlearning_rate = lr,\n","\tparams = torch.tensor([1.0, 0.0]),\n","\tt_u = t_u, t_c = t_c)\n","print('\\nFinal parameters:', params, '\\n')\n","\n","\n","t_un = 0.1 * t_u\n","params = training_loop(\n","\tn_epochs = 100,\n","\tlearning_rate = 1e-2,\n","\tparams = torch.tensor([1.0, 0.0]),\n","\tt_u = t_un, # <1>\n","\tt_c = t_c)\n","print('\\nFinal parameters:', params, '\\n')\n","\n","params = training_loop(\n","\tn_epochs = 5000,\n","\tlearning_rate = 1e-2,\n","\tparams = torch.tensor([1.0, 0.0]),\n","\tt_u = t_un, t_c = t_c)\n","print('\\nFinal parameters:', params, '\\n')\n"]},{"cell_type":"code","execution_count":null,"id":"36bd28af","metadata":{"id":"36bd28af"},"outputs":[],"source":["params\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","t_p = model(t_un, *params)  # <1>\n","\n","fig = plt.figure(dpi=200)\n","plt.xlabel(\"Temperature (¬∞Fahrenheit)\")\n","plt.ylabel(\"Temperature (¬∞Celsius)\")\n","plt.plot(t_u.numpy(), t_p.detach().numpy()) # <2>\n","plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n","plt.savefig(\"temp_unknown_plot.png\", format=\"png\")  # bookskip\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","fig = plt.figure(dpi=200)\n","plt.xlabel(\"Measurement\")\n","plt.ylabel(\"Temperature (¬∞Celsius)\")\n","plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n","\n","plt.savefig(\"temp_data_plot.png\", format=\"png\")"]},{"cell_type":"markdown","id":"33f53c3e","metadata":{"id":"33f53c3e"},"source":["Using autograd..."]},{"cell_type":"code","execution_count":null,"id":"bd94fc0b","metadata":{"id":"bd94fc0b"},"outputs":[],"source":["loss = loss_fn(model(t_u, *params), t_c)\n","loss.backward()"]},{"cell_type":"code","execution_count":null,"id":"45c861f9","metadata":{"id":"45c861f9"},"outputs":[],"source":["params = torch.tensor([1.0, 0.0], requires_grad=True)\n","params.grad is None"]},{"cell_type":"code","execution_count":null,"id":"084f6734","metadata":{"id":"084f6734"},"outputs":[],"source":["if params.grad is not None:\n","   params.grad.zero_()"]},{"cell_type":"code","execution_count":null,"id":"66d53366","metadata":{"id":"66d53366"},"outputs":[],"source":["def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n","    for epoch in range(1, n_epochs + 1):\n","        if params.grad is not None:  # <1>\n","            params.grad.zero_()\n","\n","        t_p = model(t_u, *params)\n","        loss = loss_fn(t_p, t_c)\n","        loss.backward()\n","\n","        with torch.no_grad():  # <2>\n","            params -= learning_rate * params.grad\n","\n","        if epoch % 500 == 0:\n","            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n","\n","    return params"]},{"cell_type":"code","execution_count":null,"id":"1174170c","metadata":{"id":"1174170c"},"outputs":[],"source":["training_loop(\n","    n_epochs = 5000,\n","    learning_rate = 1e-2,\n","    params = torch.tensor([1.0, 0.0], requires_grad=True), # <1>\n","    t_u = t_un, # <2>\n","    t_c = t_c)"]},{"cell_type":"code","execution_count":null,"id":"43f687a2","metadata":{"id":"43f687a2"},"outputs":[],"source":["import torch.optim as optim\n","dir(optim)"]},{"cell_type":"markdown","id":"80aedefb","metadata":{"id":"80aedefb"},"source":["‚Ü© TODO: optimizer..."]},{"cell_type":"code","execution_count":null,"id":"15421523","metadata":{"id":"15421523"},"outputs":[],"source":["# Let's use an optimizer to update the parameters\n","\n","\n","# define a training loop that uses the optimizer\n","\n","\n","# Let's train the model using the training loop with an optimizer\n"]},{"cell_type":"markdown","id":"aceb988d","metadata":{"id":"aceb988d"},"source":["# üêç MLP"]},{"cell_type":"markdown","id":"9b00eee9","metadata":{"id":"9b00eee9"},"source":["Example1: celsius vs fahrenheit..."]},{"cell_type":"code","execution_count":null,"id":"9af88cfa","metadata":{"id":"9af88cfa"},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np\n","import torch\n","import torch.optim as optim\n","\n","torch.set_printoptions(edgeitems=2, linewidth=75)"]},{"cell_type":"code","execution_count":null,"id":"fc531082","metadata":{"id":"fc531082"},"outputs":[],"source":["t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n","t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n","t_c = torch.tensor(t_c).unsqueeze(1) # <1>\n","t_u = torch.tensor(t_u).unsqueeze(1) # <1>\n","\n","t_u.shape"]},{"cell_type":"code","execution_count":null,"id":"857d7c02","metadata":{"id":"857d7c02"},"outputs":[],"source":["n_samples = t_u.shape[0]\n","n_val = int(0.2 * n_samples)\n","\n","# Shuffle the indices\n","shuffled_indices = torch.randperm(n_samples)\n","\n","# Split the indices into training and validation sets\n","train_indices = shuffled_indices[:-n_val]\n","val_indices = shuffled_indices[-n_val:]\n","\n","# show the indices\n","train_indices, val_indices"]},{"cell_type":"code","execution_count":null,"id":"d86c295b","metadata":{"id":"d86c295b"},"outputs":[],"source":["#  Split the data into training and validation sets using the shuffled indices\n","t_u_train = t_u[train_indices]\n","t_c_train = t_c[train_indices]\n","\n","t_u_val = t_u[val_indices]\n","t_c_val = t_c[val_indices]\n","\n","t_un_train = 0.1 * t_u_train\n","t_un_val = 0.1 * t_u_val"]},{"cell_type":"code","execution_count":null,"id":"a015921e","metadata":{"id":"a015921e"},"outputs":[],"source":["import torch.nn as nn\n","\n","# Define a simple linear model\n","linear_model = nn.Linear(1, 1)\n","linear_model(t_un_val)"]},{"cell_type":"code","execution_count":null,"id":"72a21b8f","metadata":{"id":"72a21b8f"},"outputs":[],"source":["print(linear_model.weight)\n","print(linear_model.bias)"]},{"cell_type":"code","execution_count":null,"id":"cd8afb5b","metadata":{"id":"cd8afb5b"},"outputs":[],"source":["x = torch.ones(10, 1)\n","linear_model(x)"]},{"cell_type":"code","execution_count":null,"id":"0aaac440","metadata":{"id":"0aaac440"},"outputs":[],"source":["linear_model = nn.Linear(1, 1)\n","optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)"]},{"cell_type":"code","execution_count":null,"id":"9acb4513","metadata":{"id":"9acb4513"},"outputs":[],"source":["def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n","\tfor epoch in range(1, n_epochs + 1):\n","\t\tt_p_train = model(t_u_train)\n","\t\tloss_train = loss_fn(t_p_train, t_c_train)\n","\n","\t\tt_p_val = model(t_u_val)\n","\t\tloss_val = loss_fn(t_p_val, t_c_val)\n","\n","\t\toptimizer.zero_grad()\n","\t\tloss_train.backward()\n","\t\toptimizer.step()\n","\n","\t\tif epoch == 1 or epoch % 1000 == 0:\n","\t\t\tprint(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"f\" Validation loss {loss_val.item():.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"da94535c","metadata":{"id":"da94535c"},"outputs":[],"source":["def loss_fn(t_p, t_c):\n","\tsquared_diffs = (t_p - t_c)**2\n","\treturn squared_diffs.mean()\n","\n","linear_model = nn.Linear(1, 1) # <1>\n","optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n","\n","training_loop(\n","    n_epochs = 3000,\n","    optimizer = optimizer,\n","    model = linear_model,\n","    loss_fn = loss_fn,\n","    t_u_train = t_un_train,\n","    t_u_val = t_un_val,\n","    t_c_train = t_c_train,\n","    t_c_val = t_c_val)\n","\n","print()\n","print(linear_model.weight)\n","print(linear_model.bias)"]},{"cell_type":"code","execution_count":null,"id":"84fd07b5","metadata":{"id":"84fd07b5"},"outputs":[],"source":["linear_model = nn.Linear(1, 1)\n","optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n","\n","training_loop(\n","\tn_epochs = 3000,\n","\toptimizer = optimizer,\n","\tmodel = linear_model,\n","\tloss_fn = nn.MSELoss(), #\n","\tt_u_train = t_un_train,\n","\tt_u_val = t_un_val,\n","\tt_c_train = t_c_train,\n","\tt_c_val = t_c_val)\n","\n","print()\n","print(linear_model.weight)\n","print(linear_model.bias)"]},{"cell_type":"markdown","id":"9dc23082","metadata":{"id":"9dc23082"},"source":["‚Ü© TODO: optimizer..."]},{"cell_type":"code","execution_count":null,"id":"b9d5087c","metadata":{"id":"b9d5087c"},"outputs":[],"source":["# sequential model"]},{"cell_type":"code","execution_count":null,"id":"73522817","metadata":{"id":"73522817"},"outputs":[],"source":["# Let's use the optimizer to train the model\n","\n","# Let's define a training loop that uses the optimizer\n","\n","# Let's train the model using the training loop with an optimizer\n","print('output', seq_model(t_un_val))\n","print('answer', t_c_val)\n","print('hidden', seq_model[0].weight) # <1>\n","print('hidden', seq_model[0].bias) # <1>"]},{"cell_type":"code","execution_count":null,"id":"dcd6788e","metadata":{"id":"dcd6788e"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","t_range = torch.arange(20., 90.).unsqueeze(1)\n","\n","fig = plt.figure(dpi=200)\n","plt.xlabel(\"Fahrenheit\")\n","plt.ylabel(\"Celsius\")\n","plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n","plt.plot(t_range.numpy(), seq_model(0.1 * t_range).detach().numpy(), 'c-')\n","plt.plot(t_u.numpy(), seq_model(0.1 * t_u).detach().numpy(), 'kx')\n","plt.show()"]},{"cell_type":"markdown","id":"b39ea01d","metadata":{"id":"b39ea01d"},"source":["**Example 2:** A nonlinear dataset.\n","\n","Use the dataset for regression:\n","- define a MLP model\n","- instantiate model, define loss and optimizer\n","- train the model\n","- plot results\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","\n","# Generate synthetic non-linear dataset\n","torch.manual_seed(0)\n","x = torch.linspace(-3, 3, 100).view(-1, 1)  # Input\n","y = x**2 + torch.sin(x) + 0.2 * torch.randn_like(x)  # Non-linear function with noise"],"metadata":{"id":"4tFH54-3zYFx"},"id":"4tFH54-3zYFx","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"9bad15c4","metadata":{"id":"9bad15c4"},"outputs":[],"source":["# Define MLP model\n","\n","# Instantiate model, define loss and optimizer\n","\n","# Training loop\n","\n","# Plot results\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["-_i3qX0HhLrV","32aab92c","aceb988d"],"gpuType":"T4","provenance":[{"file_id":"17BaacM4fe1lVSIVcYh3wH6Eu8MO_HAQO","timestamp":1748467465073}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}