{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["NO_C5o9-xRF_","1snOeEsH_5z3"],"mount_file_id":"1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo","authorship_tag":"ABX9TyPUed6C5lFbxlmAmW/zgmzi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","# **LAB 5 - Unrolling e parallelismo dinamico**\n","---"],"metadata":{"id":"fZYqN0UwVLC_"}},{"cell_type":"markdown","metadata":{"id":"NO_C5o9-xRF_"},"source":["# ▶️ CUDA setup"]},{"cell_type":"code","metadata":{"id":"8fekR2O4xRGE"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Psl9iouxRGE"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GPU computing notebooks download (from github)"],"metadata":{"id":"gcg1GyK5srek"}},{"cell_type":"code","source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"],"metadata":{"id":"tyHOxci3s3H8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"227eLdP5csN1"},"source":["NVCC Plugin for Jupyter notebook"]},{"cell_type":"code","source":["%cd GPUcomputing/utils/nvcc4jupyter-master/\n","!!python3 -m build\n","%load_ext nvcc4jupyter\n","%cd /content/"],"metadata":{"id":"4TzxMBFds8aT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUYP4kCJhEIx"},"source":["# ✅ Occupancy Calculator - DeviceQuery"]},{"cell_type":"code","metadata":{"id":"Vvl8WXljg0WK"},"source":["%%cuda\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","int main(void) {\n","\n","\tprintf(\"\\nCUDA Device Query (Runtime API) version (CUDART static linking)\\n\\n\");\n","\tint deviceCount = 0;\n","\tCHECK(cudaGetDeviceCount(&deviceCount));\n","\n","\t// This function call returns 0 if there are no CUDA capable devices.\n","\tif (deviceCount == 0)\n","\t\tprintf(\"There are no available device(s) that support CUDA\\n\");\n","\telse\n","\t\tprintf(\"Detected %d CUDA Capable device(s)\\n\", deviceCount);\n","\n","\tint dev, driverVersion = 0, runtimeVersion = 0;\n","\n","\tfor (dev = 0; dev < deviceCount; ++dev) {\n","\t\tcudaSetDevice(dev);\n","\t\tcudaDeviceProp deviceProp;\n","\t\tcudaGetDeviceProperties(&deviceProp, dev);\n","\n","\t\tprintf(\"\\nDevice %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n","\n","\t\tcudaDriverGetVersion(&driverVersion);\n","\t\tcudaRuntimeGetVersion(&runtimeVersion);\n","\n","\t\tprintf(\"  CUDA Driver Version / Runtime Version          %d.%d / %d.%d\\n\",\n","\t\t\t\tdriverVersion / 1000, (driverVersion % 100) / 10,\n","\t\t\t\truntimeVersion / 1000, (runtimeVersion % 100) / 10);\n","\n","\t\tprintf(\"  GPU arch name:                                 %s\\n\",\n","\t\t\t\t\t\t_ConvertSMVer2ArchName(deviceProp.major, deviceProp.minor));\n","\n","\t\tprintf(\"  CUDA Capability Major/Minor version number:    %d.%d\\n\",\n","\t\t\t\tdeviceProp.major, deviceProp.minor);\n","\n","\t\tprintf(\"  Total amount of global memory:                 %.0f MBytes (%llu bytes)\\n\",\n","\t\t\t\t(float) deviceProp.totalGlobalMem / 1048576.0f,\n","\t\t\t\t(unsigned long long) deviceProp.totalGlobalMem);\n","\n","\t\tprintf(\"  (%2d) Multiprocessors, (%3d) CUDA Cores/MP:     %d CUDA Cores\\n\",\n","\t\t\t\t\t\tdeviceProp.multiProcessorCount,\n","\t\t\t\t\t\t_ConvertSMVer2Cores(deviceProp.major, deviceProp.minor),\n","\t\t\t\t\t\t_ConvertSMVer2Cores(deviceProp.major, deviceProp.minor) *\n","\t\t\t\t\t\t\t\tdeviceProp.multiProcessorCount);\n","\n","\t\tprintf(\"  GPU Max Clock rate:                            %.0f MHz (%0.2f GHz)\\n\",\n","\t\t\t\tdeviceProp.clockRate * 1e-3f, deviceProp.clockRate * 1e-6f);\n","\n","\t\tprintf(\"  Memory Clock rate:                             %.0f Mhz\\n\", deviceProp.memoryClockRate * 1e-3f);\n","\t\tprintf(\"  Memory Bus Width:                              %d-bit\\n\", deviceProp.memoryBusWidth);\n","\t\tif (deviceProp.l2CacheSize)\n","\t\t\tprintf(\"  L2 Cache Size:                                 %d bytes\\n\", deviceProp.l2CacheSize);\n","\n","\t\tprintf(\"  Maximum Texture Dimension Size (x,y,z)         1D=(%d), 2D=(%d, %d), 3D=(%d, %d, %d)\\n\",\n","\t\t\t\tdeviceProp.maxTexture1D, deviceProp.maxTexture2D[0],\n","\t\t\t\tdeviceProp.maxTexture2D[1], deviceProp.maxTexture3D[0],\n","\t\t\t\tdeviceProp.maxTexture3D[1], deviceProp.maxTexture3D[2]);\n","\n","\t\tprintf(\"  Maximum Layered 1D Texture Size, (num) layers  1D=(%d), %d layers\\n\",\n","\t\t\t\tdeviceProp.maxTexture1DLayered[0],\n","\t\t\t\tdeviceProp.maxTexture1DLayered[1]);\n","\n","\t\tprintf(\"  Maximum Layered 2D Texture Size, (num) layers  2D=(%d, %d), %d layers\\n\",\n","\t\t\t\tdeviceProp.maxTexture2DLayered[0],\n","\t\t\t\tdeviceProp.maxTexture2DLayered[1],\n","\t\t\t\tdeviceProp.maxTexture2DLayered[2]);\n","\n","\t\tprintf(\"  Total amount of constant memory                %lu bytes\\n\",\n","\t\t\t\tdeviceProp.totalConstMem);\n","\t\tprintf(\"  Total amount of shared memory per block        %lu bytes\\n\",\n","\t\t\t\tdeviceProp.sharedMemPerBlock);\n","\t\tprintf(\"  Total number of registers available per block  %d\\n\",\n","\t\t\t\tdeviceProp.regsPerBlock);\n","\t\tprintf(\"  Warp size                                      %d\\n\",\n","\t\t\t\tdeviceProp.warpSize);\n","\t\tprintf(\"  Maximum number of threads per multiprocessor   %d\\n\",\n","\t\t\t\tdeviceProp.maxThreadsPerMultiProcessor);\n","\t\tprintf(\"  Maximum number of threads per block            %d\\n\",\n","\t\t\t\tdeviceProp.maxThreadsPerBlock);\n","\t\tprintf(\"  Max dimension size of a thread block (x,y,z)  (%d, %d, %d)\\n\",\n","\t\t\t\tdeviceProp.maxThreadsDim[0], deviceProp.maxThreadsDim[1],\n","\t\t\t\tdeviceProp.maxThreadsDim[2]);\n","\t\tprintf(\"  Max dimension size of a grid size    (x,y,z)  (%d, %d, %d)\\n\",\n","\t\t\t\tdeviceProp.maxGridSize[0], deviceProp.maxGridSize[1],\n","\t\t\t\tdeviceProp.maxGridSize[2]);\n","\t\tprintf(\"  Maximum memory pitch                           %lu bytes\\n\",\n","\t\t\t\tdeviceProp.memPitch);\n","\t\tprintf(\"  Texture alignment                              %lu bytes\\n\",\n","\t\t\t\tdeviceProp.textureAlignment);\n","\t\tprintf(\"  Concurrent copy and kernel execution           %s with %d copy engine(s)\\n\",\n","\t\t\t\t(deviceProp.deviceOverlap ? \"Yes\" : \"No\"),\n","\t\t\t\tdeviceProp.asyncEngineCount);\n","\t\tprintf(\"  Run time limit on kernels                      %s\\n\",\n","\t\t\t\tdeviceProp.kernelExecTimeoutEnabled ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Integrated GPU sharing Host Memory             %s\\n\",\n","\t\t\t\tdeviceProp.integrated ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Support host page-locked memory mapping        %s\\n\",\n","\t\t\t\tdeviceProp.canMapHostMemory ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Alignment requirement for Surfaces             %s\\n\",\n","\t\t\t\tdeviceProp.surfaceAlignment ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Device has ECC support                         %s\\n\",\n","\t\t\t\tdeviceProp.ECCEnabled ? \"Enabled\" : \"Disabled\");\n","\n","\t\tprintf(\"  Device supports Unified Addressing (UVA):      %s\\n\",\n","\t\t\t\tdeviceProp.unifiedAddressing ? \"Yes\" : \"No\");\n","\t\tprintf(\"  Device PCI Domain ID / Bus ID / location ID:   %d / %d / %d\\n\",\n","\t\t\t\tdeviceProp.pciDomainID, deviceProp.pciBusID,\n","\t\t\t\tdeviceProp.pciDeviceID);\n","\t}\n","\treturn 0;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Several API functions exist to assist programmers in choosing thread block size and cluster size based on register and shared memory requirements.\n","\n","- `cudaOccupancyMaxActiveBlocksPerMultiprocessor`, is the occupancy calculator API that provides an **occupancy prediction based on the block size and shared memory usage** of a kernel. This function reports occupancy in terms of the number of concurrent thread blocks per multiprocessor.\n","Note that this value can be converted to other metrics. Multiplying by the number of warps per block yields the number of concurrent warps per multiprocessor; further dividing concurrent warps by max warps per multiprocessor gives the occupancy as a percentage.\n","- `cudaOccupancyMaxPotentialBlockSize` and `cudaOccupancyMaxPotentialBlockSizeVariableSMem`, are the occupancy-based launch configurator APIs, **heuristically calculate an execution configuration that achieves the maximum multiprocessor-level occupancy.**\n","- `cudaOccupancyMaxActiveClusters`, can provided occupancy prediction based on the cluster size, block size and shared memory usage of a kernel. This function reports occupancy in terms of number of max active clusters of a given size on the GPU present in the system."],"metadata":{"id":"evll6aSlzVtd"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","The following code sample calculates the occupancy of MyKernel. It then reports the occupancy level with the **ratio between concurrent warps versus maximum warps per multiprocessor**."],"metadata":{"id":"JSbDdWC3zzHX"}},{"cell_type":"code","source":["%%cuda_group_save --name \"occupancy.cu\" --group \"OCC\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","\n","// Device code\n","__global__ void MyKernel(int *d, int *a, int *b) {\n","  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","  d[idx] = a[idx] * b[idx];\n","}\n","\n","// Host code\n","int main() {\n","  device_feat();    // device feats\n","  int numBlocks;    // number of of active blocks\n","\n","  // These variables are used to convert occupancy to warps\n","  int device;\n","  cudaDeviceProp prop;\n","  int activeWarps;\n","  int maxWarps;\n","\n","  cudaGetDevice(&device);\n","  cudaGetDeviceProperties(&prop, device);\n","  maxWarps = prop.maxThreadsPerMultiProcessor / prop.warpSize;\n","\n","  for (int blockSize = 16; blockSize <= 1024; blockSize*=2) {\n","    cudaOccupancyMaxActiveBlocksPerMultiprocessor(&numBlocks, MyKernel, blockSize, 0);\n","    activeWarps = numBlocks * blockSize / prop.warpSize;\n","    double occup = (double)activeWarps / maxWarps * 100;\n","    printf(\"blockSize = %4d <-> Occupancy [numBlocks = %2d,  activeWarps = %2d]:\\t%2.2f%%\\n\", blockSize, numBlocks, activeWarps, occup);\n","  }\n","  return 0;\n","}"],"metadata":{"id":"13Kv4NcSOanG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_75 src/OCC/occupancy.cu -o occupancy\n","!./occupancy"],"metadata":{"id":"sXoLaamxSk33"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","The following code sample configures an occupancy-based kernel launch of MyKernel according to the user input.\n"],"metadata":{"id":"JoXN6tHHz5AV"}},{"cell_type":"code","source":["%%cuda_group_save --name \"occupancy.cu\" --group \"OCC\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","\n","// Device code\n","__global__ void MyKernel(float *array, int arrayCount) {\n","  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","  if (idx < arrayCount)\n","    array[idx] *= array[idx];\n","}\n","\n","__global__ void MyKernel1(int *d, int *a, int *b) {\n","  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","  d[idx] = a[idx] * b[idx];\n","}\n","\n","// occupancy calculator\n","int occupancy(float *array, int arrayCount) {\n","  int blockSize;      // The launch configurator returned block size\n","  int minGridSize;    // The minimum grid size needed to achieve the\n","                      // maximum occupancy for a full device launch\n","  int gridSize;       // The actual grid size needed, based on input size\n","\n","  cudaOccupancyMaxPotentialBlockSize(&minGridSize, &blockSize, (void*)MyKernel, 0, arrayCount);\n","\n","  // Round up according to array size\n","  gridSize = (arrayCount + blockSize - 1) / blockSize;\n","  printf(\"blockSize = %4d, gridSize = %d, minGridSize = %2d\\n\", blockSize, gridSize, minGridSize);\n","\n","  MyKernel<<<gridSize, blockSize>>>(array, arrayCount);\n","  cudaDeviceSynchronize();\n","\n","  // compute occupancy\n","  int device;\n","  int numBlocks;\n","  cudaDeviceProp prop;\n","  cudaGetDevice(&device);\n","  cudaGetDeviceProperties(&prop, device);\n","  int maxWarps = prop.maxThreadsPerMultiProcessor / prop.warpSize;\n","  cudaOccupancyMaxActiveBlocksPerMultiprocessor(&numBlocks, MyKernel, blockSize, 0);\n","  int activeWarps = numBlocks * blockSize / 32;\n","  double occup = (double)activeWarps / maxWarps * 100;\n","  printf(\"Occupancy [blockSize = %4d, activeWarps = %2d]:\\t%2.2f%%\\n\", blockSize, activeWarps, occup);\n","\n","  return 0;\n","}\n","\n","// MAIN\n","int main(void) {\n","  device_feat();    // device feats\n","  int N = 2<<20;\n","  size_t size = N * sizeof(float);\n","\n","  // Allocate input vectors h_A and h_B in host memory\n","  float* h_A = (float*)malloc(size);\n","  float* h_B = (float*)malloc(size);\n","  float* h_C = (float*)malloc(size);\n","\n","  // Allocate vectors in device memory\n","  float* d_A;\n","  cudaMalloc(&d_A, size);\n","  float* d_B;\n","  cudaMalloc(&d_B, size);\n","  float* d_C;\n","  cudaMalloc(&d_C, size);\n","\n","  // Copy vectors from host memory to device memory\n","  cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","  cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","  // Invoke kernel\n","  occupancy(d_A, N);\n","\n","  // Free device memory\n","  cudaFree(d_A);\n","  cudaFree(d_B);\n","  cudaFree(d_C);\n","\n","  return 0;\n","}"],"metadata":{"id":"o-tdfCu8LWfM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_75  src/OCC/occupancy.cu -o occupancy\n","!./occupancy"],"metadata":{"id":"vGWag71kX1Ad"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ↘️ *`TODO...`*"],"metadata":{"id":"hlvdDnAdHaee"}},{"cell_type":"markdown","source":["Apply the same calculator to the kernel:\n","\n","```\n","__global__ void blockParReduce1(int *in, int *out, ulong n)\n","```\n","\n"],"metadata":{"id":"lv1svOfqJFPr"}},{"cell_type":"code","source":["%%cuda_group_save --name \"occupancy.cu\" --group \"OCC\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","__global__ void blockParReduce1(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","\t// in-place reduction in global memory\n","\tfor (int stride = 1; stride < blockDim.x; stride *= 2) {\n","\t\tif ((tid % (2 * stride)) == 0)\n","\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","// MAIN\n","int main(void) {\n","  int numBlocks;        // Occupancy in terms of active blocks\n","\n","  // These variables are used to convert occupancy to warps\n","  int device;\n","  cudaDeviceProp prop;\n","  int activeWarps;\n","  int maxWarps;\n","\n","  cudaGetDevice(&device);\n","  cudaGetDeviceProperties(&prop, device);\n","  maxWarps = prop.maxThreadsPerMultiProcessor / prop.warpSize;\n","\n","  for (int blockSize = 16; blockSize <= 1024; blockSize*=2) {\n","    cudaOccupancyMaxActiveBlocksPerMultiprocessor(&numBlocks, blockParReduce1, blockSize, 0);\n","    activeWarps = numBlocks * blockSize / prop.warpSize;\n","    double occup = (double)activeWarps / maxWarps * 100;\n","    printf(\"Occupancy [blockSize = %4d, activeWarps = %2d]:\\t%2.2f%%\\n\", blockSize, activeWarps, occup);\n","  }\n","  return 0;\n","}"],"metadata":{"id":"8BSlGWgvHaCl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_75 --ptxas-options=-v src/OCC/occupancy.cu -o occupancy\n","!./occupancy"],"metadata":{"id":"I2H9W15WYKaE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Apply the same calculator to the kernel:\n","\n","```\n","__global__ void blockParReduce_SMEM(int *in, int *out, ulong n)\n","```\n"],"metadata":{"id":"PL72zrGpYB8U"}},{"cell_type":"code","source":["%%cuda_group_save --name \"occupancy.cu\" --group \"OCC\"\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","#define SMEM_DIM 1024\n","\n","/*\n","    This version uses sequential addressing -- no divergence or bank conflicts.\n","*/\n","__global__ void blockParReduce_SMEM(int *in, int *out, ulong n) {\n","\n","\t// shared mem\n","\t__shared__ int smem[SMEM_DIM];\n","\n","\tunsigned int tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// load shared mem\n","\tsmem[tid] = (idx < n) ? in[idx] : 0;\n","\n","\t// synchronize within threadblock\n","\t__syncthreads();\n","\n","\t// do reduction in shared mem\n","\tfor (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n","\t\tif (tid < stride)\n","\t\t\tsmem[tid] += smem[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = smem[0];\n","}\n","\n","\n","// MAIN\n","int main(void) {\n","  int numBlocks;        // Occupancy in terms of active blocks\n","\n","  // These variables are used to convert occupancy to warps\n","  int device;\n","  cudaDeviceProp prop;\n","  int activeWarps;\n","  int maxWarps;\n","\n","  cudaGetDevice(&device);\n","  cudaGetDeviceProperties(&prop, device);\n","  maxWarps = prop.maxThreadsPerMultiProcessor / prop.warpSize;\n","\n","  for (int blockSize = 16; blockSize <= 1024; blockSize*=2) {\n","    cudaOccupancyMaxActiveBlocksPerMultiprocessor(&numBlocks, blockParReduce_SMEM, blockSize, 0);\n","    activeWarps = numBlocks * blockSize / prop.warpSize;\n","    double occup = (double)activeWarps / maxWarps * 100;\n","    printf(\"Occupancy [blockSize = %4d, activeWarps = %2d]:\\t%2.2f%%\\n\", blockSize, activeWarps, occup);\n","  }\n","  return 0;\n","}"],"metadata":{"id":"2Yw-iUA9UcX0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_75 --ptxas-options=-v src/OCC/occupancy.cu -o occupancy\n","!./occupancy"],"metadata":{"id":"Rq5tZidEYNtQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_75 --ptxas-options=-v src/OCC/occupancy.cu"],"metadata":{"id":"J6l-x5kymaN0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ✅ Profiling"],"metadata":{"id":"1snOeEsH_5z3"}},{"cell_type":"code","source":["%%cuda_group_save --name \"preduce.cu\" --group \"OCC\"\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <assert.h>\n","#include \"/content/GPUcomputing/utils/helper_string.h\"\n","#include \"/content/GPUcomputing/utils/helper_cuda.h\"\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","\n","/*\n"," *  Block by block parallel implementation with divergence (sequential schema)\n"," */\n","__global__ void blockParReduce1(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","\t// in-place reduction in global memory\n","\tfor (int stride = 1; stride < blockDim.x; stride *= 2) {\n","\t\tif ((tid % (2 * stride)) == 0)\n","\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","/*\n"," *  Block by block parallel implementation without divergence (interleaved schema)\n"," */\n","__global__ void blockParReduce2(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","\t// in-place reduction in global memory\n","\tfor (int stride = blockDim.x / 2; stride > 0; stride >>= 1)  {\n","\t\tif (tid < stride)\n","\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","\n","/*\n"," * MAIN: test on parallel reduction\n"," */\n","int main(void) {\n","\tint *a, *b, *d_a, *d_b;\n","\tint blockSize = 1024;            // block dim 1D\n","\tulong numBlock = 1024*1024;      // grid dim 1D\n","\tulong n = blockSize * numBlock;  // array dim\n","\tlong sum_CPU = 0, sum_GPU;\n","\tlong nByte = n*sizeof(int), mByte = numBlock * sizeof(int);\n","\tdouble start, stopGPU, stopCPU, speedup;\n","\n","\tprintf(\"\\n****  test on parallel reduction  ****\\n\");\n","\n","\t// init\n","\ta = (int *) malloc(nByte);\n","\tb = (int *) malloc(mByte);\n","\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n","\n","\tCHECK(cudaMalloc((void **) &d_a, nByte));\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void **) &d_b, mByte));\n","\tCHECK(cudaMemset((void *) d_b, 0, mByte));\n","\n","\t/***********************************************************/\n","\t/*                     CPU reduction                       */\n","\t/***********************************************************/\n","\tprintf(\"  Vector length: %.2f MB\\n\",n/(1024.0*1024.0));\n","\tprintf(\"\\n  CPU procedure...\\n\");\n","\tstart = seconds();\n","\tfor (ulong i = 0; i < n; i++)\n","    sum_CPU += a[i];\n","\tstopCPU = seconds() - start;\n","\tprintf(\"    Elapsed time: %f (sec) \\n\", stopCPU);\n","\tprintf(\"    sum: %lu\\n\",sum_CPU);\n","\n","\tprintf(\"\\n  GPU kernels (mem required %lu bytes)\\n\", nByte);\n","\n","\t/***********************************************************/\n","\t/*         KERNEL blockParReduce1 (divergent)              */\n","\t/***********************************************************/\n","\t// block by block parallel implementation with divergence\n","\tprintf(\"\\n  Launch kernel: blockParReduce1...\\n\");\n","\tstart = seconds();\n","\tblockParReduce1<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaGetLastError());\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\n","  // memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\n","  // check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++)\n","\t\tsum_GPU += b[i];\n","\tassert(sum_GPU == n);\n","\n","\t// reset input vector on GPU\n","\tfor (ulong i = 0; i < n; i++) a[i]=1;\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\n","\t/***********************************************************/\n","\t/*        KERNEL blockParReduce2  (non divergent)          */\n","\t/***********************************************************/\n","\t// block by block parallel implementation without divergence\n","\tprintf(\"\\n  Launch kernel: blockParReduce2...\\n\");\n","\tstart = seconds();\n","\tblockParReduce2<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\tCHECK(cudaGetLastError());\n","\n","  // memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\n","  // check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++) {\n","\t\tsum_GPU += b[i];\n","  //\t\tprintf(\"b[%d] = %d\\n\",i,b[i]);\n","\t}\n","\tassert(sum_GPU == n);\n","\n","  // reset input vector on GPU\n","\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++)\n","\t\tsum_GPU += b[i];\n","\tassert(sum_GPU == n);\n","\n","\tcudaFree(d_a);\n","\n","\tCHECK(cudaDeviceReset());\n","\treturn 0;\n","}"],"metadata":{"id":"URVoVFZajMAD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -O2 -arch=sm_75  src/OCC/preduce.cu -o preduce\n","!./preduce\n","\n","!ncu preduce\n","!ncu -o preduce_profile preduce"],"metadata":{"id":"K8YvyTng_-iC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ✅ Parallel reduction unrolling\n","\n","\n"],"metadata":{"id":"OHR7Zs3dNs1N"}},{"cell_type":"code","source":["%%cuda_group_save --name \"preduceUNROLL.cu\" --group \"UNROLL\"\n","\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#include \"/content/GPUcomputing/utils/common.h\"\n","\n","\n","#define DIM 1024\n","\n","/*\n"," * An example of using shared memory to optimize performance of a parallel\n"," * reduction by constructing partial results for a thread block in shared memory\n"," * before flushing to global memory.\n"," */\n","\n","extern __shared__ int dsmem[];\n","\n","//# Recursive Implementation of Interleaved Pair Approach\n","int recursiveReduce(int *data, int const size) {\n","  if (size == 1) return data[0];\n","\n","  int const stride = size / 2;\n","\n","  for (int i = 0; i < stride; i++)\n","    data[i] += data[i + stride];\n","\n","  return recursiveReduce(data, stride);\n","}\n","\n","__device__ void warpReduce(volatile int *smem, unsigned int tid) {\n","  smem[tid] = min(smem[tid],smem[tid+32]);\n","  smem[tid] = min(smem[tid],smem[tid+16]);\n","  smem[tid] = min(smem[tid],smem[tid+8]);\n","  smem[tid] = min(smem[tid],smem[tid+4]);\n","  smem[tid] = min(smem[tid],smem[tid+2]);\n","  smem[tid] = min(smem[tid],smem[tid+1]);\n","}\n","\n","//# unroll4 + complete unroll for loop + gmem\n","__global__ void reduceGmem(int *g_idata, int *g_odata, unsigned int n) {\n","    //# set thread ID\n","    unsigned int tid = threadIdx.x;\n","    int *idata = g_idata + blockIdx.x * blockDim.x;\n","\n","    //# boundary check\n","    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (idx >= n) return;\n","\n","    //# in-place reduction in global memory\n","    if (blockDim.x >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 512 && tid < 256) idata[tid] += idata[tid + 256];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 256 && tid < 128) idata[tid] += idata[tid + 128];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 128 && tid < 64) idata[tid] += idata[tid + 64];\n","\n","    __syncthreads();\n","\n","    // unrolling warp\n","    if (tid < 32)\n","      warpReduce(idata, tid);\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n","}\n","\n","__global__ void reduceSmem(int *g_idata, int *g_odata, unsigned int n) {\n","    __shared__ int smem[DIM];\n","\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","\n","    // boundary check\n","    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (idx >= n) return;\n","\n","    // convert global data pointer to the local pointer of this block\n","    int *idata = g_idata + blockIdx.x * blockDim.x;\n","\n","    // set to smem by each threads\n","    smem[tid] = idata[tid];\n","    __syncthreads();\n","\n","    // in-place reduction in shared memory\n","    if (blockDim.x >= 1024 && tid < 512) smem[tid] += smem[tid + 512];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 512 && tid < 256) smem[tid] += smem[tid + 256];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 256 && tid < 128) smem[tid] += smem[tid + 128];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 128 && tid < 64)  smem[tid] += smem[tid + 64];\n","\n","    __syncthreads();\n","\n","    // unrolling warp\n","    if (tid < 32)\n","      warpReduce(smem, tid);\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n","}\n","\n","__global__ void reduceSmemDyn(int *g_idata, int *g_odata, unsigned int n) {\n","    extern __shared__ int smem[];\n","\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    int *idata = g_idata + blockIdx.x * blockDim.x;\n","\n","    // set to smem by each threads\n","    smem[tid] = idata[tid];\n","    __syncthreads();\n","\n","    // in-place reduction in global memory\n","    if (blockDim.x >= 1024 && tid < 512)  smem[tid] += smem[tid + 512];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 512 && tid < 256)  smem[tid] += smem[tid + 256];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 256 && tid < 128) smem[tid] += smem[tid + 128];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 128 && tid < 64) smem[tid] += smem[tid + 64];\n","\n","    __syncthreads();\n","\n","    // unrolling warp\n","    if (tid < 32)\n","      warpReduce(smem, tid);\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n","}\n","\n","\n","int main(int argc, char **argv) {\n","  // set up device\n","  int dev = 0;\n","  cudaDeviceProp deviceProp;\n","  CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","  printf(\"%s starting reduction at \", argv[0]);\n","  printf(\"device %d: %s \", dev, deviceProp.name);\n","  CHECK(cudaSetDevice(dev));\n","\n","  bool bResult = false;\n","\n","  // initialization\n","  int power = 10;\n","\n","  // execution configuration\n","  int blocksize = DIM;   // initial block size\n","\n","  if (argc >= 2)\n","      blocksize = atoi(argv[1]);\n","\n","  if (argc >= 3)\n","      power = atoi(argv[2]);\n","\n","  int size = 1 << power; // total number of elements to reduce\n","  printf(\"    with array size %d  \", size);\n","\n","  dim3 block (blocksize, 1);\n","  dim3 grid  ((size + block.x - 1) / block.x, 1);\n","  printf(\"grid %d block %d\\n\", grid.x, block.x);\n","\n","  // allocate host memory\n","  size_t bytes = size * sizeof(int);\n","  int *h_idata = (int *) malloc(bytes);\n","  int *h_odata = (int *) malloc(grid.x * sizeof(int));\n","  int *tmp     = (int *) malloc(bytes);\n","\n","  // initialize the array\n","  for (int i = 0; i < size; i++)\n","    h_idata[i] = (int)( rand() & 0xFF );\n","\n","  memcpy (tmp, h_idata, bytes);\n","\n","  int gpu_sum = 0;\n","\n","  // allocate device memory\n","  int *d_idata = NULL;\n","  int *d_odata = NULL;\n","  CHECK(cudaMalloc((void **) &d_idata, bytes));\n","  CHECK(cudaMalloc((void **) &d_odata, grid.x * sizeof(int)));\n","\n","  // cpu reduction\n","  int cpu_sum = recursiveReduce (tmp, size);\n","  printf(\"cpu reduce          : %d\\n\", cpu_sum);\n","\n","  // reduce gmem\n","  CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","  reduceNeighboredGmem<<<grid.x, block>>>(d_idata, d_odata, size);\n","  CHECK(cudaGetLastError());\n","  CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int), cudaMemcpyDeviceToHost));\n","  gpu_sum = 0;\n","\n","  for (int i = 0; i < grid.x; i++)\n","    gpu_sum += h_odata[i];\n","\n","  printf(\"reduceNeighboredGmem: %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x, block.x);\n","\n","  // reduce gmem\n","  CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","  reduceNeighboredSmem<<<grid.x, block>>>(d_idata, d_odata, size);\n","  CHECK(cudaGetLastError());\n","  CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int), cudaMemcpyDeviceToHost));\n","  gpu_sum = 0;\n","\n","  for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n","\n","  printf(\"reduceNeighboredSmem: %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x, block.x);\n","\n","  // reduce gmem\n","  CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","  reduceGmem<<<grid.x, block>>>(d_idata, d_odata, size);\n","  CHECK(cudaGetLastError());\n","  CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int), cudaMemcpyDeviceToHost));\n","  gpu_sum = 0;\n","\n","  for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n","\n","  printf(\"reduceGmem          : %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x, block.x);\n","\n","  // reduce smem\n","  CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","  reduceSmem<<<grid.x, block>>>(d_idata, d_odata, size);\n","  CHECK(cudaGetLastError());\n","  CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int), cudaMemcpyDeviceToHost));\n","  gpu_sum = 0;\n","\n","  for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n","\n","  printf(\"reduceSmem          : %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x, block.x);\n","\n","  // reduce smem\n","  CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","  reduceSmemDyn<<<grid.x, block, blocksize*sizeof(int)>>>(d_idata, d_odata,\n","          size);\n","  CHECK(cudaGetLastError());\n","  CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int), cudaMemcpyDeviceToHost));\n","  gpu_sum = 0;\n","\n","  for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n","\n","  printf(\"reduceSmemDyn       : %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x, block.x);\n","\n","  // reduce gmem\n","  CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","  reduceGmemUnroll<<<grid.x / 4, block>>>(d_idata, d_odata, size);\n","  CHECK(cudaGetLastError());\n","  CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(int), cudaMemcpyDeviceToHost));\n","  gpu_sum = 0;\n","\n","  for (int i = 0; i < grid.x / 4; i++) gpu_sum += h_odata[i];\n","\n","  printf(\"reduceGmemUnroll4   : %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x / 4, block.x);\n","\n","  // reduce smem\n","  CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","  reduceSmemUnroll<<<grid.x / 4, block>>>(d_idata, d_odata, size);\n","  CHECK(cudaGetLastError());\n","  CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(int), cudaMemcpyDeviceToHost));\n","  gpu_sum = 0;\n","\n","  for (int i = 0; i < grid.x / 4; i++) gpu_sum += h_odata[i];\n","\n","  printf(\"reduceSmemUnroll4   : %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x / 4, block.x);\n","\n","  // reduce smem\n","  CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","  reduceSmemUnrollDyn<<<grid.x / 4, block, DIM*sizeof(int)>>>(d_idata, d_odata, size);\n","  CHECK(cudaGetLastError());\n","  CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(int), cudaMemcpyDeviceToHost));\n","  gpu_sum = 0;\n","\n","  for (int i = 0; i < grid.x / 4; i++) gpu_sum += h_odata[i];\n","\n","  printf(\"reduceSmemDynUnroll4: %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x / 4, block.x);\n","\n","  // free host memory\n","  free(h_idata);\n","  free(h_odata);\n","\n","  // free device memory\n","  CHECK(cudaFree(d_idata));\n","  CHECK(cudaFree(d_odata));\n","\n","  // reset device\n","  CHECK(cudaDeviceReset());\n","\n","  // check the results\n","  bResult = (gpu_sum == cpu_sum);\n","\n","  if(!bResult) printf(\"Test failed!\\n\");\n","\n","  return EXIT_SUCCESS;\n","}\n"],"metadata":{"id":"aF_XWzGyNmBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_75  src/UNROLL/preduceUNROLL.cu -o preduce\n","!./preduce 1024 20"],"metadata":{"id":"HCyY1Y8_sB0S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_75 --ptxas-options=-v src/preduceSMEM.cu -o preduce\n","!./preduce 1024 20"],"metadata":{"id":"sCBstFF3U1Ya"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ↘️ *`TODO...`*"],"metadata":{"id":"4RYX2IU4dwaw"}},{"cell_type":"markdown","source":["Kernel privo di divergenza + unrolling:\n","\n","* Introdurre warp unrolling\n","* Introdurre block unrolling\n","* Specializzare su diversi num blocchi\n","* Confrontare i vari kernel...\n","\n","\n"],"metadata":{"id":"WK1z7xCcSz5v"}},{"cell_type":"code","source":["%%cuda_group_save --name \"preduceUnroll.cu\" --group \"OCC\"\n","\n","#include <assert.h>\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","\n","/*\n"," *  Device function: block parallel reduction based on warp unrolling\n"," */\n","__device__ void blockWarpUnroll(int *thisBlock, int blockDim, uint tid) {\n","  // in-place reduction in global memory\n","    for (int stride = blockDim / 2; stride > 32; stride >>= 1)  {\n","      if (tid < stride)\n","        thisBlock[tid] += thisBlock[tid + stride];\n","\n","      // synchronize within threadblock\n","      __syncthreads();\n","    }\n","\n","    // unrolling warp\n","    if (tid < 32) {\n","      volatile int *vmem = thisBlock;\n","      vmem[tid] += vmem[tid + 32];\n","      vmem[tid] += vmem[tid + 16];\n","      vmem[tid] += vmem[tid + 8];\n","      vmem[tid] += vmem[tid + 4];\n","      vmem[tid] += vmem[tid + 2];\n","      vmem[tid] += vmem[tid + 1];\n","    }\n","}\n","\n","/*\n"," *  Block by block parallel implementation with warp unrolling\n"," */\n","__global__ void blockParReduceUroll(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","  // block parall. reduction based on warp unrolling\n","  blockWarpUnroll(thisBlock, blockDim.x, tid);\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","/*\n"," *  Multi block parallel implementation with block and warp unrolling\n"," */\n","__global__ void multBlockParReduceUroll8(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x * 8;\n","\n","    // unrolling 8 blocks\n","    if (idx + 7 * blockDim.x < n) {\n","        int a1 = in[idx];\n","        int a2 = in[idx + blockDim.x];\n","        int a3 = in[idx + 2 * blockDim.x];\n","        int a4 = in[idx + 3 * blockDim.x];\n","        int a5 = in[idx + 4 * blockDim.x];\n","        int a6 = in[idx + 5 * blockDim.x];\n","        int a7 = in[idx + 6 * blockDim.x];\n","        int a8 = in[idx + 7 * blockDim.x];\n","        in[idx] = a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8;\n","    }\n","    __syncthreads();\n","\n","\t// block parall. reduction based on warp unrolling\n","  blockWarpUnroll(thisBlock, blockDim.x, tid);\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","/*\n"," *  Multi block parallel implementation with block and warp unrolling\n"," */\n","__global__ void multBlockParReduceUroll16(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x * 16 + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x * 16;\n","\n","    // unrolling 16 blocks\n","    if (idx + 15 * blockDim.x < n) {\n","    \tint a1 = in[idx];\n","    \tint a2 = in[idx + blockDim.x];\n","    \tint a3 = in[idx + 2 * blockDim.x];\n","    \tint a4 = in[idx + 3 * blockDim.x];\n","    \tint a5 = in[idx + 4 * blockDim.x];\n","    \tint a6 = in[idx + 5 * blockDim.x];\n","    \tint a7 = in[idx + 6 * blockDim.x];\n","    \tint a8 = in[idx + 7 * blockDim.x];\n","    \tint a9 = in[idx + 8 * blockDim.x];\n","    \tint a10 = in[idx + 9 * blockDim.x];\n","    \tint a11 = in[idx + 10 * blockDim.x];\n","    \tint a12 = in[idx + 11 * blockDim.x];\n","    \tint a13 = in[idx + 12 * blockDim.x];\n","    \tint a14 = in[idx + 13 * blockDim.x];\n","    \tint a15 = in[idx + 14 * blockDim.x];\n","    \tint a16 = in[idx + 15 * blockDim.x];\n","    \tin[idx] = a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8+\n","    \t\t\ta9 + a10 + a11 + a12 + a13 + a14 + a15 + a16;\n","    }\n","    __syncthreads();\n","\n","\t// block parall. reduction based on warp unrolling\n","  blockWarpUnroll(thisBlock, blockDim.x, tid);\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","/*\n"," *  Block by block parallel implementation without divergence (interleaved schema)\n"," */\n","__global__ void blockParReduce2(int *in, int *out, ulong n) {\n","\n","\tuint tid = threadIdx.x;\n","\tulong idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// boundary check\n","\tif (idx >= n)\n","\t\treturn;\n","\n","\t// convert global data pointer to the local pointer of this block\n","\tint *thisBlock = in + blockIdx.x * blockDim.x;\n","\n","\t// in-place reduction in global memory\n","\tfor (int stride = blockDim.x / 2; stride > 0; stride >>= 1)  {\n","\t\tif (tid < stride)\n","\t\t\tthisBlock[tid] += thisBlock[tid + stride];\n","\n","\t\t// synchronize within threadblock\n","\t\t__syncthreads();\n","\t}\n","\n","\t// write result for this block to global mem\n","\tif (tid == 0)\n","\t\tout[blockIdx.x] = thisBlock[0];\n","}\n","\n","\n","\n","/*\n"," * MAIN: test on parallel reduction\n"," */\n","int main(void) {\n","\tint *a, *b, *d_a, *d_b;\n","\tint blockSize = 1024;            // block dim 1D\n","\tulong numBlock = 1024*1024;      // grid dim 1D\n","\tulong n = blockSize * numBlock;  // array dim\n","\tlong sum_CPU = 0, sum_GPU;\n","\tlong nByte = n*sizeof(int), mByte = numBlock * sizeof(int);\n","\tdouble start, stopGPU, stopCPU, speedup;\n","\n","\tprintf(\"\\n****  test on parallel reduction  ****\\n\");\n","\n","\t// init\n","\ta = (int *) malloc(nByte);\n","\tb = (int *) malloc(mByte);\n","\tCHECK(cudaMalloc((void **) &d_a, nByte));\n","\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void **) &d_b, mByte));\n","\tCHECK(cudaMemset((void *) d_b, 0, mByte));\n","\n","\t/***********************************************************/\n","\t/*                     CPU reduction                       */\n","\t/***********************************************************/\n","\tprintf(\"  Vector length: %.2f GB\\n\",n/(1024.0*1024.0*1024.0));\n","\tprintf(\"\\n  CPU procedure...\\n\");\n","\tstart = seconds();\n","\tfor (ulong i = 0; i < n; i++) sum_CPU += a[i];\n","\tstopCPU = seconds() - start;\n","\tprintf(\"    Elapsed time: %f (sec) \\n\", stopCPU);\n","\tprintf(\"    sum: %lu\\n\",sum_CPU);\n","\n","\tprintf(\"\\n  GPU kernels (mem required %lu bytes)\\n\", nByte);\n","\n","\t/***********************************************************/\n","\t/*        KERNEL blockParReduce2  (non divergent)          */\n","\t/***********************************************************/\n","\t// block by block parallel implementation without divergence\n","\tprintf(\"\\n  Launch kernel: blockParReduce2...\\n\");\n","\tstart = seconds();\n","\tblockParReduce2<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\tCHECK(cudaGetLastError());\n","  // memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","  // check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++) {\n","\t\tsum_GPU += b[i];\n","\t}\n","\tassert(sum_GPU == n);\n","  // reset input vector on GPU\n","\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\n","\t/***********************************************************/\n","\t/*               KERNEL blockParReduceUroll                */\n","\t/***********************************************************/\n","\n","\t// block by block parallel implementation without divergence\n","\tprintf(\"\\n  Launch kernel: blockParReduceUroll...\\n\");\n","\tstart = seconds();\n","\tblockParReduceUroll<<<numBlock, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\tCHECK(cudaGetLastError());\n","\t// memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock; i++)\n","\t\tsum_GPU += b[i];\n","\tassert(sum_GPU == n);\n","\t// reset input vector on GPU\n","\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\n","\t/***********************************************************/\n","\t/*            KERNEL multBlockParReduceUroll8              */\n","\t/***********************************************************/\n","\t// block by block parallel implementation without divergence\n","\tprintf(\"\\n  Launch kernel: multBlockParReduceUroll8...\\n\");\n","\tstart = seconds();\n","\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\tCHECK(cudaGetLastError());\n","\t// memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock/8; i++)\n","\t\tsum_GPU += b[i];\n","\tprintf(\"    sum: %lu\\n\",sum_GPU);\n","\tassert(sum_GPU == n);\n","\t// reset input vector on GPU\n","\tfor (ulong i = 0; i < n; i++) a[i] = 1;\n","\tCHECK(cudaMemcpy(d_a, a, nByte, cudaMemcpyHostToDevice));\n","\n","\t/***********************************************************/\n","\t/*            KERNEL multBlockParReduceUroll16             */\n","\t/***********************************************************/\n","\t// block by block parallel implementation without divergence\n","\tprintf(\"\\n  Launch kernel: multBlockParReduceUroll16...\\n\");\n","\tstart = seconds();\n","\tmultBlockParReduceUroll16<<<numBlock/16, blockSize>>>(d_a, d_b, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tstopGPU = seconds() - start;\n","\tspeedup = stopCPU/stopGPU;\n","\tprintf(\"    Elapsed time: %f (sec) - speedup %.1f\\n\", stopGPU,speedup);\n","\tCHECK(cudaGetLastError());\n","\t// memcopy D2H\n","\tCHECK(cudaMemcpy(b, d_b, mByte, cudaMemcpyDeviceToHost));\n","\t// check result\n","\tsum_GPU = 0;\n","\tfor (uint i = 0; i < numBlock/16; i++)\n","\t\tsum_GPU += b[i];\n","\tassert(sum_GPU == n);\n","\n","\tcudaFree(d_a);\n","\n","\tCHECK(cudaDeviceReset());\n","\treturn 0;\n","}"],"metadata":{"id":"NAeBUVaScJKK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_70 src/preduceUnroll.cu -o preduceUnroll\n","!./preduceUnroll"],"metadata":{"id":"9u9U4XHAncOe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOFMQZAkjlLW"},"source":["# ✅ Parallelismo dinamico"]},{"cell_type":"code","source":["%%cuda --name nestedHelloWorld.cu\n","#include <stdio.h>\n","\n","/*\n"," * A simple example of nested kernel launches from the GPU. Each thread displays\n"," * its information when execution begins, and also diagnostics when the next\n"," * lowest nesting layer completes.\n"," */\n","\n","__global__ void nestedHelloWorld(int const iSize, int iDepth) {\n","\tint tid = threadIdx.x;\n","\tprintf(\"Recursion=%d: Hello World from thread %d block %d\\n\", iDepth, tid,\tblockIdx.x);\n","\n","\t// condition to stop recursive execution\n","\tif (iSize == 1)\n","\t\treturn;\n","\n","\t// reduce block size to half\n","\tint nthreads = iSize >> 1;\n","\n","\n","\t// thread 0 launches child grid recursively\n","\tif (tid == 0 && nthreads > 0) {\n","\t\tnestedHelloWorld<<<gridDim.x, nthreads>>>(nthreads, ++iDepth);\n","\t\tprintf(\"-------> nested execution depth: %d\\n\", iDepth);\n","\t}\n","}\n","\n","int main(int argc, char **argv) {\n","\tint size = 8;\n","\tint blocksize = 8;   // initial block size\n","\tint igrid = 2;\n","\n","\tsize = igrid * blocksize;\n","\n","\tdim3 block(blocksize, 1);\n","\tdim3 grid((size + block.x - 1) / block.x, 1);\n","\tprintf(\"%s Execution Configuration: grid %d block %d\\n\", argv[0], grid.x,\n","\t\t\tblock.x);\n","\n","\tnestedHelloWorld<<<grid, block>>>(block.x, 0);\n","\n","\tcudaDeviceReset();\n","\treturn 0;\n","}"],"metadata":{"id":"WJQmiG5fyEqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_70 -dc src/nestedHelloWorld.cu\n","!nvcc -arch=sm_70 *.o -o nestedHelloWorld\n","!./nestedHelloWorld\n"],"metadata":{"id":"F4AkCagXzdAF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Introdurre il parallelismo dinamico nel calcolo di prodotti MQDB"],"metadata":{"id":"VR2PLOEZz4fD"}},{"cell_type":"code","source":["%%cuda --name mqdb.h\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <string.h>\n","#include <math.h>\n","#include <sys/time.h>\n","#include <time.h>\n","\n","#ifndef MQDB_H\n","#define MQDB_H\n","\n","#define randu() ((float)rand() / (float) RAND_MAX)\n","#define abs(x) ((x)<0 ? (-x) : (x))\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","typedef struct MQDB {\n","\tchar desc[100];   // description\n","\tint nBlocks;      // num. of blocks\n","\tint *blkSize;     // block dimensions\n","\tfloat *elem;       // elements in row-major order\n","\tulong nElems;     // actual number of elements\n","} mqdb;\n","\n","typedef unsigned long ulong;\n","typedef unsigned int uint;\n","\n","// # function prototypes #\n","int genRandDims(mqdb*, uint, uint);\n","void fillBlocks(mqdb*, uint, uint, char, float);\n","mqdb mqdbConst(uint, uint, uint, float);\n","void mqdbProd(mqdb, mqdb, mqdb);\n","void matProd(mqdb, mqdb, mqdb);\n","void checkResult(mqdb, mqdb);\n","void mqdbDisplay(mqdb);\n","\n","#endif"],"metadata":{"id":"lXx-e0jR3mL2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QVQVpcvKjkIk"},"source":["%%cuda --name MQDB-CUDA-DP.cu\n","\n","#include \"mqdb.h\"\n","#include \"../GPUcomputing/utils/common.h\"\n","\n","#define BLOCK_SIZE 16     // block size\n","\n","struct tms {\n","\tdouble GPUtmsMQDB;\n","\tdouble GPUtmsMQDBDynPar1;\n","\tdouble GPUtmsMQDBDynPark;\n","\tfloat density;\n","};\n","\n","// the kernels prototype\n","__global__ void mqdbBlockProd(mqdb, mqdb, mqdb, uint, uint, uint);\n","__global__ void mqdbProdDP1(mqdb, mqdb, mqdb, uint, uint);\n","__global__ void mqdbProdDPk(mqdb, mqdb, mqdb, uint);\n","\n","/*\n"," * Test on MQDB kernels\n"," */\n","void testKernelsMQDB(uint n, uint k, struct tms* times) {\n","\n","\t// mqdb host matrices\n","\tmqdb A, B, C, C1;\n","\n","\t// mqdb device matrices\n","\tmqdb d_A, d_B, d_C;\n","\n","\t// fill in\n","\tA = mqdbConst(n, k, 10, 1);\n","\tB = mqdbConst(n, k, 10, 1);\n","\tC = mqdbConst(n, k, 10, 1);\n","\tC1 = mqdbConst(n, k, 10, 1);\n","\n","\tulong nBytes = n * n * sizeof(float);\n","\tulong kBytes = k * sizeof(uint);\n","\tprintf(\"Memory size required = %.1f (MB)\\n\",(float)nBytes/(1024.0*1024.0));\n","\n","\t// malloc and copy on device memory\n","\td_A.nBlocks = A.nBlocks;\n","\tCHECK(cudaMalloc((void**)&d_A.blkSize, kBytes));\n","\tCHECK(cudaMemcpy(d_A.blkSize, A.blkSize, kBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void**)&d_A.elem, nBytes));\n","\tCHECK(cudaMemcpy(d_A.elem, A.elem, nBytes, cudaMemcpyHostToDevice));\n","\td_B.nBlocks = B.nBlocks;\n","\tCHECK(cudaMalloc((void**)&d_B.blkSize, kBytes));\n","\tCHECK(cudaMemcpy(d_B.blkSize, B.blkSize, kBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void**)&d_B.elem, nBytes));\n","\tCHECK(cudaMemcpy(d_B.elem, B.elem, nBytes, cudaMemcpyHostToDevice));\n","\td_C.nBlocks = C.nBlocks;\n","\tCHECK(cudaMalloc((void**)&d_C.blkSize, kBytes));\n","\tCHECK(cudaMemcpy(d_C.blkSize, C.blkSize, kBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMalloc((void**)&d_C.elem, nBytes));\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\n","\t/***********************************************************/\n","\t/*                     GPU MQDB product                    */\n","\t/***********************************************************/\n","\tprintf(\"Kernel MQDB product...\\n\");\n","\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n","\tdim3 grid((n + block.x - 1) / block.x, (n + block.y - 1) / block.y);\n","\tuint sdim = 0;\n","\tdouble start = seconds();\n","\tfor (uint i = 0; i < k; i++ ) {\n","\t\tuint d = A.blkSize[i];\n","\t\tmqdbBlockProd<<<grid, block>>>(d_A, d_B, d_C, sdim, d, n);\n","\t\tsdim += d;\n","\t}\n","\tCHECK(cudaDeviceSynchronize());\n","\tdouble GPUtime2 = seconds() - start;\n","\tprintf(\"   elapsed time:                    %.2f (sec)\\n\", GPUtime2);\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n","\tcheckResult(C,C1);\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\n","\t/***********************************************************/\n","\t/*              GPU MQDB dynamic par. GRID(1)              */\n","\t/***********************************************************/\n","\tstart = seconds();\n","\tprintf(\"Kernel MQDB product with dynamic parall. GRID(1)...\\n\");\n","\tmqdbProdDP1<<< 1, 1 >>>(d_A, d_B, d_C, k, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tdouble GPUtime3 = seconds() - start;\n","\tprintf(\"   elapsed time:                        %.2f (sec)\\n\", GPUtime3);\n","\tprintf(\"   speedup vs GPU MQDB product:         %.2f\\n\", GPUtime2/GPUtime3);\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n","\tcheckResult(C,C1);\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\n","\t/***********************************************************/\n","\t/*              GPU MQDB dynamic par. GRID(k)              */\n","\t/***********************************************************/\n","\tstart = seconds();\n","\tprintf(\"Kernel MQDB product with dynamic parall. GRID(k)...\\n\");\n","\tmqdbProdDPk<<< 1, k >>>(d_A, d_B, d_C, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tdouble GPUtime4 = seconds() - start;\n","\tprintf(\"   elapsed time:                        %.2f (sec)\\n\", GPUtime4);\n","\tprintf(\"   speedup vs GPU MQDB product:         %.2f\\n\", GPUtime2/GPUtime4);\n","\tprintf(\"   speedup vs GPU MQDB product GRID(1): %.2f\\n\", GPUtime3/GPUtime4);\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C1.elem, d_C.elem, nBytes, cudaMemcpyDeviceToHost));\n","\tcheckResult(C,C1);\n","\tCHECK(cudaMemset(d_C.elem, 0.0, nBytes));\n","\n","\tCHECK(cudaFree(d_A.elem));\n","\tCHECK(cudaFree(d_B.elem));\n","\tCHECK(cudaFree(d_C.elem));\n","\n","\t// collect times\n","\ttimes->GPUtmsMQDB = GPUtime2;\n","\ttimes->GPUtmsMQDBDynPar1 = GPUtime3;\n","\ttimes->GPUtmsMQDBDynPark = GPUtime4;\n","\tfloat den = 0;\n","\tfor (uint j = 0; j < k; j++)\n","\t\tden += A.blkSize[j]*A.blkSize[j];\n","\ttimes->density = den/(n*n);\n","}\n","\n","/*\n"," * main function\n"," */\n","int main(int argc, char *argv[]) {\n","\tuint n = 16*1024;      // matrix size\n","\tuint min_k = 10;       // max num of blocks\n","\tuint max_k = 20;       // max num of blocks\n","\n","\tstruct tms times[max_k-min_k+1];\n","\n","\t// multiple tests on kernels\n","\tfor (uint k = min_k; k <= max_k; k++) {\n","\t\tprintf(\"\\n*****   k = %d --- (avg block size = %f)\\n\",k,(float)n/k);\n","\t\ttestKernelsMQDB(n, k, &times[k-min_k]);\n","\t}\n","\n","\tFILE *fd;\n","\tfd = fopen(\"res.csv\", \"w\");\n","\tif (fd == NULL) {\n","\t\tperror(\"file error!\\n\");\n","\t\texit(1);\n","\t}\n","\n","\t// write results on file\n","\tfprintf(fd,\"num blocks,\");\n","\t\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\t\tfprintf(fd,\"%d,\",j+min_k);\n","\n","\tfprintf(fd,\"\\nKernel MQDB product,\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsMQDB);\n","\n","\tfprintf(fd,\"\\nKernel MQDB product with dynamic parall. GRID(1),\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsMQDBDynPar1);\n","\n","\tfprintf(fd,\"\\nKernel MQDB product with dynamic parall. GRID(k),\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].GPUtmsMQDBDynPark);\n","\n","\tfprintf(fd,\"\\ndensity,\");\n","\tfor (uint j = 0; j <= max_k-min_k; j++)\n","\t\tfprintf(fd,\"%.4f,\",times[j].density);\n","\n","\tfclose(fd);\n","\n","\treturn 0;\n","}\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_70 -dc src/MQDB-CUDA-DP.cu GPUcomputing/lab1/MQDB/mqdb.cpp\n","!nvcc -arch=sm_70 MQDB-CUDA-DP.o mqdb.o -o mqdb_prod\n","!rm -rf *.o\n","!./mqdb_prod"],"metadata":{"id":"_ci8xYBY2oSM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ↘️ *`TODO...`*"],"metadata":{"id":"Z2o3XANQf6Zv"}},{"cell_type":"code","metadata":{"id":"v9nRkLgeB10A"},"source":["%%cuda --name mqdb_DP.cu\n","\n","#include \"../../utils/MQDB/mqdb.h\"\n","\n","#define BLOCK_SIZE 16     // block size\n","\n","\n","/*\n"," * Kernel for block sub-matrix product of mqdb\n"," */\n","__global__ void mqdbBlockProd(mqdb A, mqdb B, mqdb C, uint sdim, uint d, uint n) {\n","\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// jump to the right block sub-matrix\n","\tint  offset = (n+1)*sdim;\n","\n","\t// each thread computes an entry of the product matrix\n","\tif ((row < d) && (col < d)) {\n","\t\tfloat val = 0;\n","\n","\t\tfor (int k = 0; k < d; k++)\n","\t\t\tval += A.elem[row * n + k + offset] * B.elem[k * n + col + offset];\n","\t\tC.elem[row * n + col + offset] = val;\n","\t}\n","}\n","\n","/*\n"," * Kernel for block sub-matrix product of mqdb: parent grid(1)\n"," */\n","__global__ void mqdbProdDP1(mqdb A, mqdb B, mqdb C, uint k, uint n) {\n","\t// using grid(1,1)\n","\tuint sdim = 0;\n","\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n","\tdim3 grid((n + block.x - 1) / block.x, (n + block.y - 1) / block.y);\n","\tfor (uint i = 0; i < k; i++ ) {\n","\t\tuint d = A.blkSize[i];\n","\t\tmqdbBlockProd<<<grid, block>>>(A, B, C, sdim, d, n);\n","\t\tsdim += d;\n","\t}\n","}\n","\n","/*\n"," * Kernel for block sub-matrix product of mqdb: parent grid(k)\n"," */\n","__global__ void mqdbProdDPk(mqdb A, mqdb B, mqdb C, uint n) {\n","\t// using grid(1,k)\n","\tuint i = threadIdx.x;\n","\tuint sdim = 0;\n","\n","\t// block displacement\n","\tuint d = A.blkSize[i];\n","\tif (i > 0) {\n","\t\tfor (uint j = 0; j < i; j++)\n","\t\t\tsdim += A.blkSize[j];\n","\t}\n","\n","\t// grid dims\n","\tdim3 grid((d + blockDim.x - 1) / blockDim.x, (d + blockDim.y - 1) / blockDim.y);\n","\tmqdbBlockProd<<<grid,blockDim>>>(A, B, C, sdim, d, n);\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLxZjCx8bT3s"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_37 -dc MQDB-CUDA-DP/mqdb_DP.cu MQDB-CUDA-DP/main.cu ../utils/MQDB/mqdb.cpp\n","!nvcc -arch=sm_37 mqdb_DP.o main.o mqdb.o -o mqdb_prod\n","!rm -rf *.o\n","!./mqdb_prod"],"execution_count":null,"outputs":[]}]}