{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CUDA_lab6.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["WoJbB3T5Vkw-","_cGSqZovVkxK","zs_a5Vuimily","iUYP4kCJhEIx","OHR7Zs3dNs1N","8B0w12MS4xtP","SOFMQZAkjlLW"],"mount_file_id":"1mk0QXjREp-k_J-pdFfmgoC7-EVmgPyAo","authorship_tag":"ABX9TyP2PgKenUTW0iIvmQZRh3aR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["---\n","# **LAB 6 - Shared memory (SMEM)**\n","---"],"metadata":{"id":"fZYqN0UwVLC_"}},{"cell_type":"markdown","metadata":{"id":"WoJbB3T5Vkw-"},"source":["# ‚ñ∂Ô∏è CUDA setup"]},{"cell_type":"code","metadata":{"id":"Fht2Wy8wVkxJ"},"source":["!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jP2H_YJVkxJ"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## [GPU Compute Capability](https://developer.nvidia.com/cuda-gpus)"],"metadata":{"id":"VKbaxH9wWosO"}},{"cell_type":"markdown","metadata":{"id":"_cGSqZovVkxK"},"source":["## NVCC Plugin for Jupyter notebook\n","\n","*Usage*:\n","\n","\n","*   Load Extension `%load_ext nvcc_plugin`\n","*   Mark a cell to be treated as cuda cell\n","`%%cuda --name example.cu --compile false`\n","\n","**NOTE**: The cell must contain either code or comments to be run successfully. It accepts 2 arguments. `-n | --name` - which is the name of either CUDA source or Header. The name parameter must have extension `.cu` or `.h`. Second argument -c | --compile; default value is false. The argument is a flag to specify if the cell will be compiled and run right away or not. It might be usefull if you're playing in the main function\n","\n","*  We are ready to run CUDA C/C++ code right in your Notebook. For this we need explicitly say to the interpreter, that we want to use the extension by adding `%%cu` at the beginning of each cell with CUDA code. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"RCVhMkqYVkxK"},"source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6PDOytTVkxK"},"source":["%load_ext nvcc_plugin"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bash and data setup"],"metadata":{"id":"cReFlD-VRfZe"}},{"cell_type":"code","source":["#@title Bash setup\n","%%writefile /root/.bashrc\n","\n","# If not running interactively, don't do anything\n","[ -z \"$PS1\" ] && return\n","\n","# don't put duplicate lines in the history. See bash(1) for more options\n","# ... or force ignoredups and ignorespace\n","HISTCONTROL=ignoredups:ignorespace\n","\n","# append to the history file, don't overwrite it\n","shopt -s histappend\n","\n","# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)\n","HISTSIZE=10000\n","HISTFILESIZE=20000\n","\n","# check the window size after each command and, if necessary,\n","# update the values of LINES and COLUMNS.\n","shopt -s checkwinsize\n","\n","# make less more friendly for non-text input files, see lesspipe(1)\n","[ -x /usr/bin/lesspipe ] && eval \"$(SHELL=/bin/sh lesspipe)\"\n","\n","PS1='\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ '\n","\n","# enable color support of ls and also add handy aliases\n","if [ -x /usr/bin/dircolors ]; then\n","    test -r ~/.dircolors && eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\"\n","    alias ls='ls --color=auto'\n","    #alias dir='dir --color=auto'\n","    #alias vdir='vdir --color=auto'\n","\n","    alias grep='grep --color=auto'\n","    alias fgrep='fgrep --color=auto'\n","    alias egrep='egrep --color=auto'\n","fi\n","\n","# some more ls aliases\n","alias ll='ls -lF'\n","alias la='ls -A'\n","alias l='ls -CF'\n","\n","# path setup\n","export PATH=\"./:/usr/local/cuda/bin:$PATH\""],"metadata":{"cellView":"form","id":"O8ICSyy8_GEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!source /root/.bashrc"],"metadata":{"id":"QxIfKO3Ghf7g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Clone GPUcomputing site on github..."],"metadata":{"id":"IYG8Cv4bTzyI"}},{"cell_type":"code","source":["!git clone https://github.com/giulianogrossi/GPUcomputing.git"],"metadata":{"id":"E7jZmHjCT0vu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define some paths..."],"metadata":{"id":"ZarLje6wR_Og"}},{"cell_type":"code","source":["# path setup\n","!mkdir -p /content/GPUcomputing/lab6\n","%cd /content/GPUcomputing/lab6\n","!mkdir -p parReduceSMEM\n","!mkdir -p prodMatSMEM\n","!mkdir -p convolutionSMEM"],"metadata":{"id":"tC-AaOJlkLOO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ‚ñ∂Ô∏è VS Code on Colab"],"metadata":{"id":"zs_a5Vuimily"}},{"cell_type":"code","source":["#@title Colab-ssh tunnel\n","#@markdown Execute this cell to open the ssh tunnel. Check [colab-ssh documentation](https://github.com/WassimBenzarti/colab-ssh) for more details.\n","\n","# Install colab_ssh on google colab\n","!pip install colab_ssh --upgrade\n","\n","from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n","ssh_tunnel_password = \"gpu\" #@param {type: \"string\"}\n","launch_ssh_cloudflared(password=ssh_tunnel_password)\n","\n","# Optional: if you want to clone a Github or Gitlab repository\n","repository_url=\"https://github.com/giulianogrossi/GPUcomputing\" #@param {type: \"string\"}\n","init_git_cloudflared(repository_url)"],"metadata":{"id":"BCf9JxqphHAp","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUYP4kCJhEIx"},"source":["# ‚ñ∂Ô∏è DeviceQuery"]},{"cell_type":"code","metadata":{"id":"kW9b_Yuxi7id"},"source":["# DeviceQuery dell'attuale device (su Colab!)\n","!nvcc /content/GPUcomputing/utils/deviceQuery.cu -o deviceQuery\n","!./deviceQuery"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ‚úÖ Parallel reduction con SMEM\n"],"metadata":{"id":"OHR7Zs3dNs1N"}},{"cell_type":"code","source":["%%writefile parReduceSMEM/preduceSMEM.cu\n","\n","#include \"../../utils/common.h\"\n","#include <cuda_runtime.h>\n","#include <stdio.h>\n","#define DIM 1024\n","\n","/*\n"," * An example of using shared memory to optimize performance of a parallel\n"," * reduction by constructing partial results for a thread block in shared memory\n"," * before flushing to global memory.\n"," */\n","\n","extern __shared__ int dsmem[];\n","\n","// Recursive Implementation of Interleaved Pair Approach\n","int recursiveReduce(int *data, int const size) {\n","    if (size == 1) return data[0];\n","\n","    int const stride = size / 2;\n","\n","    for (int i = 0; i < stride; i++)\n","        data[i] += data[i + stride];\n","\n","    return recursiveReduce(data, stride);\n","}\n","\n","// unroll4 + complete unroll for loop + gmem\n","__global__ void reduceGmem(int *g_idata, int *g_odata, unsigned int n) {\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    int *idata = g_idata + blockIdx.x * blockDim.x;\n","\n","    // boundary check\n","    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (idx >= n) return;\n","\n","    // in-place reduction in global memory\n","    if (blockDim.x >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 512 && tid < 256) idata[tid] += idata[tid + 256];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 256 && tid < 128) idata[tid] += idata[tid + 128];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 128 && tid < 64) idata[tid] += idata[tid + 64];\n","\n","    __syncthreads();\n","\n","    // unrolling warp\n","    if (tid < 32)\n","    {\n","        volatile int *vsmem = idata;\n","        vsmem[tid] += vsmem[tid + 32];\n","        vsmem[tid] += vsmem[tid + 16];\n","        vsmem[tid] += vsmem[tid +  8];\n","        vsmem[tid] += vsmem[tid +  4];\n","        vsmem[tid] += vsmem[tid +  2];\n","        vsmem[tid] += vsmem[tid +  1];\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n","}\n","\n","__global__ void reduceSmem(int *g_idata, int *g_odata, unsigned int n) {\n","    __shared__ int smem[DIM];\n","\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","\n","    // boundary check\n","    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (idx >= n) return;\n","\n","    // convert global data pointer to the local pointer of this block\n","    int *idata = g_idata + blockIdx.x * blockDim.x;\n","\n","    // set to smem by each threads\n","    smem[tid] = idata[tid];\n","    __syncthreads();\n","\n","    // in-place reduction in shared memory\n","    if (blockDim.x >= 1024 && tid < 512) smem[tid] += smem[tid + 512];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 512 && tid < 256) smem[tid] += smem[tid + 256];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 256 && tid < 128) smem[tid] += smem[tid + 128];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 128 && tid < 64)  smem[tid] += smem[tid + 64];\n","\n","    __syncthreads();\n","\n","    // unrolling warp\n","    if (tid < 32)\n","    {\n","        volatile int *vsmem = smem;\n","        vsmem[tid] += vsmem[tid + 32];\n","        vsmem[tid] += vsmem[tid + 16];\n","        vsmem[tid] += vsmem[tid +  8];\n","        vsmem[tid] += vsmem[tid +  4];\n","        vsmem[tid] += vsmem[tid +  2];\n","        vsmem[tid] += vsmem[tid +  1];\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n","}\n","\n","__global__ void reduceSmemDyn(int *g_idata, int *g_odata, unsigned int n) {\n","    extern __shared__ int smem[];\n","\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    int *idata = g_idata + blockIdx.x * blockDim.x;\n","\n","    // set to smem by each threads\n","    smem[tid] = idata[tid];\n","    __syncthreads();\n","\n","    // in-place reduction in global memory\n","    if (blockDim.x >= 1024 && tid < 512)  smem[tid] += smem[tid + 512];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 512 && tid < 256)  smem[tid] += smem[tid + 256];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 256 && tid < 128) smem[tid] += smem[tid + 128];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 128 && tid < 64) smem[tid] += smem[tid + 64];\n","\n","    __syncthreads();\n","\n","    // unrolling warp\n","    if (tid < 32)\n","    {\n","        volatile int *vsmem = smem;\n","        vsmem[tid] += vsmem[tid + 32];\n","        vsmem[tid] += vsmem[tid + 16];\n","        vsmem[tid] += vsmem[tid +  8];\n","        vsmem[tid] += vsmem[tid +  4];\n","        vsmem[tid] += vsmem[tid +  2];\n","        vsmem[tid] += vsmem[tid +  1];\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n","}\n","\n","// unroll4 + complete unroll for loop + gmem\n","__global__ void reduceGmemUnroll(int *g_idata, int *g_odata, unsigned int n) {\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    unsigned int idx = blockIdx.x * blockDim.x * 4 + threadIdx.x;\n","\n","    // convert global data pointer to the local pointer of this block\n","    int *idata = g_idata + blockIdx.x * blockDim.x * 4;\n","\n","    // unrolling 4\n","    if (idx + 3 * blockDim.x < n)\n","    {\n","        int a1 = g_idata[idx];\n","        int a2 = g_idata[idx + blockDim.x];\n","        int a3 = g_idata[idx + 2 * blockDim.x];\n","        int a4 = g_idata[idx + 3 * blockDim.x];\n","        g_idata[idx] = a1 + a2 + a3 + a4;\n","    }\n","\n","    __syncthreads();\n","\n","    // in-place reduction in global memory\n","    if (blockDim.x >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 512 && tid < 256) idata[tid] += idata[tid + 256];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 256 && tid < 128) idata[tid] += idata[tid + 128];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 128 && tid < 64) idata[tid] += idata[tid + 64];\n","\n","    __syncthreads();\n","\n","    // unrolling warp\n","    if (tid < 32)\n","    {\n","        volatile int *vsmem = idata;\n","        vsmem[tid] += vsmem[tid + 32];\n","        vsmem[tid] += vsmem[tid + 16];\n","        vsmem[tid] += vsmem[tid +  8];\n","        vsmem[tid] += vsmem[tid +  4];\n","        vsmem[tid] += vsmem[tid +  2];\n","        vsmem[tid] += vsmem[tid +  1];\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n","}\n","\n","__global__ void reduceSmemUnroll(int *g_idata, int *g_odata, unsigned int n)\n","{\n","    // static shared memory\n","    __shared__ int smem[DIM];\n","\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","\n","    // global index, 4 blocks of input data processed at a time\n","    unsigned int idx = blockIdx.x * blockDim.x * 4 + threadIdx.x;\n","\n","    // unrolling 4 blocks\n","    int tmpSum = 0;\n","\n","    // boundary check\n","    if (idx + 4 * blockDim.x <= n)\n","    {\n","        int a1 = g_idata[idx];\n","        int a2 = g_idata[idx + blockDim.x];\n","        int a3 = g_idata[idx + 2 * blockDim.x];\n","        int a4 = g_idata[idx + 3 * blockDim.x];\n","        tmpSum = a1 + a2 + a3 + a4;\n","    }\n","\n","    smem[tid] = tmpSum;\n","    __syncthreads();\n","\n","    // in-place reduction in shared memory\n","    if (blockDim.x >= 1024 && tid < 512) smem[tid] += smem[tid + 512];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 512 && tid < 256)  smem[tid] += smem[tid + 256];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 256 && tid < 128)  smem[tid] += smem[tid + 128];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 128 && tid < 64)   smem[tid] += smem[tid + 64];\n","\n","    __syncthreads();\n","\n","    // unrolling warp\n","    if (tid < 32)\n","    {\n","        volatile int *vsmem = smem;\n","        vsmem[tid] += vsmem[tid + 32];\n","        vsmem[tid] += vsmem[tid + 16];\n","        vsmem[tid] += vsmem[tid +  8];\n","        vsmem[tid] += vsmem[tid +  4];\n","        vsmem[tid] += vsmem[tid +  2];\n","        vsmem[tid] += vsmem[tid +  1];\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n","}\n","\n","__global__ void reduceSmemUnrollDyn(int *g_idata, int *g_odata, unsigned int n)\n","{\n","    extern __shared__ int smem[];\n","\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    unsigned int idx = blockIdx.x * blockDim.x * 4 + threadIdx.x;\n","\n","    // unrolling 4\n","    int tmpSum = 0;\n","\n","    if (idx + 3 * blockDim.x < n)\n","    {\n","        int a1 = g_idata[idx];\n","        int a2 = g_idata[idx + blockDim.x];\n","        int a3 = g_idata[idx + 2 * blockDim.x];\n","        int a4 = g_idata[idx + 3 * blockDim.x];\n","        tmpSum = a1 + a2 + a3 + a4;\n","    }\n","\n","    smem[tid] = tmpSum;\n","    __syncthreads();\n","\n","    // in-place reduction in global memory\n","    if (blockDim.x >= 1024 && tid < 512)  smem[tid] += smem[tid + 512];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 512 && tid < 256)  smem[tid] += smem[tid + 256];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 256 && tid < 128) smem[tid] += smem[tid + 128];\n","\n","    __syncthreads();\n","\n","    if (blockDim.x >= 128 && tid < 64) smem[tid] += smem[tid + 64];\n","\n","    __syncthreads();\n","\n","    // unrolling warp\n","    if (tid < 32)\n","    {\n","        volatile int *vsmem = smem;\n","        vsmem[tid] += vsmem[tid + 32];\n","        vsmem[tid] += vsmem[tid + 16];\n","        vsmem[tid] += vsmem[tid +  8];\n","        vsmem[tid] += vsmem[tid +  4];\n","        vsmem[tid] += vsmem[tid +  2];\n","        vsmem[tid] += vsmem[tid +  1];\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n","}\n","\n","__global__ void reduceNeighboredGmem(int *g_idata, int *g_odata,\n","                                     unsigned int  n)\n","{\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    // convert global data pointer to the local pointer of this block\n","    int *idata = g_idata + blockIdx.x * blockDim.x;\n","\n","    // boundary check\n","    if (idx >= n) return;\n","\n","    // in-place reduction in global memory\n","    for (int stride = 1; stride < blockDim.x; stride *= 2)\n","    {\n","        if ((tid % (2 * stride)) == 0)\n","        {\n","            idata[tid] += idata[tid + stride];\n","        }\n","\n","        // synchronize within threadblock\n","        __syncthreads();\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n","}\n","\n","__global__ void reduceNeighboredSmem(int *g_idata, int *g_odata,\n","                                     unsigned int  n)\n","{\n","    __shared__ int smem[DIM];\n","\n","    // set thread ID\n","    unsigned int tid = threadIdx.x;\n","    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    // convert global data pointer to the local pointer of this block\n","    int *idata = g_idata + blockIdx.x * blockDim.x;\n","\n","    // boundary check\n","    if (idx >= n) return;\n","\n","    smem[tid] = idata[tid];\n","    __syncthreads();\n","\n","    // in-place reduction in global memory\n","    for (int stride = 1; stride < blockDim.x; stride *= 2)\n","    {\n","        if ((tid % (2 * stride)) == 0)\n","        {\n","            smem[tid] += smem[tid + stride];\n","        }\n","\n","        // synchronize within threadblock\n","        __syncthreads();\n","    }\n","\n","    // write result for this block to global mem\n","    if (tid == 0) g_odata[blockIdx.x] = smem[0];\n","}\n","\n","int main(int argc, char **argv) {\n","    // set up device\n","    int dev = 0;\n","    cudaDeviceProp deviceProp;\n","    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","    printf(\"%s starting reduction at \", argv[0]);\n","    printf(\"device %d: %s \", dev, deviceProp.name);\n","    CHECK(cudaSetDevice(dev));\n","\n","    bool bResult = false;\n","\n","    // initialization\n","    int power = 10;\n","\n","    // execution configuration\n","    int blocksize = DIM;   // initial block size\n","\n","    if (argc >= 2) {\n","        blocksize = atoi(argv[1]);\n","    }\n","\n","    if (argc >= 3) {\n","        power = atoi(argv[2]);\n","    }\n","\n","    int size = 1 << power; // total number of elements to reduce\n","    printf(\"    with array size %d  \", size);\n","\n","    dim3 block (blocksize, 1);\n","    dim3 grid  ((size + block.x - 1) / block.x, 1);\n","    printf(\"grid %d block %d\\n\", grid.x, block.x);\n","\n","    // allocate host memory\n","    size_t bytes = size * sizeof(int);\n","    int *h_idata = (int *) malloc(bytes);\n","    int *h_odata = (int *) malloc(grid.x * sizeof(int));\n","    int *tmp     = (int *) malloc(bytes);\n","\n","    // initialize the array\n","    for (int i = 0; i < size; i++)\n","        h_idata[i] = (int)( rand() & 0xFF );\n","\n","    memcpy (tmp, h_idata, bytes);\n","\n","    int gpu_sum = 0;\n","\n","    // allocate device memory\n","    int *d_idata = NULL;\n","    int *d_odata = NULL;\n","    CHECK(cudaMalloc((void **) &d_idata, bytes));\n","    CHECK(cudaMalloc((void **) &d_odata, grid.x * sizeof(int)));\n","\n","    // cpu reduction\n","    int cpu_sum = recursiveReduce (tmp, size);\n","    printf(\"cpu reduce          : %d\\n\", cpu_sum);\n","\n","    // reduce gmem\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    reduceNeighboredGmem<<<grid.x, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaGetLastError());\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"reduceNeighboredGmem: %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x,\n","           block.x);\n","\n","    // reduce gmem\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    reduceNeighboredSmem<<<grid.x, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaGetLastError());\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"reduceNeighboredSmem: %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x,\n","           block.x);\n","\n","    // reduce gmem\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    reduceGmem<<<grid.x, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaGetLastError());\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"reduceGmem          : %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x,\n","           block.x);\n","\n","    // reduce smem\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    reduceSmem<<<grid.x, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaGetLastError());\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"reduceSmem          : %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x,\n","           block.x);\n","\n","    // reduce smem\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    reduceSmemDyn<<<grid.x, block, blocksize*sizeof(int)>>>(d_idata, d_odata,\n","            size);\n","    CHECK(cudaGetLastError());\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"reduceSmemDyn       : %d <<<grid %d block %d>>>\\n\", gpu_sum, grid.x,\n","           block.x);\n","\n","    // reduce gmem\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    reduceGmemUnroll<<<grid.x / 4, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaGetLastError());\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x / 4; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"reduceGmemUnroll4   : %d <<<grid %d block %d>>>\\n\", gpu_sum,\n","            grid.x / 4, block.x);\n","\n","    // reduce smem\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    reduceSmemUnroll<<<grid.x / 4, block>>>(d_idata, d_odata, size);\n","    CHECK(cudaGetLastError());\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x / 4; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"reduceSmemUnroll4   : %d <<<grid %d block %d>>>\\n\", gpu_sum,\n","            grid.x / 4, block.x);\n","\n","    // reduce smem\n","    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n","    reduceSmemUnrollDyn<<<grid.x / 4, block, DIM*sizeof(int)>>>(d_idata,\n","            d_odata, size);\n","    CHECK(cudaGetLastError());\n","    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(int),\n","                     cudaMemcpyDeviceToHost));\n","    gpu_sum = 0;\n","\n","    for (int i = 0; i < grid.x / 4; i++) gpu_sum += h_odata[i];\n","\n","    printf(\"reduceSmemDynUnroll4: %d <<<grid %d block %d>>>\\n\", gpu_sum,\n","            grid.x / 4, block.x);\n","\n","    // free host memory\n","    free(h_idata);\n","    free(h_odata);\n","\n","    // free device memory\n","    CHECK(cudaFree(d_idata));\n","    CHECK(cudaFree(d_odata));\n","\n","    // reset device\n","    CHECK(cudaDeviceReset());\n","\n","    // check the results\n","    bResult = (gpu_sum == cpu_sum);\n","\n","    if(!bResult) printf(\"Test failed!\\n\");\n","\n","    return EXIT_SUCCESS;\n","}\n"],"metadata":{"id":"aF_XWzGyNmBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_37 parReduceSMEM/preduceSMEM.cu -o preduce\n","!./preduce 512 12"],"metadata":{"id":"sCBstFF3U1Ya"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vXUIQkZLCTcG"},"source":["# ‚úÖ Moltiplicazione matriciale con SMEM\n"]},{"cell_type":"markdown","source":["# üî¥ TODO"],"metadata":{"id":"8B0w12MS4xtP"}},{"cell_type":"code","metadata":{"id":"-Y52R0d3CA50"},"source":["%%writefile prodMatSMEM/prodMatSMEM.cu\n","\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include \"../../utils/common.h\"\n","\n","#define IDX(i,j,n) (i*n+j)\n","#define ABS(x,y) (x-y>=0?x-y:y-x)\n","#define N 1024\n","#define P 1024\n","#define M 1024\n","\n","#define BLOCK_SIZE 16\n","\n","/*\n"," * Kernel for matrix product with static SMEM\n"," *      C  =  A  *  B\n"," *    (NxM) (MxP) (PxM)\n"," */\n","__global__ void matProdSMEMstatic(float* A, float* B, float* C) {\n","\t// indexes\n","\tuint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tuint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// target: compute the right sum for the given row and col\n","\tfloat sum = 0.0;\n","\n","\t// static shared memory\n","\t__shared__ float As[BLOCK_SIZE][BLOCK_SIZE];\n","\t__shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];\n","\n","\t// loop over blocks from block row of matrix A\n","\t// and block column of matrix B\n","\tuint numBlocks = (P + BLOCK_SIZE - 1) / BLOCK_SIZE;\n","\tfor (uint m = 0; m < numBlocks; m++) {\n","\n","\t\t// copy block from matrix to shared memory\n","\t\tuint r = m * BLOCK_SIZE + threadIdx.y;\n","\t\tuint c = m * BLOCK_SIZE + threadIdx.x;\n","\t\tAs[threadIdx.y][threadIdx.x] = A[IDX(row, c, P)];\n","\t\tBs[threadIdx.y][threadIdx.x] = B[IDX(r, col, M)];\n","\n","\t\t//---------------------------------------------------------------\n","\t\t__syncthreads();  //  BARRIER SYNC on SMEM loading\n","\n","\t\t// length of this part of row-column product is BLOCK_SIZE\n","\t\t// except for last block when it may be smaller\n","\t\tuint K = BLOCK_SIZE;\n","\t\tif (m == numBlocks - 1) K = P - m * BLOCK_SIZE; // tune last block\n","\n","\t\t// compute this part of row-column product\n","\t\tfor (uint k = 0; k < K; k++)\n","\t\t\tsum += As[threadIdx.y][k] * Bs[k][threadIdx.x];\n","\n","\t\t//---------------------------------------------------------------\n","\t\t__syncthreads();  //  BARRIER SYNC on prod over blocks\n","\t\t// Synchronize to make sure that the preceding\n","\t\t// computation is done before loading two new\n","\t\t// sub-matrices of A and B in the next iteration\n","\t}\n","\n","\t// store computed element in matrix C\n","\tif (row < N && col < M)\n","\t\tC[row * M + col] = sum;\n","}\n","\n","\n","/*\n"," * Kernel for matrix product using dynamic SMEM\n"," */\n","__global__ void matProdSMEMdynamic(float* A, float* B, float* C, const uint SMEMsize) {\n","\t// indexes\n","\tuint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tuint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// dynamic shared memory (inside or outside kernel)\n","\textern __shared__ float smem[];\n","\n","\t// Var As is manually set at beginning of shared\n","\tfloat *As = smem;\n","\t// Var Bs is manually set at the end of As\n","\tfloat *Bs = &smem[SMEMsize];\n","\n","\t// loop over blocks from block row of matrix A\n","\t// and block column of matrix B\n","\tfloat sum = 0.0;\n","\tuint numBlocks = (P + blockDim.x - 1) / blockDim.x;\n","\tfor (uint m = 0; m < numBlocks; m++) {\n","\n","\t\t// copy block from matrix to shared memory\n","\t\tuint c = m * blockDim.x + threadIdx.x;\n","\t\tuint r = m * blockDim.y + threadIdx.y;\n","\t\tAs[threadIdx.y * blockDim.y + threadIdx.x] = A[IDX(row, c, P)];\n","\t\tBs[threadIdx.y * blockDim.y + threadIdx.x] = B[IDX(r, col, M)];\n","\n","\t\t//---------------------------------------------------------------\n","\t\t__syncthreads();\n","\n","\t\t// length of this part of row-column product is BLOCK_SIZE\n","\t\t// except for last block when it may be smaller\n","\t\tuint K = (m == numBlocks - 1 ? P - m * blockDim.x : blockDim.x);\n","\n","\t\t// compute this part of row-column product\n","\t\tfor (int k = 0; k < K; k++)\n","\t\t\tsum += As[threadIdx.y * blockDim.x + k] * Bs[k * blockDim.y + threadIdx.x];\n","\n","\t\t//---------------------------------------------------------------\n","\t\t__syncthreads();\n","\t}\n","\n","\t// store computed element in matrix C\n","\tif (row < N && col < M)\n","\t\tC[row * M + col] = sum;\n","}\n","\n","/*\n"," * Kernel for naive matrix product\n"," */\n","__global__ void matProd(float* A, float* B, float* C) {\n","\t// indexes\n","\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","\t// each thread computes an entry of the product matrix\n","\tif ((row < N) && (col < M)) {\n","\t\tfloat sum = 0;\n","\t\tfor (int k = 0; k < P; k++)\n","\t\t\tsum += A[row * P + k] * B[k * M + col];\n","\t\tC[row * M + col] = sum;\n","\t}\n","}\n","\n","/*\n"," *  matrix product on CPU\n"," */\n","void matProdCPU(float* A, float* B, float* C) {\n","\n","\tfor (int i = 0; i < N; i++)\n","\t\tfor (int j = 0; j < M; j++) {\n","\t\t\tfloat sum = 0;\n","\t\t\tfor (int k = 0; k < P; k++)\n","\t\t\t\tsum += A[i * P + k] * B[k * M + j];\n","\t\t\tC[i * M + j] = sum;\n","\t\t}\n","}\n","\n","/*\n"," * Test the device\n"," */\n","unsigned long testCUDADevice(void) {\n","\tint dev = 0;\n","\n","\tcudaDeviceSetCacheConfig (cudaFuncCachePreferEqual);\n","\tcudaDeviceProp deviceProp;\n","\tcudaSetDevice(dev);\n","\tcudaGetDeviceProperties(&deviceProp, dev);\n","\tprintf(\"Device %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n","\tprintf(\"Total amount of shared memory available per block: %lu KB\\n\",\n","\t\t\tdeviceProp.sharedMemPerBlock / 1024);\n","\treturn deviceProp.sharedMemPerBlock;\n","}\n","\n","\n","/*\n"," * elementwise comparison between two mqdb\n"," */\n","void checkResult(float *A, float *B) {\n","\tdouble epsilon = 1.0E-8;\n","\tbool match = 1;\n","\tfor (int i = 0; i < N*M; i++)\n","\t\tif (ABS(A[i], B[i]) > epsilon) {\n","\t\t\tmatch = 0;\n","\t\t\tprintf(\"   * Arrays do not match!\\n\");\n","\t\t\tbreak;\n","\t\t}\n","\tif (match)\n","\t\tprintf(\"   Arrays match\\n\\n\");\n","}\n","\n","/*\n"," * MAIN\n"," */\n","int main(void) {\n","\t // Kernels for matrix product\n","\t //      C  =  A  *  B\n","\t //    (NxM) (MxP) (PxM)\n","\tuint rowA = N, rowB = P;\n","\tuint colA = P, colB = M;\n","\tuint rowC = N, colC = M;\n","\tfloat *A, *B, *C, *C1;\n","\tfloat *dev_A, *dev_B, *dev_C;\n","\n","\t// dims\n","\tunsigned long Asize = rowA * colA * sizeof(float);\n","\tunsigned long Bsize = rowB * colB * sizeof(float);\n","\tunsigned long Csize = rowC * colC * sizeof(float);\n","\tunsigned long maxSMEMbytes;\n","\tuint nByteSMEM = 2 * BLOCK_SIZE * BLOCK_SIZE * sizeof(float);\n","\tprintf(\"N = %d, M = %d, P = %d\\n\",N,M,P);\n","\n","\t// test device shared memory\n","\tmaxSMEMbytes = testCUDADevice();\n","\tif (maxSMEMbytes < nByteSMEM)\n","\t\tprintf(\"Shared memory usage WARNING: available: %lu, required: %d bytes\\n\",\n","\t\t\t\tmaxSMEMbytes, nByteSMEM);\n","\telse\n","\t\tprintf(\"Total amount of shared memory required per block %.1f KB\\n\",\n","\t\t\t\t(float) nByteSMEM / (float) 1024);\n","\n","\t// malloc host memory\n","\tA = (float*) malloc(Asize);\n","\tB = (float*) malloc(Bsize);\n","\tC = (float*) malloc(Csize);\n","\tC1 = (float*) malloc(Csize);\n","\n","\t// malloc device memory\n","\tCHECK(cudaMalloc((void** )&dev_A, Asize));\n","\tCHECK(cudaMalloc((void** )&dev_B, Bsize));\n","\tCHECK(cudaMalloc((void** )&dev_C, Csize));\n","\tprintf(\"Total amount of allocated memory on GPU %lu bytes\\n\\n\",\n","\t\t\tAsize + Bsize + Csize);\n","\n","\t// fill the matrices A and B\n","\tfor (int i = 0; i < N * P; i++)\n","\t\tA[i] = rand() % 10;\n","\tfor (int i = 0; i < P * M; i++)\n","\t\tB[i] = rand() % 10;\n","\tmatProdCPU(A, B, C);\n","\n","\t// copy matrices A and B to the GPU\n","\tCHECK(cudaMemcpy(dev_A, A, Asize, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemcpy(dev_B, B, Bsize, cudaMemcpyHostToDevice));\n","\n","\t/***********************************************************/\n","\t/*              GPU matProdSMEM static SMEM               */\n","\t/***********************************************************/\n","\t// grid block dims = shared mem dims = BLOCK_SIZE\n","\tdim3 block(BLOCK_SIZE, BLOCK_SIZE);\n","\tdim3 grid((M + block.x - 1) / block.x, (N + block.y - 1) / block.y);\n","\tdouble start = seconds();\n","\tmatProdSMEMstatic<<<grid, block>>>(dev_A, dev_B, dev_C);\n","\tCHECK(cudaDeviceSynchronize());\n","\tprintf(\"   Kernel matProdSMEM static elapsed time GPU = %f\\n\", seconds() - start);\n","\n","\t// copy the array 'C' back from the GPU to the CPU\n","\tCHECK(cudaMemcpy(C1, dev_C, Csize, cudaMemcpyDeviceToHost));\n","\tcheckResult(C,C1);\n","\n","\t/***********************************************************/\n","\t/*            GPU matProdSMEMD dynamic SMEM                */\n","\t/***********************************************************/\n","\t// set cache size\n","\tcudaDeviceSetCacheConfig (cudaFuncCachePreferShared);\n","\n","\t// try with various SMEM sizes\n","\tuint sizes[] = {8,16,32};\n","\tfor (int i = 0; i < 3; i++) {\n","\t\tuint blockSize = sizes[i];\n","\t\tblock.x = blockSize;\n","\t\tblock.y = blockSize;\n","\t\tgrid.x = (M + block.x - 1) / block.x;\n","\t\tgrid.y = (N + block.y - 1) / block.y;\n","\t\tuint SMEMsize = blockSize * blockSize;\n","\t\tuint SMEMbyte = 2 * SMEMsize * sizeof(float);\n","\t\tstart = seconds();\n","\t\tmatProdSMEMdynamic<<< grid, block, SMEMbyte >>>(dev_A, dev_B, dev_C, SMEMsize);\n","\t\tCHECK(cudaDeviceSynchronize());\n","\t\tprintf(\"   Kernel matProdSMEM dynamic (SMEM size %d) elapsed time GPU = %f\\n\", blockSize, seconds() - start);\n","\n","\t\t// copy the array 'C' back from the GPU to the CPU\n","\t\tCHECK(cudaMemcpy(C1, dev_C, Csize, cudaMemcpyDeviceToHost));\n","\t\tcheckResult(C,C1);\n","\t}\n","\n","\t// free the memory allocated on the GPU\n","\tcudaFree(dev_A);\n","\tcudaFree(dev_B);\n","\tcudaFree(dev_C);\n","\n","\tcudaDeviceReset();\n","\treturn EXIT_SUCCESS;\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"urXtf5RQ7hfh"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0PSc9B9PDTWt"},"source":["# Compilazione ed esecuzione\n","\n","!nvcc -arch=sm_60 matProdSMEM.cu  -o matProdSMEM\n","!matProdSMEM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfR471rze2p-"},"source":["!ls -la"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOFMQZAkjlLW"},"source":["# ‚úÖ Convoluzione con SMEM"]},{"cell_type":"code","metadata":{"id":"v9nRkLgeB10A"},"source":["%%writefile convolutionSMEM/conv1D.cu\n","\n","#include <stdlib.h>\n","#include <stdio.h>\n","#include \"../../utils/common.h\"\n","\n","#define MASK_RADIUS  5\n","#define MASK_SIZE    2 * MASK_RADIUS + 1\n","#define BLOCK_SIZE   128\n","#define TILE_WIDTH   BLOCK_SIZE + MASK_SIZE - 1\n","\n","__device__ __constant__ float d_mask[MASK_SIZE];\n","\n","void initialData(float*, int);\n","void movingAverage(float*, int n);\n","void printData(float*, const int);\n","void convolutionHost(float*, float*, float*, const int);\n","void checkResult(float*, float*, int);\n","\n","/*\n"," * kernel for 1D convolution: it holds only if MASK_RADIUS < BLOCK_SIZE\n"," */\n","__global__ void convolution1D(float *result, float *data, int n) {\n","\tunsigned int i = blockDim.x * blockIdx.x + threadIdx.x;\n","\n","\t// shared memory size = BLOCK_SIZE + MASK\n","\t__shared__ float tile[TILE_WIDTH];\n","\n","\t// boundary\n","\tint left = blockIdx.x * blockDim.x - MASK_RADIUS;\n","\tint right = (blockIdx.x + 1) * blockDim.x;\n","\n","  // left halo\n","\tif (threadIdx.x < MASK_RADIUS)                      \n","\t\ttile[threadIdx.x] = left < 0 ? 0 : data[left + threadIdx.x];\n","\n","  // center\n","\ttile[threadIdx.x + MASK_RADIUS] = data[i];\n","\n","  // right halo  \n","\tif (threadIdx.x >= blockDim.x - MASK_RADIUS)  \n","\t\ttile[threadIdx.x + MASK_SIZE - 1] = right >= n ? 0 :\n","\t\t\t\tdata[right + threadIdx.x - blockDim.x + MASK_RADIUS];\n","\n","\t__syncthreads();\n","\n","\t// convolution: tile * mask\n","\tfloat sum = 0;\n","\tfor (int i = -MASK_RADIUS; i <= MASK_RADIUS; i++)\n","\t\tsum += tile[threadIdx.x + MASK_RADIUS + i] * d_mask[i + MASK_RADIUS];\n","\n","\t// final result\n","\tresult[i] = sum;\n","}\n","\n","/*\n"," * MAIN: convolution 1D host & device\n"," */\n","int main(int argc, char **argv) {\n","\t// set up device\n","\tint dev = 0;\n","\tcudaDeviceProp deviceProp;\n","\tCHECK(cudaGetDeviceProperties(&deviceProp, dev));\n","\tprintf(\"starting conv1D at device %d: %s\\n\", dev, deviceProp.name);\n","\tCHECK(cudaSetDevice(dev));\n","\n","\t// set up array size\n","\tint n = 1 << 24;\n","\tint N = MASK_SIZE;\n","\n","\tprintf(\"Array of size = %.1f MB\\n\", n/(1024.0*1024.0));\n","\n","\t// mem sizes\n","\tsize_t nBytes = n * sizeof(float);\n","\tsize_t nBytes_mask = N * sizeof(float);\n","\n","\t// grid configuration\n","\tdim3 block(BLOCK_SIZE);\n","\tdim3 grid((n + BLOCK_SIZE - 1) / BLOCK_SIZE);\n","\n","\t// allocate host memory\n","\tfloat *h_data = (float *) malloc(nBytes);\n","\tfloat *h_result = (float *) malloc(nBytes);\n","\tfloat *result = (float *) malloc(nBytes);\n","\tfloat *h_mask = (float *) malloc(nBytes_mask);\n","\n","\t//  initialize host array\n","\tmovingAverage(h_mask, N);\n","\tinitialData(h_data, n);\n","\n","\t// convolution on host\n","\tdouble start = seconds();\n","\tconvolutionHost(h_data, result, h_mask, n);\n","\tdouble hostElaps = seconds() - start;\n","\n","\t// allocate device memory\n","\tfloat *d_data, *d_result;\n","\tCHECK(cudaMalloc((void**)&d_data, nBytes));\n","\tCHECK(cudaMalloc((void**)&d_result, nBytes));\n","\n","\t// copy data from host to device\n","\tCHECK(cudaMemcpy(d_data, h_data, nBytes, cudaMemcpyHostToDevice));\n","\tCHECK(cudaMemcpyToSymbol(d_mask, h_mask, nBytes_mask));\n","\n","\tstart = seconds();\n","\tconvolution1D<<<grid, block>>>(d_result, d_data, n);\n","\tCHECK(cudaDeviceSynchronize());\n","\tdouble devElaps = seconds() - start;\n","  printf(\"Times:\\n\");\n","\tprintf(\"   - CPU elapsed time = %f\\n\", hostElaps);\n","  printf(\"   - GPU elapsed time = %f\\n\", devElaps);\n","  printf(\"   - Speed-up (ratio) = %f\\n\", hostElaps / devElaps);\n","\n","\tCHECK(cudaMemcpy(h_result, d_result, nBytes, cudaMemcpyDeviceToHost));\n","\n","\t// check result\n","\tcheckResult(h_result, result, n);\n","\n","\t// free host and device memory\n","\tCHECK(cudaFree(d_result));\n","\tCHECK(cudaFree(d_data));\n","\tfree(h_data);\n","\tfree(h_mask);\n","\tfree(h_result);\n","\tfree(result);\n","\n","\t// reset device\n","\tCHECK(cudaDeviceReset());\n","\treturn EXIT_SUCCESS;\n","}\n","\n","void initialData(float *h_data, int n) {\n","\t// initialize the data\n","\tfor (int i = 0; i < n; i++)\n","\t\th_data[i] = 10.0;\n","}\n","\n","void movingAverage(float *h_mask, int n) {\n","\t// initialize mask moving average\n","\tfor (int i = 0; i < n; i++)\n","\t\th_mask[i] = 1.0 / ((float) n);\n","\treturn;\n","}\n","\n","void printData(float *a, const int size) {\n","\tprintf(\"\\n\");\n","\tfor (int i = 0; i < size; i++)\n","\t\tprintf(\"%.2f \", a[i]);\n","\tprintf(\"\\n\");\n","\treturn;\n","}\n","\n","void convolutionHost(float *data, float *result, float *mask, const int n) {\n","\tfor (int i = 0; i < n; i++) {\n","\t\tfloat sum = 0;\n","\t\tfor (int j = 0; j < MASK_SIZE; j++) {\n","\t\t\tint idx = i - MASK_RADIUS + j;\n","\t\t\tif (idx >= 0 && idx < n)\n","\t\t\t\tsum += data[idx] * mask[j];\n","\t\t}\n","\t\tresult[i] = sum;\n","\t}\n","}\n","\n","void checkResult(float *d_result, float *h_result, int n) {\n","\tdouble epsilon = 1.0E-8;\n","\n","\tfor (int i = 0; i < n; i++)\n","\t\tif (abs(h_result[i] - d_result[i]) > epsilon) {\n","\t\t\tprintf(\"different on entry (%d) |h_result - d_result| >  %f\\n\", i,\n","\t\t\t\t\tepsilon);\n","\t\t\tbreak;\n","\t\t}\n","}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLxZjCx8bT3s"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_37  convolutionSMEM/conv1D.cu -o conv1D\n","!./conv1D"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üî¥ TODO"],"metadata":{"id":"hI7kdGlx72HO"}},{"cell_type":"code","metadata":{"id":"bwcTDn6ehJr_"},"source":["%%writefile convolutionSMEM/conv2D.cu\n","#include <stdlib.h>\n","#include <string.h>\n","\n","#include \"../../utils/common.h\"\n","\n","#define DATA_WIDTH   (20*1024)\n","#define DATA_HEIGHT  (20*1024)\n","#define BLOCK_SIZE   8\n","#define MASK_RADIUS  2\n","#define MASK_SIZE    (2 * MASK_RADIUS + 1)\n","#define TILE_WIDTH   (BLOCK_SIZE + MASK_SIZE - 1)\n","#define DEBUG 0\n","\n","// constant mem\n","__constant__ float M_dev[MASK_SIZE*MASK_SIZE];\n","\n","/*\n"," * kernel for convolution 2D (it holds only if MASK_RADIUS < BLOCK_SIZE)\n"," */\n","__global__ void conv2D(float *A, float *B) {\n","\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n","\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n","\tint RAD = MASK_RADIUS;\n","  int BmR = BLOCK_SIZE - RAD;\n","  int W = DATA_WIDTH;\n","  int H = DATA_HEIGHT;\n","\tint m = MASK_SIZE;\n","\n","\t// shared mem\n","\t__shared__ float A_s[TILE_WIDTH][TILE_WIDTH];\n","\n","  // START SHARED MEMORY LOADING\n","\n","  // 1. copy the tile upper halo \n","  if ((threadIdx.y < RAD) ) {\n","    \n","    // left corner\n","    if (threadIdx.x < RAD && (x-RAD) >= 0 && (y-RAD) >= 0)\n","      A_s[threadIdx.y][threadIdx.x] = A[(y-RAD) * W + x - RAD];\n","\n","    // right corner\n","    if (threadIdx.x >= BmR && (x+RAD) < W && (y-RAD) >= 0) \n","      A_s[threadIdx.y][threadIdx.x + 2*RAD] = A[(y-RAD) * W + x + RAD];\n","    \n","    // edge\n","    if ((y-RAD) >= 0) \n","      A_s[threadIdx.y][threadIdx.x + RAD] = A[(y-RAD) * W + x ];  \n","  }\n","\n","  // 2. copy the tile bottom halo \n","  if (threadIdx.y >= BmR) {\n","    \n","    // left corner\n","    if (threadIdx.x < RAD && (x-RAD) >= 0 && (y+RAD) < H)\n","      A_s[threadIdx.y + 2*RAD][threadIdx.x] = A[(y+RAD) * W + x - RAD];\n","\n","    // right corner\n","    if (threadIdx.x >= BmR && (y+RAD) < H) \n","      A_s[threadIdx.y + 2*RAD][threadIdx.x + 2*RAD] = A[(y+RAD) * W + x + RAD];\n","    \n","    // edge\n","    if ((y+RAD) < H) \n","      A_s[threadIdx.y + 2*RAD][threadIdx.x + RAD] = A[(y+RAD) * W + x];  \n","  }\n","\n","  // 3. copy the tile left-edge halo \n","  if (threadIdx.x < RAD) \n","    // edge\n","    if ((x-RAD) >= 0) \n","      A_s[threadIdx.y + RAD][threadIdx.x] = A[y * W + x - RAD];  \n","\n","  // 4. copy the tile right-edge halo \n","  if (threadIdx.x >= BmR) \n","    // edge\n","    if ((x+RAD) < W) \n","      A_s[threadIdx.y + RAD][threadIdx.x + 2*RAD] = A[y * W + x + RAD];  \n","      \n","\n","  // 5. copy the tile center <-> block\n","\tA_s[RAD + threadIdx.y][RAD + threadIdx.x] = A[y*W+x];\n","\t\n","  // END SHARED MEMORY LOADING\n","\n","\t__syncthreads();\n","\n","\tfloat conv_sum = 0.0;\n","\tfor (int i = 0; i < m; i++)\n","\t\tfor (int j = 0; j < m; j++)\n","\t\t\tconv_sum += A_s[threadIdx.y+i][threadIdx.x+j] * M_dev[i*m + j];\n","\t\n","  // store conv result\n","  B[x*W+y] = conv_sum;\n","}\n","\n","/*\n"," * Average filter\n"," */\n","void Avg_mask(float *mask) {\n","\tint n = MASK_SIZE;\n","\tfor (int i = 0; i < n*n; i++)\n","\t\tmask[i] = (float) 1.0f / (n * n);\n","}\n","\n","\n","/*\n"," * main\n"," */\n","int main(void) {\n","\n","  // check params\n","  if (MASK_RADIUS >= BLOCK_SIZE) {\n","    printf(\"ERROR: it holds only if MASK_RADIUS < BLOCK_SIZE!\\n\");\n","    return 1;\n","  }\n","\n","\tint nW = DATA_WIDTH;\n","  int nH = DATA_HEIGHT;\n","\tint b = BLOCK_SIZE;\n","\n","\tfloat M[MASK_SIZE*MASK_SIZE]; // const size\n","\tfloat *A, *B, *A_dev, *B_dev;\n","\tint datasize = nW * nH * sizeof(float);\n","  int masksize = MASK_SIZE*MASK_SIZE * sizeof(float);\n","\n","  printf(\"Data size: %.2f (MB)\\n\", (float)datasize/(1024.0*1024.0));\n","\tprintf(\"Initializing data...\\n\");\n","\tA = (float *) malloc(datasize);\n","\tB = (float *) malloc(datasize);\n","\n","\t// initialize data\n","\tfor (int i = 0; i < nH; i++)\n","\t\tfor (int j = 0; j < nW; j++)\n","\t\t\tA[i*nW+j] = rand()%10;\n","\n","  // initialize mask \n","\tAvg_mask(M);\n","\n","#if DEBUG\n","\t// print data\n","\tprintf(\"Print matrix A...\\n\");\n","\tfor (int i = 0; i < nH; i++) {\n","    if (i%8 == 0 && i>0)\n","      printf(\"\\n\");\n","\n","\t\tfor (int j = 0; j < nW; j++)\n","      if (j%8 == 0 && j>0)\n","\t\t\t  printf(\" %0.0f \", A[i*nW+j]);\n","      else\n","        printf(\"%0.0f \", A[i*nW+j]);\n","\t\tprintf(\"\\n\");\n","\t}\n","\n","\tprintf(\"Print matrix M ...\\n\");\n","\tfor (int i = 0; i < MASK_SIZE; i++) {\n","\t\tfor (int j = 0; j < MASK_SIZE; j++)\n","\t\t\t  printf(\" %1.2f \", M[i * MASK_SIZE + j]);\n","\t\tprintf(\"\\n\");\n","\t}\n","#endif\n","\n","\t// cuda allocation \n","\tCHECK(cudaMemcpyToSymbol(M_dev, M, masksize));\n","\tCHECK(cudaMalloc((void **) &A_dev, datasize));\n","\tCHECK(cudaMalloc((void **) &B_dev, datasize));\n","\tCHECK(cudaMemcpy(A_dev, A, datasize, cudaMemcpyHostToDevice));\n","\t\n","\t// block, grid dims, kernel\n","\tdim3 block(b, b);\n","\tdim3 grid((nW+b-1)/b, (nH+b-1)/b);\n","  double iStart, iElaps;\n","\tiStart = seconds();\n","\tconv2D<<<grid, block>>>(A_dev, B_dev);\n","  cudaDeviceSynchronize();\n","  iElaps = seconds() - iStart;\n","\tprintf(\"\\nconv2D<<<(%d,%d), (%d,%d)>>> elapsed time %f sec \\n\\n\", grid.x, grid.y, block.x, block.y, iElaps);\n","\tCHECK(cudaGetLastError());\n","\n","\tCHECK(cudaMemcpy(B, B_dev, datasize, cudaMemcpyDeviceToHost));\n","\n","#if DEBUG\n","\t// print out data\n","\tprintf(\"Print results...\\n\");\n","\tfor (int i = 0; i < nH; i++) {\n","    if (i%8 == 0 && i>0)\n","      printf(\"\\n\");\n","\t\tfor (int j = 0; j < nW; j++)\n","      if (j%8 == 0 && j>0)\n","\t\t\t  printf(\" %0.2f \", B[i*nW+j]);\n","      else\n","        printf(\"%0.2f \", B[i*nW+j]);\n","\t\tprintf(\"\\n\");\n","\t}\n","#endif\n","\n","\tcudaFree(A_dev);\n","\tcudaFree(B_dev);\n","  cudaDeviceReset();\n","\tfree(A);\n","\tfree(B);\n","\treturn 0;\n","}\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yiun00TE2wcE"},"source":["# Compilazione ed esecuzione\n","!nvcc -arch=sm_37  convolutionSMEM/conv2D.cu -o conv2D\n","!./conv2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TQ9BuU3ZW_zL"},"source":["!nvprof ./conv2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"v6SsH_9Dz_w8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"sDZeIJHW1I6V"},"execution_count":null,"outputs":[]}]}